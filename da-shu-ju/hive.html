<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Hive | PYY在线笔记</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/study/img/logo.png">
    <meta name="description" content="PYY在线笔记">
    
    <link rel="preload" href="/study/assets/css/0.styles.f503b9f0.css" as="style"><link rel="preload" href="/study/assets/js/app.dc60e210.js" as="script"><link rel="preload" href="/study/assets/js/6.fceef279.js" as="script"><link rel="preload" href="/study/assets/js/2.6082ecbd.js" as="script"><link rel="prefetch" href="/study/assets/js/10.7ed69d34.js"><link rel="prefetch" href="/study/assets/js/11.9448c32e.js"><link rel="prefetch" href="/study/assets/js/12.86c493c7.js"><link rel="prefetch" href="/study/assets/js/13.9ed58975.js"><link rel="prefetch" href="/study/assets/js/14.48e59348.js"><link rel="prefetch" href="/study/assets/js/15.b5bdf29c.js"><link rel="prefetch" href="/study/assets/js/16.7e65e129.js"><link rel="prefetch" href="/study/assets/js/17.d21d2357.js"><link rel="prefetch" href="/study/assets/js/18.ff6a09ec.js"><link rel="prefetch" href="/study/assets/js/19.4dd597a5.js"><link rel="prefetch" href="/study/assets/js/20.13424f64.js"><link rel="prefetch" href="/study/assets/js/21.d0a93e41.js"><link rel="prefetch" href="/study/assets/js/22.3157d1d1.js"><link rel="prefetch" href="/study/assets/js/23.bf30424e.js"><link rel="prefetch" href="/study/assets/js/24.6e0cd257.js"><link rel="prefetch" href="/study/assets/js/25.85fbb512.js"><link rel="prefetch" href="/study/assets/js/26.c54e0c14.js"><link rel="prefetch" href="/study/assets/js/27.6da488a3.js"><link rel="prefetch" href="/study/assets/js/28.321038ce.js"><link rel="prefetch" href="/study/assets/js/29.3fe454c4.js"><link rel="prefetch" href="/study/assets/js/3.e7c144f8.js"><link rel="prefetch" href="/study/assets/js/30.2c2ed4ad.js"><link rel="prefetch" href="/study/assets/js/31.99fb9619.js"><link rel="prefetch" href="/study/assets/js/32.5aea4bba.js"><link rel="prefetch" href="/study/assets/js/33.8ed67f2e.js"><link rel="prefetch" href="/study/assets/js/34.4eb2a764.js"><link rel="prefetch" href="/study/assets/js/35.32c83c52.js"><link rel="prefetch" href="/study/assets/js/36.0e7c4410.js"><link rel="prefetch" href="/study/assets/js/37.029a3bab.js"><link rel="prefetch" href="/study/assets/js/38.9404c1e2.js"><link rel="prefetch" href="/study/assets/js/39.99a331b6.js"><link rel="prefetch" href="/study/assets/js/4.5e539c6c.js"><link rel="prefetch" href="/study/assets/js/40.68a12f82.js"><link rel="prefetch" href="/study/assets/js/41.f802eb8f.js"><link rel="prefetch" href="/study/assets/js/42.9353144d.js"><link rel="prefetch" href="/study/assets/js/43.58a525e4.js"><link rel="prefetch" href="/study/assets/js/44.d327c357.js"><link rel="prefetch" href="/study/assets/js/45.54dc5bdd.js"><link rel="prefetch" href="/study/assets/js/46.97eb4353.js"><link rel="prefetch" href="/study/assets/js/47.d0f5dd26.js"><link rel="prefetch" href="/study/assets/js/48.c71e0efd.js"><link rel="prefetch" href="/study/assets/js/49.c4bf96d9.js"><link rel="prefetch" href="/study/assets/js/5.49f21cfc.js"><link rel="prefetch" href="/study/assets/js/50.a9f40bc0.js"><link rel="prefetch" href="/study/assets/js/51.cb5601bb.js"><link rel="prefetch" href="/study/assets/js/52.f4b73d57.js"><link rel="prefetch" href="/study/assets/js/7.e9fa99bf.js"><link rel="prefetch" href="/study/assets/js/8.60f08f23.js"><link rel="prefetch" href="/study/assets/js/9.1ebd5ad9.js">
    <link rel="stylesheet" href="/study/assets/css/0.styles.f503b9f0.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/study/" class="home-link router-link-active"><img src="/study/img/logo.png" alt="PYY在线笔记" class="logo"> <span class="site-name can-hide">PYY在线笔记</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/study/技术方案/" class="nav-link">
  技术方案
</a></div><div class="nav-item"><a href="/study/Java技术栈/" class="nav-link">
  Java技术栈
</a></div><div class="nav-item"><a href="/study/分布式/" class="nav-link">
  分布式
</a></div><div class="nav-item"><a href="/study/大数据/" class="nav-link">
  大数据
</a></div><div class="nav-item"><a href="/study/消息队列/" class="nav-link">
  消息队列
</a></div><div class="nav-item"><a href="/study/数据结构和算法/" class="nav-link">
  数据结构和算法
</a></div><div class="nav-item"><a href="/study/k8s/" class="nav-link">
  k8s
</a></div><div class="nav-item"><a href="/study/ServiceMesh/" class="nav-link">
  ServiceMesh
</a></div><div class="nav-item"><a href="/study/DevOps/" class="nav-link">
  DevOps
</a></div><div class="nav-item"><a href="/study/总结/" class="nav-link">
  总结
</a></div><div class="nav-item"><a href="https://www.jianshu.com/u/af08f637aff8" target="_blank" rel="noopener noreferrer" class="nav-link external">
  博客
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/study/技术方案/" class="nav-link">
  技术方案
</a></div><div class="nav-item"><a href="/study/Java技术栈/" class="nav-link">
  Java技术栈
</a></div><div class="nav-item"><a href="/study/分布式/" class="nav-link">
  分布式
</a></div><div class="nav-item"><a href="/study/大数据/" class="nav-link">
  大数据
</a></div><div class="nav-item"><a href="/study/消息队列/" class="nav-link">
  消息队列
</a></div><div class="nav-item"><a href="/study/数据结构和算法/" class="nav-link">
  数据结构和算法
</a></div><div class="nav-item"><a href="/study/k8s/" class="nav-link">
  k8s
</a></div><div class="nav-item"><a href="/study/ServiceMesh/" class="nav-link">
  ServiceMesh
</a></div><div class="nav-item"><a href="/study/DevOps/" class="nav-link">
  DevOps
</a></div><div class="nav-item"><a href="/study/总结/" class="nav-link">
  总结
</a></div><div class="nav-item"><a href="https://www.jianshu.com/u/af08f637aff8" target="_blank" rel="noopener noreferrer" class="nav-link external">
  博客
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Dev Ops</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Java技术栈</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Service Mesh</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>K 8 S</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>分布式</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>大数据</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/study/da-shu-ju/" aria-current="page" class="sidebar-link">介绍</a></li><li><a href="/study/da-shu-ju/azkaban.html" class="sidebar-link">Azkaban</a></li><li><a href="/study/da-shu-ju/clickhouse.html" class="sidebar-link">ClickHouse</a></li><li><a href="/study/da-shu-ju/elkda-gui-mo-ri-zhi-shi-shi-chu-li.html" class="sidebar-link">ELK大规模日志实时处理</a></li><li><a href="/study/da-shu-ju/elasticsearch.html" class="sidebar-link">ElasticSearch</a></li><li><a href="/study/da-shu-ju/flink.html" class="sidebar-link">Flink</a></li><li><a href="/study/da-shu-ju/flume.html" class="sidebar-link">Flume</a></li><li><a href="/study/da-shu-ju/hbase.html" class="sidebar-link">HBase</a></li><li><a href="/study/da-shu-ju/hadoop.html" class="sidebar-link">Hadoop</a></li><li><a href="/study/da-shu-ju/hive.html" aria-current="page" class="active sidebar-link">Hive</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#什么是数仓" class="sidebar-link">什么是数仓</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#基本概念" class="sidebar-link">基本概念</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#数仓为何而来" class="sidebar-link">数仓为何而来</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#数仓的创建" class="sidebar-link">数仓的创建</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#主要特征" class="sidebar-link">主要特征</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#oltp、olap" class="sidebar-link">OLTP、OLAP</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#数据库与数据仓库的区别" class="sidebar-link">数据库与数据仓库的区别</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#数据仓库、数据集市" class="sidebar-link">数据仓库、数据集市</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#数仓的分层架构" class="sidebar-link">数仓的分层架构</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#案例" class="sidebar-link">案例</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-的基本概念" class="sidebar-link">Hive 的基本概念</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-简介" class="sidebar-link">Hive 简介</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#案例-2" class="sidebar-link">案例</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-架构" class="sidebar-link">Hive 架构</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-数据模型" class="sidebar-link">Hive 数据模型</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-与传统数据库对比" class="sidebar-link">Hive 与传统数据库对比</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-元数据" class="sidebar-link">Hive 元数据</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-安装和环境配置" class="sidebar-link">Hive 安装和环境配置</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#安装前准备" class="sidebar-link">安装前准备</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hadoop与hive整合" class="sidebar-link">Hadoop与Hive整合</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#远程模式安装" class="sidebar-link">远程模式安装</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-客户端使用" class="sidebar-link">Hive 客户端使用</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-beeline-client" class="sidebar-link">Hive Beeline Client</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hiveserver、hiveserver2服务" class="sidebar-link">HiveServer、HiveServer2服务</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#关系梳理" class="sidebar-link">关系梳理</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#具体使用" class="sidebar-link">具体使用</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-使用体验" class="sidebar-link">Hive 使用体验</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive使用起来和mysql差不多吗" class="sidebar-link">Hive使用起来和MySQL差不多吗？</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive如何才能将结构化数据映射成为表" class="sidebar-link">Hive如何才能将结构化数据映射成为表？</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#使用hive进行小数据分析如何" class="sidebar-link">使用Hive进行小数据分析如何？</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-ddl-概述" class="sidebar-link">Hive DDL 概述</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#ddl-语法的作用" class="sidebar-link">DDL 语法的作用</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-中的-ddl-使用" class="sidebar-link">Hive 中的 DDL 使用</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-ddl-建表基础" class="sidebar-link">Hive DDL 建表基础</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#完整的建表语法树" class="sidebar-link">完整的建表语法树</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-数据类型详解" class="sidebar-link">Hive 数据类型详解</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-读写文件机制" class="sidebar-link">Hive 读写文件机制</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive数据存储路径" class="sidebar-link">Hive数据存储路径</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#案例-数据hive建表映射" class="sidebar-link">案例-数据Hive建表映射</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-ddl-建表高级" class="sidebar-link">Hive DDL 建表高级</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-内、外部表" class="sidebar-link">Hive 内、外部表</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-分区表" class="sidebar-link">Hive 分区表</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-分桶表" class="sidebar-link">Hive 分桶表</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-事务表" class="sidebar-link">Hive 事务表</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-view-视图" class="sidebar-link">Hive View 视图</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive3-0-新特性-物化视图" class="sidebar-link">Hive3.0 新特性 - 物化视图</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-ddl-其它语法" class="sidebar-link">Hive DDL 其它语法</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#database-schema-数据库-ddl操作" class="sidebar-link">Database|Schema （数据库）DDL操作</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#table-表-ddl操作" class="sidebar-link">Table（表）DDL操作</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#partition-分区-ddl操作" class="sidebar-link">Partition（分区）DDL操作</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-show-显示语法" class="sidebar-link">Hive Show 显示语法</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#整体概述-5" class="sidebar-link">整体概述</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#常用语句" class="sidebar-link">常用语句</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-dml-load-加载数据" class="sidebar-link">Hive DML Load 加载数据</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#背景" class="sidebar-link">背景</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#load-语法" class="sidebar-link">Load 语法</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#案例-load-data-from-local-fs-or-hdfs" class="sidebar-link">案例 - Load Data From Local FS or HDFS</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive3-0-load新特性" class="sidebar-link">Hive3.0 Load新特性</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-dml-insert-插入数据" class="sidebar-link">Hive DML Insert 插入数据</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#背景-2" class="sidebar-link">背景</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#insert-select" class="sidebar-link">insert + select</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#multiple-inserts-多重插入" class="sidebar-link">multiple inserts 多重插入</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#dynamic-partition-insert-动态分区插入" class="sidebar-link">dynamic partition insert 动态分区插入</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#insert-directory-导出数据" class="sidebar-link">insert + directory 导出数据</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-dml-update、delete-更新删除数据" class="sidebar-link">Hive DML Update、Delete 更新删除数据</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#update-操作" class="sidebar-link">update 操作</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#delete-操作" class="sidebar-link">delete 操作</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-dql-select-查询数据" class="sidebar-link">Hive DQL Select 查询数据</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#数据环境准备" class="sidebar-link">数据环境准备</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#语法树" class="sidebar-link">语法树</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#基础查询" class="sidebar-link">基础查询</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#高阶查询" class="sidebar-link">高阶查询</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#join-连接查询" class="sidebar-link">join 连接查询</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-内置运算符" class="sidebar-link">Hive 内置运算符</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#概述" class="sidebar-link">概述</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#关系运算符" class="sidebar-link">关系运算符</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#算术运算符" class="sidebar-link">算术运算符</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#逻辑运算符" class="sidebar-link">逻辑运算符</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-函数入门" class="sidebar-link">Hive 函数入门</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#概述-2" class="sidebar-link">概述</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#分类标准" class="sidebar-link">分类标准</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#内置函数分类" class="sidebar-link">内置函数分类</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#用户自定义函数分类" class="sidebar-link">用户自定义函数分类</a></li></ul></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#hive-高阶函数" class="sidebar-link">Hive 高阶函数</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#udtf之explode函数" class="sidebar-link">UDTF之explode函数</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#lateral-view-侧视图" class="sidebar-link">Lateral View 侧视图</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#aggregation-聚合函数" class="sidebar-link">Aggregation 聚合函数</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#window-functions-窗口函数" class="sidebar-link">Window functions 窗口函数</a></li><li class="sidebar-sub-header"><a href="/study/da-shu-ju/hive.html#sampling-抽样函数" class="sidebar-link">Sampling 抽样函数</a></li></ul></li></ul></li><li><a href="/study/da-shu-ju/hue.html" class="sidebar-link">Hue</a></li><li><a href="/study/da-shu-ju/oozie.html" class="sidebar-link">Oozie</a></li><li><a href="/study/da-shu-ju/sqoop.html" class="sidebar-link">Sqoop</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>总结</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>技术方案</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>数据结构和算法</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>消息队列</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="hive"><a href="#hive" class="header-anchor">#</a> Hive</h1> <h2 id="什么是数仓"><a href="#什么是数仓" class="header-anchor">#</a> 什么是数仓</h2> <h3 id="基本概念"><a href="#基本概念" class="header-anchor">#</a> 基本概念</h3> <p>数据仓库（英文：Data Warehouse，简称 DW 或 DWH），是一个用于存储、分析、报告的数据系统。</p> <p>数据仓库的目的是构建<strong>面向分析</strong>的集成化数据环境，为企业提供决策支持（Decision Support）。</p> <p><img src="/study/assets/img/image-20210814215649241.00c69c3b.png" alt="image-20210814215649241"></p> <p>数据仓库<strong>本身并不 &quot;生产&quot; 任何数据</strong>，其数据来源于不同的外部系统。</p> <p>同时数据仓库自身也<strong>不需要 &quot;消费&quot; 任何数据</strong>，其结果开放给各个外部应用系统使用。</p> <p>这也是为什么叫 &quot;仓库&quot;, 而不叫 &quot;工厂&quot; 的原因。</p> <p><img src="/study/assets/img/image-20210814220235191.bf7032ea.png" alt="image-20210814220235191"></p> <h3 id="数仓为何而来"><a href="#数仓为何而来" class="header-anchor">#</a> 数仓为何而来</h3> <p>先下结论：<strong>为了分析数据而来</strong>，分析结果为企业决策提供支撑。</p> <p>企业中，信息总是用作两个目的：</p> <p>1）操作型记录的保存</p> <p>2）分析型决策的制定</p> <p>以下一中国人寿保险公司（chinalife）发展为例，阐述数据仓库为何而来？</p> <p><strong>操作型记录的保存</strong></p> <ul><li><p>中国人寿保险（集团）公司下多条业务线，包括：人寿险、财险、车险、养老险等。各个线的业务正常运营需要记录维护包括客户、保单、收付费、核保、理赔等信息。</p></li> <li><p>**联机事务处理系统（OLTP）**正好可以满足上述业务需求开展，其主要任务是执行联机事务处理。其基本特征是前台接收用户数据可以立即传送给后台进行处理，并在很短时间内给出处理结果。</p> <p><img src="/study/assets/img/image-20210814221217249.36d54a85.png" alt="image-20210814221217249"></p></li> <li><p><strong>关系型数据库（RDBMS）就是OLTP典型应用</strong>，比如：Oracle、MySQL、SQL Server等。</p> <p><img src="/study/assets/img/image-20210814221338831.32c2bdd0.png" alt="image-20210814221338831"></p></li></ul> <p><strong>分析型决策的制定</strong></p> <ul><li><p>随着集团业务的持续运营，业务数据将会越来越多。由此也产生出许多运营相关的困惑：</p> <ul><li><p>能够确定哪些险种正在恶化或已成为不良险种？</p></li> <li><p>能够用有效的方式制定新增和续保的政策吗？</p></li> <li><p>理赔过程有欺诈的可能吗？我们是否有欺诈识别能力？</p></li> <li><p>现在得到的报表是否只是某业务线的？集团整体侧面数据如何？</p> <p>...</p></li></ul></li> <li><p>为了能够正确认识这些问题，制定相关的解决措施，瞎拍桌子肯定是不行的。</p></li> <li><p>最稳妥的办法就是：**基于业务数据开展数据分析，基于分析的结果给决策提供支撑。**也就是所谓的数据驱动决策的制定。</p> <p><img src="/study/assets/img/image-20210814221946683.c66a320e.png" alt="image-20210814221946683"></p> <blockquote><p>问题：在哪里进行数据分析？数据库可以吗？</p></blockquote> <p><strong>OLTP环境开展分析可行吗？</strong></p> <p>可以，但是没必要</p> <p>OLTP系统的核心是面向业务，支持业务，支持事务。所有的业务操作而言分为读、写两种操作，一般来说<strong>读的压力明显大于写的压力</strong>。如果在OLTP环境直接开展各种分析，有以下问题需要考虑：</p> <p>1）数据分析也是对数据进行读取操作，会让读取压力倍增；</p> <p>2）OLTP仅存储数周或数月的数据；</p> <p>3）数据分散存储在不同的表中，字段类型属性不统一；</p> <p>当分析所涉及数据规模较小的时候，在业务低峰期可以在OLTP系统上开展直接分析。但是<strong>为了更好的进行各种规模的数据分析，同时也不影响OLTP系统运行，此时需要构建一个集成统一的数据分析平台。</strong></p> <p>该平台的目的很简单：<strong>面向分析，支持分析，<strong>并且和OLTP系统</strong>解耦合</strong>。</p> <p>基于这种需求，数据仓库的雏形开始在企业中出现了。</p></li></ul> <h3 id="数仓的创建"><a href="#数仓的创建" class="header-anchor">#</a> 数仓的创建</h3> <p>如数仓定义所说，数仓是一个用于存储、分析、报告的数据系统，目的是构建面向分析的集成化数据环境。我们把这种<strong>面向分析、支持分析</strong>的系统称之为 <strong>OLAP （联机分析处理）系统</strong>。数据仓库就是OLAP的一种。</p> <p>中国人寿保险公司就是基于分析决策的需求，构建数仓平台。</p> <p><img src="/study/assets/img/image-20210814224140151.d4704bdd.png" alt="image-20210814224140151"></p> <h3 id="主要特征"><a href="#主要特征" class="header-anchor">#</a> 主要特征</h3> <p><img src="/study/assets/img/image-20210814224746581.f73c3c0f.png" alt="image-20210814224746581"></p> <ul><li><p><strong>面向主题性（Subject-Oriented）</strong></p> <ul><li><p>数据库中，最大的特点是<strong>面向应用</strong>进行数据的组织，各个业务系统可能是相互分离的。</p></li> <li><p>而<strong>数据仓库则是面向主题的</strong>。主题是一个抽象的概念，是较高层次上企业信息系统中的<strong>数据综合</strong>、<strong>归类</strong>并进行分析利用的抽象。在逻辑意义上，它是对企业中某一宏观分析领域所涉及的分析对象。</p></li> <li><p>操作行处理（传统数据）对数据的划分并不适用于决策分析。而基于主题组织的数据则不同，它们被划分为各自独立的领域，各个领域有各自的逻辑内涵但互不交叉，在<strong>抽象层次上对数据进行完整、一致和准确的描述</strong>。</p> <p><img src="/study/assets/img/image-20210814225358751.b4b01449.png" alt="image-20210814225358751"></p></li></ul></li> <li><p><strong>集成性（Integrated）</strong></p> <ul><li><p>确定主题之后，就需要获取和主题相关的数据。当下企业中主题相关的<strong>数据通常会分布在多个操作系统中，彼此分散、独立、异构</strong>。</p></li> <li><p>因此在数据进入数据仓库之前，必然要经过<strong>统一与综合，对数据进行抽取、清洗、转换和汇总</strong>，这一步是数据仓库建设中最关键、最复杂的一步，所要完成的工作有：</p> <p>1）要统一源数据中所有矛盾之处，如字段同名异义、异名同义、单位不统一、字长不统一，等等。</p> <p>2）进行数据综合和计算。数据仓库中的数据综合工作可以在从原有数据库抽取数据时生成，但许多是在数据仓库内部生成的，即进入数据仓库以后进行综合生成的。</p> <blockquote><p>一句话总结来说：不论数据来源于哪里，只要它属于同一个主题，我就要把它集中到一起，且保障它们之间格式统一干净规整。</p></blockquote> <p>下图说明了保险公司综合数据的简单处理过程，其中数据仓库中与 &quot;承保&quot; 主题有关的数据来自于不同操作性系统。这些系统内部数据命名可能不同，数据格式也可能不同。把不同来源的数据存储到数据仓库之前，需要去除这些不一致。</p></li></ul> <p><img src="/study/assets/img/image-20210814230700137.8e9d61cc.png" alt="image-20210814230700137"></p></li> <li><p><strong>非易失性、非异变性（Non-Volatile）</strong></p> <ul><li><strong>数据仓库是分析数据的平台，而不是创造数据的平台</strong>。我们通过数仓去分析数据中的规律，而不是去创造修改其中的规律。因此数据进入数据仓库后，它便稳定且不会改变。</li> <li>操作性数据库主要服务于日常的业务操作，使得数据库需要不断对数据进行实时更新，以便迅速获取当前最新数据，不至于影响业务正常的运作。在数仓中只要保存过去的业务数据，不需要每一笔业务都实时更新数据仓库，而是根据商业需要每隔一段时间把一批相对较新的数据导入到数据仓库。</li> <li><strong>数据仓库的数据反映的是一段相对长时间内历史数据的内容</strong>，而不同时间点数据库快照的集合，以及基于这些数据快照进行统计、综合和重组的导出数据。</li> <li>数据仓库的用户对数据的操作大多是数据查询或者比较复杂的挖掘，一旦数据进入数仓以后，一般情况下被较长时间保留。<strong>数据仓库一般有大量的查询操作，但修改和删除操作很少。</strong></li></ul></li> <li><p><strong>时变性（Time-Variant）</strong></p> <ul><li><p>数据仓库包括各种粒度的历史数据，数据可能与某个特定日期、星期、月份、季度或年份有关。</p></li> <li><p>虽然数据仓库的用户不能修改数据，但并不是说数仓的数据就永远不变的。分析的结果只能反应过去的情况，当业务变化后，挖掘出的模式会失去时效性。因此数仓的数据<strong>需要随着时间更新，以适应决策的需要</strong>。从这个角度讲，数仓建设是一个项目，更是一个过程。</p></li> <li><p>数据仓库的数据随时间的变化表现在一下几个方面：</p> <p>1）数据仓库的数据时限一般要远远长于操作型数据的数据时限；</p> <p>2）操作型系统存储的是当前数据，而数据仓库存储的是历史数据；</p> <p>3）数据仓库中数据是按照时间顺序追加的，它们都带有时间属性。</p></li></ul></li></ul> <h3 id="oltp、olap"><a href="#oltp、olap" class="header-anchor">#</a> OLTP、OLAP</h3> <ul><li><p>联机<strong>事务</strong>处理 OLTP （On-Line <strong>Transaction</strong> Processing）</p> <ul><li><p>操作性处理，叫联机事务处理 OLTP （On-Line <strong>Transaction</strong> Processing），主要目标是做数据处理，它是针对具体业务在数据库联机的日常操作，通常对少数记录进行查询、修改。</p></li> <li><p>用户较为关心操作的响应时间、数据的安全性、完整性和并发支持用户数等问题。</p></li> <li><p>传统的<strong>关系型数据库系统（RDBMS）作为数据管理的主要手段，主要用于操作型处理。</strong></p> <p><img src="/study/assets/img/image-20210814233109413.57c28a55.png" alt="image-20210814233109413"></p></li></ul></li> <li><p>联机<strong>分析</strong>处理 OLAP（On-Line Analytical Processing)</p> <ul><li>分析型处理，叫联机分析处理 OLAP（On-Line <strong>Analytical</strong> Processing），主要目标是做数据分析。</li> <li>一般针对某些主题的历史数据进行复杂的多维分析，支持管理决策。</li> <li><strong>数据仓库是 OLAP 系统的一个典型示例</strong>，主要用于数据分析。<img src="/study/assets/img/image-20210814233356949.4acd7430.png" alt="image-20210814233356949"></li></ul></li> <li><p>对比</p> <p><img src="/study/assets/img/image-20210814233507062.e36c28e4.png" alt="image-20210814233507062"></p></li></ul> <h3 id="数据库与数据仓库的区别"><a href="#数据库与数据仓库的区别" class="header-anchor">#</a> 数据库与数据仓库的区别</h3> <p>数据库与数据仓库的区别实际讲的是 OLTP 与 OLAP 的区别。</p> <p>OLTP系统的典型应用就是 RDBMS，也就是我们俗称的数据库，当然这里要特别强调此数据库表的是关系型数据库，NoSQL数据库并不在讨论范围内。</p> <p>OLAP 系统的典型应用就是 DW，也就是我们俗称的数据仓库。</p> <p><strong>结论：</strong></p> <ul><li>数据仓库不是大型的数据库，虽然数据仓库存储的数据规模很大。</li> <li>数据仓库的出现，并不是为了取代数据库。</li> <li>数据库是面向事务的设计，数据仓库是面向主题设计的。</li> <li>数据库一般存储业务数据，数据仓库存储的一般是历史数据。</li> <li>数据库是为了<strong>捕获数据</strong>而设计，数据仓库是为了<strong>分析数据</strong>而设计。</li></ul> <h3 id="数据仓库、数据集市"><a href="#数据仓库、数据集市" class="header-anchor">#</a> 数据仓库、数据集市</h3> <p>数据仓库（Data Warehouse）是面向<strong>整个集团</strong>组织的数据，数据集市（Data Mart）是面向<strong>某个部门</strong>使用的。</p> <p>可以认为数据集市是数据仓库的子集，也有人把<strong>数据集市叫做小型数据仓库</strong>。数据集市通常只涉及一个主题领域，例如市场营销或销售。因此它们较小且更具体，所以它们通常更容易管理和维护，并具有更灵活的结构。</p> <p>下图中，各种操作型系统数据和包括文件在内的等其他数据作为数据源，经过ETL（抽取转加载）填充到数据仓库中；数据仓库中有不同主题数据，数据集市则根据部门特点面向指定主题，比如Purchasing（采购）、Sales（销售）、Inventory（库存）；</p> <p>用户可以根据主题数据开展各种应用：数据分析、数据报表、数据挖掘。</p> <p><img src="/study/assets/img/image-20210814235634216.82e74b38.png" alt="image-20210814235634216"></p> <h3 id="数仓的分层架构"><a href="#数仓的分层架构" class="header-anchor">#</a> 数仓的分层架构</h3> <h4 id="分层思想和标准"><a href="#分层思想和标准" class="header-anchor">#</a> 分层思想和标准</h4> <p>数据仓库的特点是本身不生产数据，也不最终消费数据。按照数据流入流出数仓的过程进行分层就显得水到渠成。</p> <p>每个企业根据自己的业务需求可以分成不同的层次。但是最基础的分层思想，理论上可分为三个层级：操作型数据层（<strong>ODS</strong>）、数据仓库层（<strong>DW</strong>）和数据应用层（<strong>DA</strong>）。</p> <p>企业在实际运行中可以基于这个基础分层之上添加新的层次，来满足不同的业务需求。</p> <p><img src="/study/assets/img/image-20210815170416173.a0eb00f2.png" alt="image-20210815170416173"></p> <h4 id="阿里巴巴数仓3层架构"><a href="#阿里巴巴数仓3层架构" class="header-anchor">#</a> 阿里巴巴数仓3层架构</h4> <p>为了更好的理解数据仓库和分层的思想以及每层的功能意义，下面结合阿里巴巴提供出的数仓分层架构图进行分析。</p> <p>阿里数仓是非常经典的3层架构，从下往上依次是：<strong>ODS、DW、DA</strong>。</p> <p>通过元数据管理和数据质量监控来把控整个数仓中数据的流转过程、血缘依赖关系和生命周期。</p> <p><img src="/study/assets/img/image-20210815173137434.a0850e8e.png" alt="image-20210815173137434"></p> <p>数据仓库的数据来源于不同的源数据，并提供多样的数据应用，数据自下而上流入数据仓库后向上层开放应用，而数据仓库只是中间集成化数据管理的一个平台。</p> <ul><li><p><strong>ODS层（Operation Data Store）操作型数据层</strong>，也称之为源数据层、数据引入层、数据暂存层、临时缓存层</p> <p>此层数据无任何更改，直接沿用外围系统数据结构和数据，不对外开放；为临时存储层，是接口数据的临时存储区域，为后一步的数据处理做准备。 <strong>主要完成基础数据引入到数仓的职责，和数据源系统进行解耦合，同时记录基础数据的历史变化。</strong></p></li> <li><p><strong>DW层（Data Warehouse）数据仓库层</strong> ：也称为细节层，DW层的数据应该是一致的、准确的、干净的数据，即对源系统数据进行了清洗（去除了杂质）后的数据。 主要完成了数据的数据的<strong>加工与整合</strong>，建立一致性的维度，构建<strong>可复用的面向分析和统计的明细实时表</strong>，以及汇总公共粒度的指标。内部具体划分如下：</p> <ul><li>公共维度层（DIM）：基于维度建模理念思想，建立整个企业的一致性维度。</li> <li>公共汇总粒度事实层（DWS、DWB）：已分析的主题对象作为建模驱动，基于上层的应用和产品的指标要求，构建公共粒度的汇总指标事实表，以宽表化手段物理化模型。</li> <li>明细粒度事实表（DWD）：将明细事实表的某些重要维度属性字段做适当冗余，即宽表化处理。</li></ul></li> <li><p>DA层或ADS层，数据应用层 ，面向最终用户，面向业务定制提供为产品和数据分析使用的数据。包括前端报表、分析图标、KPI、仪表盘、OLAT专题、数据挖掘等分析。</p></li></ul> <h4 id="为什么要对数据仓库分层"><a href="#为什么要对数据仓库分层" class="header-anchor">#</a> 为什么要对数据仓库分层？</h4> <p><strong>好处</strong></p> <p>分层的主要原因是在管理数据的时候，能对数据有一个更加清晰的掌控，详细来讲，主要有下面几个原因：</p> <ul><li><strong>清晰数据结构</strong>
每一个数据分层都有它的作用域，在使用表的时候能更方便地定位和理解。</li> <li>数据血缘追踪
简单来说，我们最终给业务呈现的是一个能直接使用业务表，但是它的来源有很多，如果有一张来源表出问题了，我们希望能够快速准确地定位到问题，并清楚它的危害范围。</li> <li><strong>减少重复开发</strong>
规范数据分层，开发一些通用的中间层数据，能够减少极大的重复计算。</li> <li><strong>把复杂问题简单化</strong>
将一个复杂的任务分解成多个步骤来完成，每一层只处理单一的步骤，比较简单和容易理解。而且便于维护数据的准确性，当数据出现问题之后，可以不用修复所有的数据，只需要从有问题的步骤开始修复。</li> <li><strong>屏蔽原始数据的异常</strong>
屏蔽业务的影响，不必改一次业务就需要重新接入数据</li></ul> <h4 id="etl-和-elt"><a href="#etl-和-elt" class="header-anchor">#</a> ETL 和 ELT</h4> <p>数据仓库<strong>从各数据源获取数据及在数据仓库内的数据转换和流动</strong>都可以认为是ETL（抽取Extra, 转化Transfer, 装载Load）的过程。但是在实际操作中将数据加载到仓库却产生了两种不同做法：ETL和ELT。</p> <ul><li><p><strong>Extract，Transform，Load，ETL</strong></p> <p>首先从数据源池中提取数据，这些数据源通常是事务性数据库。数据保存在临时暂存数据库中。然后执行转换操作，将数据结构化并转换为适合目标数据仓库系统的形式。然后将结构化数据加载到仓库中，以备分析。</p> <p><img src="/study/assets/img/image-20210815210141921.73545191.png" alt="image-20210815210141921"></p></li> <li><p><strong>Extract，Load，Transform ，ELT</strong></p> <p>使用ELT，数据在从源数据池中提取后立即加载。没有临时数据库，这意味着数据会立即加载到单一的集中存储库中。数据在数据仓库系统中进行转换，以便与商业智能工具和分析一起使用。<strong>大数据时代的数仓这个特点很明显。</strong></p> <p><img src="/study/assets/img/image-20210815210155155.4c4142d8.png" alt="image-20210815210155155"></p></li></ul> <h3 id="案例"><a href="#案例" class="header-anchor">#</a> 案例</h3> <blockquote><p><strong>场景分析</strong>：美团点评酒旅数仓建设实践</p></blockquote> <p>下面通过一线互联网企业真实的数仓建设实践案例，来从宏观层面感受以下几点：</p> <ul><li>数仓面向主题分析的特点</li> <li>在企业中数仓是一个不断维护的工程</li> <li>数仓分层并不局限于经典3层，可以根据自身需求进行调整</li> <li>没有好的架构，只有适合自己业务需求的架构</li> <li>它山之石可以攻玉</li></ul> <h4 id="架构变迁"><a href="#架构变迁" class="header-anchor">#</a> 架构变迁</h4> <p>在美团点评酒旅事业群内，业务由<strong>传统的团购</strong>形式转向<strong>预订</strong>、<strong>直连</strong>等更加丰富的产品形式，业务系统也在迅速的迭代变化，这些都对数据仓库的扩展性、稳定性、易用性提出了更高要求。</p> <p>基于此，美团采取了分层次、分主题的方式不断优化并调整层次结构，下图展示了技术架构的变迁。</p> <p><img src="/study/assets/img/image-20210815212809155.55425450.png" alt="image-20210815212809155"></p> <p><strong>第一代</strong>数仓模型层次中，由于当时美团整体的业务系统所支持的产品形式比较单一（团购），业务系统中包含了所有业务品类的数据，所以由平台的角色来加工数据仓库基础层是非常合适的，平台统一建设，支持各个业务线使用，所以在本阶段中酒旅只是建立了一个相对比较简单的<strong>数据集市</strong>。</p> <p><strong>第二代</strong>数仓模型层次的建设，由建设<strong>数据集市</strong>的形式转变成了<strong>直接建设酒旅数据仓库</strong>，成为了酒旅自身业务系统数据的唯一加工者。</p> <p>随着美团和点评融合，同时酒旅自身的业务系统重构的频率也相对较高，对第二代数仓模型稳定性造成了非常大的影响，原本的维度模型非常难适配这么迅速的变化。核心问题是在用业务系统和业务线关系错综复杂，业务系统之间差异性明显且变更频繁。</p> <p><img src="/study/assets/img/image-20210815213108300.97ad40c6.png" alt="image-20210815213108300"></p> <p>于是在<strong>第三代</strong>ODS与多维明细层中间加入了<strong>数据整合层</strong>，参照Bill Inmon所提出的企业信息工厂建设的模式，基本按照三范式的原则来进行数据整合，由业务驱动调整成了由技术驱动的方式来建设数据仓库基础层。</p> <p>使用本基础层的最根本出发点还是在于美团的供应链、业务、数据它们本身的多样性，如果业务、数据相对比较单一、简单，本层次的架构方案很可能将不再适用。</p> <p><img src="/study/assets/img/image-20210815213225816.55740ebc.png" alt="image-20210815213225816"></p> <h4 id="主题建设"><a href="#主题建设" class="header-anchor">#</a> 主题建设</h4> <p>实际上在传统的一些如银行、制造业、电信、零售等行业里，都有一些比较成熟的模型，如耳熟能详的BDWM模型，它们都是经过一些具有相类似行业的企业在二三十年数据仓库建设中所积累的行业经验，不断的优化并通用化。</p> <p>但美团所处的O2O行业本身就没有可借鉴的成熟的数据仓库主题以及模型，所以，在摸索建设两年的时间里，美团总结了下面比较适合现状的七大主题（后续可能还会新增）</p> <p><img src="/study/assets/img/image-20210815213459111.55bab6ab.png" alt="image-20210815213459111"></p> <h4 id="整体架构"><a href="#整体架构" class="header-anchor">#</a> 整体架构</h4> <p>确定好技术和业务主题之后，数仓的整体架构就比较清晰了。美团酒旅数仓七个主题基本上都采用6层结构的方式来建设，划分<strong>主题</strong>更多是从<strong>业务的角度</strong>出发，而<strong>层次</strong>划分则是基于技术，<strong>实质上就是基于业务与技术的结合完成了整体的数据仓库架构</strong>。</p> <p><img src="/study/assets/img/image-20210815213645894.26ae32a4.png" alt="image-20210815213645894"></p> <p>比如，以订单主题为例。在订单主题的建设过程中，美团是按照<strong>由分到总的结构思路来进行建设</strong>，首先分供应链建设订单相关实体（数据整合中间层3NF），然后再进行适度抽象把分供应链的相关订单实体进行合并后生成订单实体（数据整合层3NF），后续在数据整合层的订单实体基础上再扩展部分维度信息来完成后续层次的建设。</p> <p><img src="/study/assets/img/image-20210815213744652.73ad2937.png" alt="image-20210815213744652"></p> <h2 id="hive-的基本概念"><a href="#hive-的基本概念" class="header-anchor">#</a> <strong>Hive</strong> 的基本概念</h2> <h3 id="hive-简介"><a href="#hive-简介" class="header-anchor">#</a> Hive 简介</h3> <h4 id="什么是-hive"><a href="#什么是-hive" class="header-anchor">#</a> 什么是 <strong>Hive</strong> ？</h4> <p>Apache Hive是一款建立在Hadoop之上的开源<strong>数据仓库系统</strong>，可以将存储在Hadoop文件中的结构化、半结构化数据文件<strong>映射</strong>为一张数据库表，基于表提供了一种类似SQL的查询模型，称为Hive查询语言（HQL），用于访问和分析存储在Hadoop文件中的大型数据集。</p> <p>Hive核心是将<strong>HQL转换为MapReduce</strong>程序，然后将程序提交到Hadoop群集执行。Hive由Facebook实现并开源。</p> <p><img src="/study/assets/img/image-20210815214132169.9b34c6f7.png" alt="image-20210815214132169"></p> <h4 id="为什么使用-hive"><a href="#为什么使用-hive" class="header-anchor">#</a> 为什么使用 Hive ？</h4> <ul><li><p>使用Hadoop MapReduce直接处理数据所面临的问题</p></li> <li><p>人员学习成本太高</p></li> <li><p>项目周期要求太短</p></li> <li><p>MapReduce实现复杂查询逻辑开发难度太大</p></li> <li><p>使用Hive处理数据的好处</p> <ul><li>操作接口采用类SQL语法，提供快速开发的能力（简单、容易上手）</li> <li>避免了去写MapReduce，减少开发人员的学习成本</li> <li>支持自定义函数，功能扩展很方便</li> <li>背靠Hadoop，擅长存储分析海量数据集</li></ul></li></ul> <h4 id="hive与hadoop的关系"><a href="#hive与hadoop的关系" class="header-anchor">#</a> Hive与Hadoop的关系</h4> <p>从功能来说，数据仓库软件，至少需要具备下述两种能力：</p> <ul><li><p>存储数据的能力</p></li> <li><p>分析数据的能力</p></li></ul> <p>Apache Hive作为一款大数据时代的数据仓库软件，当然也具备上述两种能力。只不过Hive并不是自己实现了上述两种能力，而是借助Hadoop。</p> <p><strong>Hive利用HDFS存储数据，利用MapReduce查询分析数据。</strong></p> <p>这样突然发现Hive没啥用，不过是套壳Hadoop罢了。其实不然，Hive的最大的魅力在于用户专注于编写HQL，Hive帮您转换成为MapReduce程序完成对数据的分析。</p> <p><img src="/study/assets/img/image-20210815214526859.85946889.png" alt="image-20210815214526859"></p> <h3 id="案例-2"><a href="#案例-2" class="header-anchor">#</a> 案例</h3> <h4 id="场景设计"><a href="#场景设计" class="header-anchor">#</a> 场景设计</h4> <blockquote><p>如何模拟实现 Hive 的功能</p></blockquote> <p>如果让您设计Hive这款软件，要求能够实现<strong>用户编写sql语句，Hive自动将sql转换MapReduce程序，处理位于HDFS上的结构化数据</strong>。如何实现？</p> <p>在HDFS文件系统上有一个文件，路径为/data/china_user.txt，其内容如下：</p> <div class="language-txt extra-class"><pre class="language-text"><code>1,zhangsan,18,beijing
2,lisi,25,shanghai
3,allen,30,shanghai
4,wangwu,15,nanjing
5,james,45,hangzhou
6,tony,26,beijing
</code></pre></div><h4 id="需求"><a href="#需求" class="header-anchor">#</a> 需求</h4> <blockquote><p>统计来自于上海年龄大于25岁的用户有多少个？</p></blockquote> <h4 id="场景目的"><a href="#场景目的" class="header-anchor">#</a> 场景目的</h4> <p>重点理解下面两点</p> <ul><li><p>Hive能将数据文件映射成为一张表，这个<strong>映射是指什么</strong>？</p></li> <li><p>Hive软件本身到底承担了什么功能职责？</p></li></ul> <p><strong>映射信息记录</strong></p> <p><strong>映射</strong>在数学上称之为一种<strong>对应关系</strong>，比如y=x+1，对于每一个x的值都有与之对应的y的值。</p> <p>在hive中能够写sql处理的前提是针对表，而不是针对文件，因此需要<strong>将文件和表之间的对应关系</strong>描述记录清楚。映射信息专业的叫法称之为<strong>元数据信息</strong>（元数据是指用来描述数据的数据 metadata）。</p> <p><img src="/study/assets/img/image-20210815215645873.a74197fb.png" alt="image-20210815215645873"></p> <p>具体来看，要记录的元数据信息包括：</p> <ul><li>表对应着哪个文件（位置信息）</li> <li>表的列对应着文件哪一个字段（顺序信息）</li> <li>文件字段之间的分隔符是什么</li></ul> <p><strong>SQL语法解析、编译</strong></p> <p>用户写完sql之后，hive需要针对sql进行语法校验，并且根据记录的元数据信息解读sql背后的含义，制定执行计划。并且把执行计划转换成MapReduce程序来执行，把执行的结果封装返回给用户。</p> <blockquote><p><strong>结论：</strong></p> <p><strong>Hive能将数据文件映射成为一张表，这个映射是指什么?</strong></p> <p>答：文件和表之间的对应关系</p> <p><strong>Hive软件本身到底承担了什么功能职责？</strong></p> <p>答：SQL语法解析编译成为MapReduce</p></blockquote> <h4 id="最终效果"><a href="#最终效果" class="header-anchor">#</a> 最终效果</h4> <p>基于上述分析，最终要想模拟实现的Hive的功能，大致需要下图所示组件参与其中。</p> <p>从中可以感受一下Hive承担了什么职责，当然，也可以把这个理解为Hive的架构图。</p> <p><img src="/study/assets/img/image-20210815220538670.290ecab3.png" alt="image-20210815220538670"></p> <h3 id="hive-架构"><a href="#hive-架构" class="header-anchor">#</a> Hive 架构</h3> <p><img src="/study/assets/img/image-20210815221201401.f581014b.png" alt="image-20210815221201401"></p> <ul><li><strong>用户接口</strong>： 包括CLI、JDBC/ODBC。其中，CLI(command line interface)为shell命令行；JDBC/ODBC是Hive的JAVA实现，与传统数据库JDBC类似；</li> <li><strong>元数据存储</strong>： 通常是存储在关系数据库如mysql/derby中。Hive 将元数据存储在数据库中。Hive中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。</li> <li><strong>Driver 驱动程序，包括解释器、编译器、优化器、执行器</strong>：完成HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在HDFS 中，并在随后有MapReduce 调用执行。</li> <li><strong>执行引擎</strong>：Hive本身并不直接处理数据文件。而是通过执行引擎处理。3.x Hive支持MapReduce、Tez、Spark3种执行引擎。</li></ul> <p><strong>工作原理</strong>：</p> <ol><li><p>用户创建数据库、表信息，存储在hive的元数据库中；</p></li> <li><p>向表中加载数据，元数据记录hdfs文件路径与表之间的映射关系；</p></li> <li><p>执行查询语句，首先经过解析器、编译器、优化器、执行器，将指令翻译成MapReduce，提交到Yarn上执行，最后将执行返回的结果输出到用户交互接口。</p></li></ol> <h3 id="hive-数据模型"><a href="#hive-数据模型" class="header-anchor">#</a> Hive 数据模型</h3> <h4 id="data-model概念"><a href="#data-model概念" class="header-anchor">#</a> Data Model概念</h4> <p>数据模型：用来描述数据、组织数据和对数据进行操作，是对现实世界数据特征的描述。</p> <p>Hive的数据模型<strong>类似于RDBMS库表结构</strong>，此外还有<strong>自己特有模型</strong>。</p> <p>Hive中的数据可以在粒度级别上分为三类：</p> <ul><li>Table 表</li> <li>Partition 分区</li> <li>Bucket 分桶</li></ul> <p><img src="/study/assets/img/image-20210815222143807.c0211c85.png" alt="image-20210815222143807"></p> <h4 id="databases-数据库"><a href="#databases-数据库" class="header-anchor">#</a> Databases 数据库</h4> <p>Hive作为一个数据仓库，在结构上积极向传统数据库看齐，也分数据库（Schema），每个数据库下面有各自的表组成。默认<strong>数据库default</strong>。</p> <p>Hive的数据都是<strong>存储在HDFS</strong>上的，默认有一个根目录，在 <code>hive-site.xml</code> 中，由参数 <code>hive.metastore.warehouse.dir</code> 指定。默认值为<code>/user/hive/warehouse</code>。</p> <p>因此，Hive中的数据库在HDFS上的存储路径为：</p> <div class="language- extra-class"><pre class="language-text"><code>${hive.metastore.warehouse.dir}/databasename.db
</code></pre></div><p>比如，名为test的数据库存储路径为：</p> <div class="language- extra-class"><pre class="language-text"><code>/user/hive/warehouse/test.db
</code></pre></div><h4 id="table-表"><a href="#table-表" class="header-anchor">#</a> Table 表</h4> <p>Hive表与关系数据库中的表相同。Hive中的表所对应的数据通常是存储在HDFS中，而表相关的元数据是存储在RDBMS中。</p> <p>Hive中的表的数据在HDFS上的存储路径为：</p> <div class="language- extra-class"><pre class="language-text"><code>${hive.metastore.warehouse.dir}/databasename.db/tablename
</code></pre></div><p>比如,test的数据库下t_user表存储路径为：</p> <div class="language- extra-class"><pre class="language-text"><code>/user/hive/warehouse/test.db/t_user
</code></pre></div><p><img src="/study/assets/img/image-20210815222636997.bc40f37a.png" alt="image-20210815222636997"></p> <h4 id="partitions-分区"><a href="#partitions-分区" class="header-anchor">#</a> Partitions 分区</h4> <p>Partition分区是hive的一种优化手段表。分区是指<strong>根据分区列（例如“日期day”）的值将表划分为不同分区</strong>。这样可以更快地对指定分区数据进行查询。</p> <p>分区在存储层面上的表现是:table表目录下以子文件夹形式存在。</p> <p><strong>一个文件夹表示一个分区</strong>。子文件命名标准：<strong>分区列=分区值</strong></p> <p>Hive还支持分区下继续创建分区，所谓的多重分区。关于分区表的使用和详细介绍，后面模块会单独展开。</p> <p><img src="/study/assets/img/image-20210815223050845.8912075d.png" alt="image-20210815223050845"></p> <h4 id="buckets-分桶"><a href="#buckets-分桶" class="header-anchor">#</a> Buckets 分桶</h4> <p>Bucket分桶表是hive的一种优化手段表。<strong>分桶是指根据表中字段（例如“编号ID”）的值,经过hash计算规则将数据文件划分成指定的若干个小文件</strong>。</p> <p><img src="/study/assets/img/image-20210815223207391.ac2b2b64.png" alt="image-20210815223207391"></p> <p>分桶规则：<strong>hashfunc(ID) % 桶个数</strong>，余数相同的分到同一个文件。</p> <p>分桶的好处是可以优化join查询和方便抽样查询。Bucket分桶表在hdfs中表现为同一个表目录下数据根据hash散列之后变成多个文件。关于桶表以及分桶操作，后面模块会单独展开详细讲解。</p> <p><img src="/study/assets/img/image-20210815223506676.a3518d75.png" alt="image-20210815223506676"></p> <h3 id="hive-与传统数据库对比"><a href="#hive-与传统数据库对比" class="header-anchor">#</a> **Hive **与传统数据库对比</h3> <blockquote><p>Hive 是要取代 MySQL吗？</p></blockquote> <p>Hive虽然具有RDBMS数据库的外表，包括数据模型、SQL语法都十分相似，但应用场景却完全不同。Hive只适合用来做海量数据的<strong>离线分析</strong>。Hive的定位是<strong>数据仓库</strong>，面向分析的<strong>OLAP系统</strong>。</p> <p>因此时刻告诉自己，<strong>Hive不是大型数据库，也不是要取代Mysql承担业务数据处理</strong>。</p> <p>更直观的对比请看下面这幅图：</p> <p><img src="/study/assets/img/image-20210815223641497.36ecbd6b.png" alt="image-20210815223641497"></p> <h3 id="hive-元数据"><a href="#hive-元数据" class="header-anchor">#</a> Hive 元数据</h3> <h4 id="什么是元数据"><a href="#什么是元数据" class="header-anchor">#</a> 什么是元数据</h4> <p>元数据（Metadata），又称中介数据、中继数据，为<strong>描述数据的数据</strong>（data about data），主要是描述数据属性（property）的信息，用来支持如指示存储位置、历史数据、资源查找、文件记录等功能。</p> <h4 id="hive-metadata"><a href="#hive-metadata" class="header-anchor">#</a> Hive Metadata</h4> <ul><li>Hive Metadata即Hive的元数据。</li> <li>包含用Hive创建的database、table、表的位置、类型、属性，字段顺序类型等元信息。</li> <li><strong>元数据存储在关系型数据库中</strong>。如hive内置的Derby、或者第三方如MySQL等。</li></ul> <h4 id="hive-metastore"><a href="#hive-metastore" class="header-anchor">#</a> Hive Metastore</h4> <ul><li>Metastore即<strong>元数据服务</strong>。Metastore服务的作用是<strong>管理metadata元数据</strong>，对外暴露服务地址，让各种客户端通过连接metastore服务，由metastore再去连接MySQL数据库来存取元数据。</li> <li>有了metastore服务，就可以有多个客户端同时连接，而且这些客户端不需要知道MySQL数据库的用户名和密码，只需要连接metastore 服务即可。某种程度上也保证了hive元数据的安全。</li></ul> <p><img src="/study/assets/img/image-20210815224352461.9f269748.png" alt="image-20210815224352461"></p> <h4 id="metastore配置方式"><a href="#metastore配置方式" class="header-anchor">#</a> Metastore配置方式</h4> <p>metastore服务配置有3种模式：<strong>内嵌模式、本地模式、远程模式。</strong></p> <p>区分3种配置方式的关键是弄清楚两个问题：</p> <ul><li>Metastore服务是否需要单独配置、单独启动？</li> <li>Metadata是存储在内置的derby中，还是第三方RDBMS,比如MySQL。</li></ul> <p><img src="/study/assets/img/image-20210815224610274.62def04c.png" alt="image-20210815224610274"></p> <blockquote><p>企业推荐模式--远程模式部署</p></blockquote> <h5 id="内嵌模式"><a href="#内嵌模式" class="header-anchor">#</a> 内嵌模式</h5> <p>内嵌模式（Embedded Metastore）是metastore<strong>默认部署模式</strong>。</p> <p>此种模式下，元数据存储在<strong>内置的Derby数据库</strong>，并且Derby数据库和metastore服务都嵌入在主HiveServer进程中，当启动HiveServer进程时，Derby和metastore都会启动。不需要额外起Metastore服务。</p> <p>但是一次只能支持一个活动用户，适用于<strong>测试体验</strong>，<strong>不适用于生产环境</strong>。</p> <p><img src="/study/assets/img/image-20210815224822050.54b609fa.png" alt="image-20210815224822050"></p> <h5 id="本地模式"><a href="#本地模式" class="header-anchor">#</a> 本地模式</h5> <p>本地模式（Local Metastore）下，<strong>Metastore服务与主HiveServer进程在同一进程</strong>中运行，但是存储元数据的数据库在单独的进程中运行，并且可以在单独的主机上。metastore服务将通过JDBC与metastore数据库进行通信。</p> <p>本地模式采用<strong>外部数据库</strong>来存储元数据，推荐使用MySQL。</p> <p>hive根据<code>hive.metastore.uris</code> 参数值来判断，如果为空，则为本地模式。</p> <p>缺点是：每启动一次hive服务，都内置启动了一个metastore。</p> <p><img src="/study/assets/img/image-20210815225012047.3491db77.png" alt="image-20210815225012047"></p> <h5 id="远程模式"><a href="#远程模式" class="header-anchor">#</a> 远程模式</h5> <p>远程模式（Remote Metastore）下，<strong>Metastore服务在其自己的单独JVM上运行</strong>，而不在HiveServer的JVM中运行。如果其他进程希望与Metastore服务器通信，则可以使用Thrift Network API进行通信。</p> <p>远程模式下，需要配置hive.metastore.uris 参数来指定metastore服务运行的机器ip和端口，并且<strong>需要单独手动启动metastore服务</strong>。元数据也采用外部数据库来存储元数据，推荐使用MySQL。</p> <p>在生产环境中，建议用远程模式来配置Hive Metastore。在这种情况下，其他依赖hive的软件都可以通过Metastore访问hive。由于还可以完全屏蔽数据库层，因此这也带来了更好的可管理性/安全性。</p> <p><img src="/study/assets/img/image-20210815225220374.9b62bdc2.png" alt="image-20210815225220374"></p> <h2 id="hive-安装和环境配置"><a href="#hive-安装和环境配置" class="header-anchor">#</a> Hive 安装和环境配置</h2> <h3 id="安装前准备"><a href="#安装前准备" class="header-anchor">#</a> 安装前准备</h3> <p>由于Apache Hive是一款基于Hadoop的数据仓库软件，通常部署运行在Linux系统之上。因此不管使用何种方式配置Hive Metastore，必须要先保证服务器的基础环境正常，Hadoop集群健康可用。</p> <h4 id="服务器基础环境"><a href="#服务器基础环境" class="header-anchor">#</a> 服务器基础环境</h4> <p>集群时间同步、防火墙关闭、主机Host映射、免密登录、JDK安装</p> <h4 id="hadoop集群健康可用"><a href="#hadoop集群健康可用" class="header-anchor">#</a> Hadoop集群健康可用</h4> <p>启动Hive之前必须先启动Hadoop集群。特别要注意，需<strong>等待HDFS安全模式关闭之后再启动运行Hive</strong>。
Hive不是分布式安装运行的软件，其分布式的特性主要<strong>借由Hadoop</strong>完成。包括<strong>分布式存储、分布式计算</strong>。</p> <h3 id="hadoop与hive整合"><a href="#hadoop与hive整合" class="header-anchor">#</a> Hadoop与Hive整合</h3> <p>因为Hive需要把数据<strong>存储在HDFS</strong>上，并且通过MapReduce作为执行引擎处理数据；</p> <p>因此需要在Hadoop中添加相关配置属性，以满足Hive在Hadoop上运行。</p> <p>修改Hadoop中core-site.xml，并且Hadoop集群同步配置文件，重启生效。</p> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token comment">&lt;!-- 整合hive 代理用户配置 --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hadoop.proxyuser.root.hosts<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hadoop.proxyuser.root.groups<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><h3 id="远程模式安装"><a href="#远程模式安装" class="header-anchor">#</a> 远程模式安装</h3> <p>远程模式最大的特点有两个：</p> <ul><li>需要安装MySQL来存储Hive元数据；</li> <li>需要手动单独配置启动Metastore服务。</li></ul> <p><img src="/study/assets/img/image-20210816210955071.380eff20.png" alt="image-20210816210955071"></p> <h4 id="mysql的安装"><a href="#mysql的安装" class="header-anchor">#</a> MySQL的安装</h4> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#卸载Centos7自带mariadb</span>
<span class="token function">rpm</span> -qa<span class="token operator">|</span><span class="token function">grep</span> mariadb
mariadb-libs-5.5.64-1.el7.x86_64
<span class="token function">rpm</span> -e mariadb-libs-5.5.64-1.el7.x86_64 --nodeps

<span class="token comment">#创建mysql安装包存放点</span>
<span class="token function">mkdir</span> /export/software/mysql
<span class="token comment">#上传mysql-5.7.29安装包到上述文件夹下、解压</span>
<span class="token function">tar</span> xvf mysql-5.7.29-1.el7.x86_64.rpm-bundle.tar

<span class="token comment">#执行安装</span>
yum -y <span class="token function">install</span> libaio
<span class="token function">rpm</span> -ivh mysql-community-common-5.7.29-1.el7.x86_64.rpm mysql-community-libs-5.7.29-1.el7.x86_64.rpm mysql-community-client-5.7.29-1.el7.x86_64.rpm mysql-community-server-5.7.29-1.el7.x86_64.rpm

<span class="token comment">#初始化mysql</span>
mysqld --initialize
<span class="token comment">#更改所属组</span>
<span class="token function">chown</span> mysql:mysql /var/lib/mysql -R

<span class="token comment">#启动mysql</span>
systemctl start mysqld.service
<span class="token comment">#查看生成的临时root密码</span>
<span class="token function">grep</span> <span class="token string">'temporary password'</span> /var/log/mysqld.log
<span class="token comment">#这行日志的最后就是随机生成的临时密码</span>
<span class="token punctuation">[</span>Note<span class="token punctuation">]</span> A temporary password is generated <span class="token keyword">for</span> root@localhost: o+TU+KDOm004

<span class="token comment">#修改mysql root密码、授权远程访问</span>
mysql -u root -p
Enter password:     <span class="token comment">#这里输入在日志中生成的临时密码</span>

<span class="token comment">#更新root密码  设置为hadoop</span>
mysql<span class="token operator">&gt;</span> alter user user<span class="token punctuation">(</span><span class="token punctuation">)</span> identified by <span class="token string">&quot;hadoop&quot;</span><span class="token punctuation">;</span>
Query OK, <span class="token number">0</span> rows affected <span class="token punctuation">(</span><span class="token number">0.00</span> sec<span class="token punctuation">)</span>
<span class="token comment">#授权</span>
mysql<span class="token operator">&gt;</span> use mysql<span class="token punctuation">;</span>
mysql<span class="token operator">&gt;</span> GRANT ALL PRIVILEGES ON *.* TO <span class="token string">'root'</span>@<span class="token string">'%'</span> IDENTIFIED BY <span class="token string">'hadoop'</span> WITH GRANT OPTION<span class="token punctuation">;</span>
mysql<span class="token operator">&gt;</span> FLUSH PRIVILEGES<span class="token punctuation">;</span>

<span class="token comment">#mysql的启动和关闭 状态查看</span>
systemctl stop mysqld
systemctl status mysqld
systemctl start mysqld

<span class="token comment">#建议设置为开机自启动服务</span>
systemctl <span class="token builtin class-name">enable</span>  mysqld

<span class="token comment">#查看是否已经设置自启动成功</span>
systemctl list-unit-files <span class="token operator">|</span> <span class="token function">grep</span> mysqld
</code></pre></div><h4 id="hive-安装"><a href="#hive-安装" class="header-anchor">#</a> Hive 安装</h4> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment"># 上传解压安装包</span>
<span class="token builtin class-name">cd</span> /export/server/
<span class="token function">tar</span> zxvf apache-hive-3.1.2-bin.tar.gz
<span class="token function">mv</span> apache-hive-3.1.2-bin hive

<span class="token comment">#解决hadoop、hive之间guava版本差异</span>
<span class="token builtin class-name">cd</span> /export/server/hive
<span class="token function">rm</span> -rf lib/guava-19.0.jar
<span class="token function">cp</span> /export/server/hadoop-3.1.4/share/hadoop/common/lib/guava-27.0-jre.jar ./lib/

<span class="token comment">#添加mysql jdbc驱动到hive安装包lib/文件下</span>
mysql-connector-java-5.1.32.jar

<span class="token comment">#修改hive环境变量文件 添加Hadoop_HOME</span>
<span class="token builtin class-name">cd</span> /export/server/hive/conf/
<span class="token function">mv</span> hive-env.sh.template hive-env.sh
<span class="token function">vim</span> hive-env.sh
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_HOME</span><span class="token operator">=</span>/export/server/hadoop-3.1.4
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HIVE_CONF_DIR</span><span class="token operator">=</span>/export/server/hive/conf
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HIVE_AUX_JARS_PATH</span><span class="token operator">=</span>/export/server/hive/lib

</code></pre></div><h4 id="hive-site-xml"><a href="#hive-site-xml" class="header-anchor">#</a> Hive-site.xml</h4> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#新增hive-site.xml 配置mysql等相关信息</span>
<span class="token function">vim</span> hive-site.xml
</code></pre></div><div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!-- 存储元数据mysql相关配置 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>javax.jdo.option.ConnectionURL<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span> jdbc:mysql://master:3306/hive?createDatabaseIfNotExist=true<span class="token entity named-entity" title="&amp;">&amp;amp;</span>useSSL=false<span class="token entity named-entity" title="&amp;">&amp;amp;</span>useUnicode=true<span class="token entity named-entity" title="&amp;">&amp;amp;</span>characterEncoding=UTF-8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>javax.jdo.option.ConnectionDriverName<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>com.mysql.jdbc.Driver<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>javax.jdo.option.ConnectionUserName<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>root<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>javax.jdo.option.ConnectionPassword<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token comment">&lt;!-- H2S运行绑定host --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.server2.thrift.bind.host<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>node1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token comment">&lt;!-- 远程模式部署metastore 服务地址 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.metastore.uris<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>thrift://master:9083<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token comment">&lt;!-- 关闭元数据存储授权  --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.metastore.event.db.notification.api.auth<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!-- 关闭元数据存储版本的验证 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.metastore.schema.verification<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment"># 初始化metadata</span>
<span class="token builtin class-name">cd</span> /export/server/hive
bin/schematool -initSchema -dbType mysql -verbos
<span class="token comment"># 初始化成功会在mysql中创建74张表</span>
</code></pre></div><p><img src="/study/assets/img/image-20210816221912983.0a6fc505.png" alt="image-20210816221912983"></p> <p>如果在远程模式下，直接运行hive服务，在执行操作的时候会报错，错误信息如下：</p> <p><img src="/study/assets/img/image-20210816212725723.3d9ddff0.png" alt="image-20210816212725723"></p> <blockquote><p>注意：</p> <p>在远程模式下，必须首先启动Hive metastore服务才可以使用hive。</p> <p>因为metastore服务和hive server是两个单独的进程了。</p></blockquote> <h4 id="手动启动-metastore"><a href="#手动启动-metastore" class="header-anchor">#</a> 手动启动 Metastore</h4> <p>后台启动的输出日志信息，在/root目录下，nohup.out。</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#前台启动  关闭ctrl+c</span>
/export/server/hive/bin/hive --service metastore

<span class="token comment">#前台启动开启debug日志</span>
/export/server/hive/bin/hive --service metastore --hiveconf hive.root.logger<span class="token operator">=</span>DEBUG,console

<span class="token comment">#后台启动 进程挂起  关闭使用jps + kill</span>
<span class="token comment">#输入命令回车执行 再次回车 进程将挂起后台</span>
<span class="token function">nohup</span> /export/server/hive/bin/hive --service metastore --hiveconf hive.root.logger<span class="token operator">=</span>DEBUG,console <span class="token operator">&amp;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210816222505844.fe5c51ce.png" alt="image-20210816222505844"></p> <h2 id="hive-客户端使用"><a href="#hive-客户端使用" class="header-anchor">#</a> Hive 客户端使用</h2> <p><img src="/study/assets/img/image-20210816223059715.231c40a4.png" alt="image-20210816223059715"></p> <p>Hive发展至今，总共历经了两代客户端工具。</p> <ul><li>第一代客户端（deprecated不推荐使用）：<strong>$HIVE_HOME/bin/hive,</strong> 是一个 shellUtil。主要功能：
<ul><li>一是可用于以交互或批处理模式运行Hive查询；</li> <li>二是用于Hive相关服务的启动，比如metastore服务。</li></ul></li> <li>第二代客户端（recommended 推荐使用）：<strong>$HIVE_HOME/bin/beeline</strong>，是一个JDBC客户端，是<strong>官方强烈推荐</strong>使用的Hive命令行工具，和第一代客户端相比，性能加强安全性提高。</li></ul> <img src="/study/assets/img/image-20210816222848104.fd922b8f.png" alt="image-20210816222848104" style="zoom:50%;"> <h3 id="hive-beeline-client"><a href="#hive-beeline-client" class="header-anchor">#</a> Hive Beeline Client</h3> <p>Beeline在嵌入式模式和远程模式下均可工作。</p> <p>在嵌入式模式下，它运行嵌入式 Hive(类似于Hive Client)；而<strong>远程模式下beeline通过 Thrift 连接到单独的 HiveServer2服务</strong>上，这也是官方推荐在生产环境中使用的模式。</p> <p>那么问题来了，HiveServer2是什么？HiveServer1哪里去了？</p> <h3 id="hiveserver、hiveserver2服务"><a href="#hiveserver、hiveserver2服务" class="header-anchor">#</a> HiveServer、HiveServer2服务</h3> <p>HiveServer、HiveServer2都是Hive自带的两种服务，允许客户端在不启动CLI（命令行）的情况下对Hive中的数据进行操作，且两个都允许远程客户端使用多种编程语言如java，python等向hive提交请求，取回结果。</p> <p>但是，HiveServer不能处理多于一个客户端的并发请求。因此在Hive-0.11.0版本中重写了HiveServer代码得到了HiveServer2，进而解决了该问题。HiveServer已经被废弃。</p> <p>HiveServer2支持<strong>多客户端</strong>的<strong>并发</strong>和<strong>身份认证</strong>，旨在为开放API客户端如JDBC、ODBC提供更好的支持。</p> <h3 id="关系梳理"><a href="#关系梳理" class="header-anchor">#</a> 关系梳理</h3> <p>HiveServer2通过Metastore服务读写元数据。所以在远程模式下，启动HiveServer2之前必须先<strong>首先启动metastore服务</strong>。</p> <p>特别注意：远程模式下，Beeline客户端只能通过HiveServer2服务访问Hive。而bin/hive是通过Metastore服务访问的。具体关系如下：</p> <p><img src="/study/assets/img/image-20210816223436187.93bd643b.png" alt="image-20210816223436187"></p> <h3 id="具体使用"><a href="#具体使用" class="header-anchor">#</a> 具体使用</h3> <h4 id="bin-hive-客户端"><a href="#bin-hive-客户端" class="header-anchor">#</a> bin/hive 客户端</h4> <p>在hive安装包的bin目录下，有hive提供的第一代客户端 bin/hive。该客户端可以访问hive的metastore服务，从而达到操作hive的目的。</p> <p>友情提示：<strong>如果您是远程模式部署，请手动启动运行metastore服务</strong>。如果是内嵌模式和本地模式，直接运行bin/hive，metastore服务会内嵌一起启动。</p> <p>可以直接在启动Hive metastore服务的机器上使用bin/hive客户端操作，此时不需要进行任何配置。</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#远程模式 首先启动metastore服务</span>
/export/server/hive/bin/hive --service metastore

<span class="token comment">#克隆CRT会话窗口 使用hive client连接</span>
/export/server/hive/bin/hive
</code></pre></div><p>如果需要在其他机器上通过bin/hive访问hive metastore服务，只需要在该机器的hive-site.xml配置中添加metastore服务地址即可。</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#上传hive安装包到另一个机器上，比如node3：</span>
<span class="token builtin class-name">cd</span> /export/server/
<span class="token function">tar</span> zxvf apache-hive-3.1.2-bin.tar.gz
<span class="token function">mv</span> apache-hive-3.1.2-bin hive

<span class="token comment">#解决hadoop、hive之间guava版本差异</span>
<span class="token builtin class-name">cd</span> /export/server/hive/
<span class="token function">rm</span> -rf lib/guava-19.0.jar
<span class="token function">cp</span> /export/server/hadoop-3.1.4/share/hadoop/common/lib/guava-27.0-jre.jar ./lib/

<span class="token comment">#修改hive环境变量文件 添加Hadoop_HOME</span>
<span class="token builtin class-name">cd</span> /export/server/hive/conf
<span class="token function">mv</span> hive-env.sh.template hive-env.sh
<span class="token function">vim</span> hive-env.sh
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_HOME</span><span class="token operator">=</span>/export/server/hadoop-3.1.4

<span class="token comment">#添加metastore服务地址</span>
<span class="token builtin class-name">cd</span> /export/server/hive/conf/
<span class="token function">vim</span>  hive-site.xml
</code></pre></div><div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.metastore.uris<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>thrift://node1:9083<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><p>可以通过运行 &quot;hive -H&quot; 或者 &quot;hive --help&quot; 来查看命令行选项。</p> <p><img src="/study/assets/img/image-20210904161555951.0f7d1495.png" alt="image-20210904161555951"></p> <p><img src="/study/assets/img/image-20210904161625661.a2983561.png" alt="image-20210904161625661"></p> <h5 id="功能一-batch-mode-批处理模式"><a href="#功能一-batch-mode-批处理模式" class="header-anchor">#</a> 功能一：Batch Mode 批处理模式</h5> <p>当使用-e或-f选项运行bin/hive时，它将以批处理模式执行SQL命令。</p> <p>所谓的批处理可以理解为<strong>一次性执行，执行完毕退出</strong>。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">#-e</span>
$HIVE_HOME<span class="token operator">/</span>bin<span class="token operator">/</span>hive <span class="token operator">-</span>e <span class="token string">'show databases'</span>

<span class="token comment">#-f</span>
cd <span class="token operator">~</span>
<span class="token comment">#编辑一个sql文件 里面写上合法正确的sql语句</span>
vim hive<span class="token punctuation">.</span><span class="token keyword">sql</span>
<span class="token keyword">show</span> <span class="token keyword">databases</span><span class="token punctuation">;</span>
<span class="token comment">#执行 从客户端所在机器的本地磁盘加载文件</span>
$HIVE_HOME<span class="token operator">/</span>bin<span class="token operator">/</span>hive <span class="token operator">-</span>f <span class="token operator">/</span>root<span class="token operator">/</span>hive<span class="token punctuation">.</span><span class="token keyword">sql</span>
<span class="token comment">#也可以从其他文件系统加载sql文件执行</span>
$HIVE_HOME<span class="token operator">/</span>bin<span class="token operator">/</span>hive <span class="token operator">-</span>f hdfs:<span class="token comment">//&lt;namenode&gt;:&lt;port&gt;/hive-script.sql</span>
$HIVE_HOME<span class="token operator">/</span>bin<span class="token operator">/</span>hive <span class="token operator">-</span>f s3:<span class="token comment">//mys3bucket/s3-script.sql</span>
<span class="token comment">#使用静默模式将数据从查询中转储到文件中</span>
$HIVE_HOME<span class="token operator">/</span>bin<span class="token operator">/</span>hive <span class="token operator">-</span>S <span class="token operator">-</span>e <span class="token string">'select * from itheima.student'</span> <span class="token operator">&gt;</span> a<span class="token punctuation">.</span>txt
</code></pre></div><h5 id="功能二-interactive-shell-交互式模式"><a href="#功能二-interactive-shell-交互式模式" class="header-anchor">#</a> 功能二：Interactive Shell 交互式模式</h5> <p>所谓交互式模式可以理解为<strong>客户端和hive服务一直保持连接</strong>，除非手动退出客户端。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token operator">/</span>export<span class="token operator">/</span>server<span class="token operator">/</span>hive<span class="token operator">/</span>bin<span class="token operator">/</span>hive

hive<span class="token operator">&gt;</span> <span class="token keyword">show</span> <span class="token keyword">databases</span><span class="token punctuation">;</span>
OK
<span class="token keyword">default</span>
test
itheima
<span class="token keyword">Time</span> taken: <span class="token number">0.028</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">3</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>

hive<span class="token operator">&gt;</span> <span class="token keyword">use</span> test<span class="token punctuation">;</span>
OK
<span class="token keyword">Time</span> taken: <span class="token number">0.027</span> seconds

hive<span class="token operator">&gt;</span> <span class="token keyword">exit</span><span class="token punctuation">;</span>
</code></pre></div><h5 id="功能三-启动hive服务"><a href="#功能三-启动hive服务" class="header-anchor">#</a> 功能三：启动Hive服务</h5> <p>比如metastore服务和hiveserver2服务的启动。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">#--service</span>
$HIVE_HOME<span class="token operator">/</span>bin<span class="token operator">/</span>hive <span class="token comment">--service metastore</span>
$HIVE_HOME<span class="token operator">/</span>bin<span class="token operator">/</span>hive <span class="token comment">--service hiveserver2</span>

<span class="token comment">#--hiveconf</span>
$HIVE_HOME<span class="token operator">/</span>bin<span class="token operator">/</span>hive <span class="token comment">--hiveconf hive.root.logger=DEBUG,console</span>
</code></pre></div><h4 id="bin-beeline-客户端"><a href="#bin-beeline-客户端" class="header-anchor">#</a> bin/beeline 客户端</h4> <p>hive经过发展，推出了第二代客户端beeline，但是beeline客户端不是直接访问metastore服务的，而是需要单独启动hiveserver2服务。</p> <p>在hive安装的服务器上，<strong>首先启动metastore服务，然后启动hiveserver2服务</strong>。</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#先启动metastore服务 然后启动hiveserver2服务</span>
<span class="token function">nohup</span> /export/server/hive/bin/hive --service metastore <span class="token operator">&amp;</span>
<span class="token function">nohup</span> /export/server/hive/bin/hive --service hiveserver2 <span class="token operator">&amp;</span>
</code></pre></div><p>Beeline是JDBC的客户端，通过JDBC协议和Hiveserver2服务进行通信，协议的地址是：<code>jdbc:hive2://node1:10000</code></p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token punctuation">[</span>root@node3 ~<span class="token punctuation">]</span><span class="token comment"># /export/server/hive/bin/beeline </span>
Beeline version <span class="token number">3.1</span>.2 by Apache Hive
beeline<span class="token operator">&gt;</span> <span class="token operator">!</span> connect jdbc:hive2://node1:10000
Connecting to jdbc:hive2://node1:10000
Enter username <span class="token keyword">for</span> jdbc:hive2://node1:10000: root
Enter password <span class="token keyword">for</span> jdbc:hive2://node1:10000: 
Connected to: Apache Hive <span class="token punctuation">(</span>version <span class="token number">3.1</span>.2<span class="token punctuation">)</span>
Driver: Hive JDBC <span class="token punctuation">(</span>version <span class="token number">3.1</span>.2<span class="token punctuation">)</span>
Transaction isolation: TRANSACTION_REPEATABLE_READ
<span class="token number">0</span>: jdbc:hive2://node1:1000<span class="token operator"><span class="token file-descriptor important">0</span>&gt;</span> 
</code></pre></div><p><img src="/study/assets/img/image-20210816225055505.8487156e.png" alt="image-20210816225055505"></p> <h2 id="hive-使用体验"><a href="#hive-使用体验" class="header-anchor">#</a> Hive 使用体验</h2> <h3 id="hive使用起来和mysql差不多吗"><a href="#hive使用起来和mysql差不多吗" class="header-anchor">#</a> Hive使用起来和MySQL差不多吗？</h3> <p>对于初次接触Apache Hive的人来说，最大的疑惑就是：Hive 从数据模型看起来和关系型数据库MySQL等好像。包括Hive SQL也是一种类SQL语言。那么实际使用起来如何？</p> <h4 id="过程"><a href="#过程" class="header-anchor">#</a> 过程</h4> <p>按照MySQL的思维，在hive中创建、切换数据库，创建表并执行插入数据操作，最后查询是否插入成功。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">--创建数据库</span>
<span class="token keyword">create</span> <span class="token keyword">database</span> test<span class="token punctuation">;</span>
<span class="token comment">--列出所有数据库</span>
<span class="token keyword">show</span> <span class="token keyword">databases</span><span class="token punctuation">;</span>
<span class="token comment">--切换数据库</span>
<span class="token keyword">use</span> test<span class="token punctuation">;</span>
<span class="token comment">--建表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> t_student<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">--插入一条数据</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_student <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">&quot;allen1&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">--查询表数据</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_student<span class="token punctuation">;</span>
</code></pre></div><p>在执行插入数据的时候，发现<strong>插入速度极慢，sql执行时间很长</strong>，为什么？</p> <p><img src="/study/assets/img/image-20210816235350657.cfb1f396.png" alt="image-20210816235350657"></p> <p>最终插入一条数据，历史30秒的时间。查询表数据，显示数据插入成功</p> <p><img src="/study/assets/img/image-20210816235403045.1c424e58.png" alt="image-20210816235403045"></p> <h4 id="验证"><a href="#验证" class="header-anchor">#</a> 验证</h4> <p>首先登陆Hadoop YARN上观察是否有MapReduce任务执行痕迹。</p> <div class="language-http extra-class"><pre class="language-http"><code>YARN Web UI: http://resourcemanager_host:8088/
</code></pre></div><p><img src="/study/assets/img/image-20210816235419160.b5ad7fa7.png" alt="image-20210816235419160"></p> <p>然后登陆Hadoop HDFS浏览文件系统，根据Hive的数据模型，表的数据最终是存储在HDFS和表对应的文件夹下的。</p> <div class="language-http extra-class"><pre class="language-http"><code>HDFS Web UI: http://namenode_host:9870/
</code></pre></div><p><img src="/study/assets/img/image-20210816235430014.da56caa4.png" alt="image-20210816235430014"></p> <h4 id="结论"><a href="#结论" class="header-anchor">#</a> 结论</h4> <ul><li>Hive SQL语法show和标准SQL很类似,使得学习成本降低不少。</li> <li>Hive底层是通过MapReduce执行的数据插入动作,所以速度慢。</li> <li>如果大数据集这么一条一条插入的话是非常不现实的，成本极高。</li> <li>Hive应该具有自己特有的数据插入表方式，结构化文件映射成为表。</li></ul> <h3 id="hive如何才能将结构化数据映射成为表"><a href="#hive如何才能将结构化数据映射成为表" class="header-anchor">#</a> Hive如何才能将结构化数据映射成为表？</h3> <p>在Hive中，使用insert+values语句插入数据，底层是通过MapReduce执行的，效率十分低下。此时回到Hive的本质上：可以将结构化的数据文件映射成为一张表，并提供基于表的SQL查询分析。</p> <p>假如，现在有一份结构化的数据文件，如何才能映射成功呢？在映射成功的过程中需要注意哪些问题？</p> <p>文件存储路径？字段类型？字段顺序？字段之间分隔符？</p> <h4 id="过程-2"><a href="#过程-2" class="header-anchor">#</a> 过程</h4> <p>在HDFS根目录下创建一个结构化数据文件user.txt，里面内容如下：</p> <div class="language-txt extra-class"><pre class="language-text"><code>1,zhangsan,18,beijing
2,lisi,25,shanghai
3,allen,30,shanghai
4,woon,15,nanjing
5,james,45,hangzhou
6,tony,26,beijing
</code></pre></div><p><img src="/study/assets/img/image-20210817211931079.a3118b9d.png" alt="image-20210817211931079"></p> <p>在hive中创建一张表t_user。注意：<strong>字段的类型顺序要和文件中字段保持一致。</strong></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">create</span> <span class="token keyword">table</span> t_user<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">,</span>age <span class="token keyword">int</span><span class="token punctuation">,</span>city <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="验证-2"><a href="#验证-2" class="header-anchor">#</a> 验证</h4> <p>执行数据查询操作，发现表中并没有数据。</p> <p>猜想：<strong>难道数据文件要放置在表对应的HDFS路径下才可以成功？</strong></p> <p><img src="/study/assets/img/image-20210817212034442.d63828f4.png" alt="image-20210817212034442"></p> <p>再次执行查询操作，显示如下，都是null：</p> <p><img src="/study/assets/img/image-20210817212054164.236fb8a0.png" alt="image-20210817212054164"></p> <p>表感知到结构化文件的存在，但是并没有正确识别文件中的数据。猜想：还<strong>需要指定文件中字段之间的分隔符</strong>？重建张新表，指定分隔符。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token operator">-</span>建表语句 增加分隔符指定语句
<span class="token keyword">create</span> <span class="token keyword">table</span> t_user_1<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">,</span>age <span class="token keyword">int</span><span class="token punctuation">,</span>city <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>
<span class="token comment">--关于分隔符语法 后续学习展开</span>

<span class="token comment">#把user.txt文件从本地文件系统上传到hdfs</span>
hadoop fs <span class="token operator">-</span>put <span class="token keyword">user</span><span class="token punctuation">.</span>txt <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>test<span class="token punctuation">.</span>db<span class="token operator">/</span>t_user_1<span class="token operator">/</span>

<span class="token comment">--执行查询操作</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_user_1<span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210817212133447.5c202084.png" alt="image-20210817212133447"></p> <p>此时再创建一张表，保存分隔符语法，但是故意使得字段类型和文件中不一致。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token operator">-</span>建表语句 增加分隔符指定语句（这里将name转换为 <span class="token keyword">int</span>类型）
<span class="token keyword">create</span> <span class="token keyword">table</span> t_user_2<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name <span class="token keyword">int</span><span class="token punctuation">,</span>age <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">,</span>city <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>
<span class="token comment">#把user.txt文件从本地文件系统上传到hdfs</span>
hadoop fs <span class="token operator">-</span>put <span class="token keyword">user</span><span class="token punctuation">.</span>txt <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>test<span class="token punctuation">.</span>db<span class="token operator">/</span>t_user_2<span class="token operator">/</span>

<span class="token comment">--执行查询操作</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_user_2<span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210817212214191.8cda3af5.png" alt="image-20210817212214191"></p> <p>此时发现，有的列显示null，有的列显示正常。</p> <p>name字段本身是字符串，但是建表的时候指定int，类型转换不成功；age是数值类型，建表指定字符串类型，可以转换成功。说明<strong>hive中具有自带的类型转换功能，但是不一定保证转换成功</strong>。</p> <h4 id="结论-2"><a href="#结论-2" class="header-anchor">#</a> 结论</h4> <p>要想在hive中创建表跟结构化文件映射成功，需要注意以下几个方面问题：</p> <ul><li><strong>创建表时，字段顺序、字段类型要和文件中保持一致。</strong></li> <li>如果类型不一致，hive会尝试转换，但是不保证转换成功。不成功显示null。</li> <li>文件好像要放置在Hive表对应的HDFS目录下，其他路径可以吗？</li> <li>建表的时候好像要根据文件内容指定分隔符，不指定可以吗？</li></ul> <h3 id="使用hive进行小数据分析如何"><a href="#使用hive进行小数据分析如何" class="header-anchor">#</a> 使用Hive进行小数据分析如何？</h3> <p>因为Hive是基于HDFS进行文件的存储，所以理论上能够支持的数据存储规模很大，天生适合大数据分析。假如Hive中的数据是小数据，再使用Hive开展分析效率如何呢？</p> <h4 id="过程-3"><a href="#过程-3" class="header-anchor">#</a> 过程</h4> <p>之前我们创建好了一张表t_user_1,现在通过Hive SQL找出当中年龄大于20岁的有几个。</p> <h4 id="验证-3"><a href="#验证-3" class="header-anchor">#</a> 验证</h4> <p>发现又是通过MapReduce程序执行的数据查询功能。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 执行查询操作</span>
<span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">from</span> t_user_1 <span class="token keyword">where</span> age <span class="token operator">&gt;</span> <span class="token number">20</span><span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210819212210672.7159b04c.png" alt="image-20210819212210672"></p> <h4 id="结论-3"><a href="#结论-3" class="header-anchor">#</a> 结论</h4> <ul><li>Hive底层的确是通过MapReduce执行引擎来处理数据的</li> <li>执行完一个MapReduce程序需要的时间不短</li> <li>如果是小数据集，使用hive进行分析将得不偿失，延迟很高</li> <li>如果是大数据集，使用hive进行分析，底层MapReduce分布式计算，很爽</li></ul> <h2 id="hive-ddl-概述"><a href="#hive-ddl-概述" class="header-anchor">#</a> Hive DDL 概述</h2> <h3 id="ddl-语法的作用"><a href="#ddl-语法的作用" class="header-anchor">#</a> DDL 语法的作用</h3> <p><strong>数据定义语言 (Data Definition Language, DDL)</strong>，是SQL语言集中对数据库内部的对象结构进行创建，删除，修改等的操作语言，这些数据库对象包括database（schema）、table、view、index等。</p> <p>核心语法由<strong>CREATE、ALTER与DROP</strong>三个所组成。<strong>DDL并不涉及表内部数据的操作。</strong></p> <p>在某些上下文中，该术语也称为数据描述语言，因为它描述了数据库表中的字段和记录。</p> <h3 id="hive-中的-ddl-使用"><a href="#hive-中的-ddl-使用" class="header-anchor">#</a> Hive 中的 DDL 使用</h3> <p>Hive SQL（HQL）与SQL的语法大同小异，基本上是相通的，学过SQL的使用者可以无痛使用Hive SQL。只不过在学习HQL语法的时候，特别要注意Hive自己特有的语法知识点，比如partition相关的DDL操作。</p> <p>基于Hive的设计、使用特点，**HQL中create语法（尤其create table ）**将是学习掌握DDL语法的重中之重。可以说建表是否成功直接影响数据文件是否映射成功，进而影响后续是否可以基于SQL分析数据。通俗点说，没有表，表没有数据，你分析什么呢？</p> <p>选择正确的方向,往往比盲目努力重要。</p> <h2 id="hive-ddl-建表基础"><a href="#hive-ddl-建表基础" class="header-anchor">#</a> Hive DDL 建表基础</h2> <h3 id="完整的建表语法树"><a href="#完整的建表语法树" class="header-anchor">#</a> 完整的建表语法树</h3> <p><img src="/study/assets/img/image-20210819214414052.4229737c.png" alt="image-20210819214414052"></p> <ul><li><p><strong>蓝色</strong>字体是建表语法的关键字，用于指定某些功能。</p></li> <li><p>**[]**中括号的语法表示可选。</p></li> <li><p><strong>|</strong> 表示使用的时候，左右语法二选一。</p></li> <li><p>建表语句中的语法顺序要和上述语法规则保持一致。</p></li></ul> <h3 id="hive-数据类型详解"><a href="#hive-数据类型详解" class="header-anchor">#</a> Hive 数据类型详解</h3> <h4 id="整体概述"><a href="#整体概述" class="header-anchor">#</a> 整体概述</h4> <p>Hive数据类型指的是表中列的字段类型；</p> <p>整体分为两类：<strong>原生数据类型</strong>（primitive data type）和<strong>复杂数据类型</strong>（complex data type）。</p> <p>原生数据类型包括：数值类型、时间日期类型、字符串类型、杂项数据类型；</p> <p>复杂数据类型包括：array数组、map映射、struct结构、union联合体。</p> <img src="/study/assets/img/image-20210819214739380.10fe729e.png" alt="image-20210819214739380" style="zoom:30%;"> <p>关于Hive的数据类型，需要注意：</p> <ul><li>英文字母<strong>大小写不敏感</strong>；</li> <li>除SQL数据类型外，还<strong>支持Java数据类型</strong>，比如：string；</li> <li><strong>int和string是使用最多的</strong>，大多数函数都支持；</li> <li>复杂数据类型的使用通常需要和分隔符指定语法配合使用。</li> <li>如果定义的数据类型和文件不一致，hive会尝试隐式转换，但是不保证成功。</li></ul> <h4 id="原生数据类型"><a href="#原生数据类型" class="header-anchor">#</a> 原生数据类型</h4> <p>Hive支持的原生数据类型如下图所示：</p> <p><img src="/study/assets/img/image-20210819215021196.ea8b5e5f.png" alt="image-20210819215021196"></p> <p>其中标注的数据类型是使用较多的，详细的描述请查询语法手册：</p> <p>https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types</p> <h4 id="复杂数据类型"><a href="#复杂数据类型" class="header-anchor">#</a> 复杂数据类型</h4> <p>Hive支持的复杂数据类型如下图所示：</p> <p><img src="/study/assets/img/image-20210819215129362.fa787552.png" alt="image-20210819215129362"></p> <h4 id="数据类型隐式、显示转换"><a href="#数据类型隐式、显示转换" class="header-anchor">#</a> 数据类型隐式、显示转换</h4> <h5 id="隐式转换"><a href="#隐式转换" class="header-anchor">#</a> 隐式转换</h5> <p>与SQL类似，HQL支持隐式和显式类型转换。</p> <p>原生类型从窄类型到宽类型的转换称为隐式转换，反之，则不允许。</p> <p>下表描述了类型之间允许的隐式转换：</p> <p><img src="/study/assets/img/image-20210819215343715.e2c3dc09.png" alt="image-20210819215343715"></p> <h5 id="显示转换"><a href="#显示转换" class="header-anchor">#</a> 显示转换</h5> <p>显式类型转换使用<strong>CAST函数</strong>。
例如，CAST（'100'as INT）会将100字符串转换为100整数值。
如果强制转换失败，例如CAST（‘Allen'as INT），该函数返回NULL。</p> <p><img src="/study/assets/img/image-20210819215609837.db905ddb.png" alt="image-20210819215609837"></p> <h3 id="hive-读写文件机制"><a href="#hive-读写文件机制" class="header-anchor">#</a> Hive 读写文件机制</h3> <h4 id="serde是什么"><a href="#serde是什么" class="header-anchor">#</a> SerDe是什么</h4> <p>SerDe是Serializer、Deserializer的简称，目的是用于序列化和反序列化。</p> <p><strong>序列化是对象转化为字节码的过程</strong>；而<strong>反序列化是字节码转换为对象的过程</strong>。</p> <p>Hive使用SerDe（包括FileFormat）读取和写入表<strong>行对象</strong>。需要注意的是，“key”部分在读取时会被忽略，而在写入时key始终是常数。基本上行对象存储在“value”中。</p> <p><img src="/study/assets/img/image-20210819220042460.f1b00780.png" alt="image-20210819220042460"></p> <p>可以通过 <code>desc formatted tablename</code>查看表的相关SerDe信息。默认如下：</p> <p><img src="/study/assets/img/image-20210819220423509.e3c5d35f.png" alt="image-20210819220423509"></p> <h4 id="hive-读写文件流程"><a href="#hive-读写文件流程" class="header-anchor">#</a> Hive 读写文件流程</h4> <ul><li><p><strong>Hive读取文件机制</strong>：</p> <p>首先调用InputFormat（默认TextInputFormat），返回一条一条kv键值对记录（默认是一行对应一条键值对）。然后调用SerDe（默认LazySimpleSerDe）的Deserializer，将一条记录中的value根据分隔符切分为各个字段。</p></li> <li><p><strong>Hive写文件机制</strong>：</p> <p>将Row写入文件时，首先调用SerDe（默认LazySimpleSerDe）的Serializer将对象转换成字节序列，然后调用OutputFormat将数据写入HDFS文件中。</p></li></ul> <h4 id="serde相关语法"><a href="#serde相关语法" class="header-anchor">#</a> SerDe相关语法</h4> <p><strong>ROW FORMAT</strong>这一行所代表的是跟读写文件、序列化SerDe相关的语法，功能有二：</p> <ul><li><p>使用哪个SerDe类进行序列化；</p></li> <li><p>如何指定分隔符。</p></li></ul> <p><img src="/study/assets/img/image-20210828162954453.ae9513b7.png" alt="image-20210828162954453"></p> <p>其中ROW FORMAT是语法关键字，<strong>DELIMITED</strong>和<strong>SERDE</strong>二选其一。</p> <p>如果使用<strong>delimited</strong>, 表示使用<strong>默认的LazySimpleSerDe</strong>类来处理数据。</p> <p>如果数据文件格式比较特殊可以使用<strong>ROW FORMAT SERDE serde_name</strong>指定其他的Serde类来处理数据,甚至支持用户自定义SerDe类。</p> <p><img src="/study/assets/img/image-20210819220943932.8960d95a.png" alt="image-20210819220943932"></p> <h4 id="lazysimpleserde分隔符指定"><a href="#lazysimpleserde分隔符指定" class="header-anchor">#</a> LazySimpleSerDe分隔符指定</h4> <p>LazySimpleSerDe是Hive默认的序列化类，包含4种子语法， 分别用于指定字段之间、集合元素之间、map映射 kv之间、换行的分隔符号。</p> <p>在建表的时候可以根据数据的特点灵活搭配使用。</p> <p><img src="/study/assets/img/image-20210819221109966.e2ae0e8a.png" alt="image-20210819221109966"></p> <h4 id="hive默认分隔符"><a href="#hive默认分隔符" class="header-anchor">#</a> Hive默认分隔符</h4> <p>Hive建表时如果没有row format语法指定分隔符，则采用默认分隔符；</p> <p><strong>默认的分割符是'\001'</strong>，是一种特殊的字符，使用的是ASCII编码的值，键盘是打不出来的。</p> <p><img src="/study/assets/img/image-20210819221258939.8b276ace.png" alt="image-20210819221258939"></p> <p>在vim编辑器中，连续按下Ctrl+v/Ctrl+a即可输入'\001' ，显示^A</p> <p><img src="/study/assets/img/image-20210819221405672.5476d633.png" alt="image-20210819221405672"></p> <p>在一些文本编辑器中将以SOH的形式显示：</p> <p><img src="/study/assets/img/image-20210819221425453.02e76383.png" alt="image-20210819221425453"></p> <h3 id="hive数据存储路径"><a href="#hive数据存储路径" class="header-anchor">#</a> Hive数据存储路径</h3> <h4 id="默认存储路径"><a href="#默认存储路径" class="header-anchor">#</a> 默认存储路径</h4> <ul><li>Hive表默认存储路径是由 <code>${HIVE_HOME}/conf/hive-site.xml</code>配置文件的<code>hive.metastore.warehouse.dir</code>属性指定，默认值是：<code>/user/hive/warehouse</code>。</li></ul> <p><img src="/study/assets/img/image-20210819221621347.6f6979cf.png" alt="image-20210819221621347"></p> <ul><li>在该路径下，文件将根据所属的库、表，有规律的存储在对应的文件夹下。</li></ul> <p><img src="/study/assets/img/image-20210819221848093.40effa62.png" alt="image-20210819221848093"></p> <h4 id="指定存储路径"><a href="#指定存储路径" class="header-anchor">#</a> 指定存储路径</h4> <ul><li><p>在Hive建表的时候，可以<strong>通过 location 语法来更改数据在HDFS上的存储路径</strong>，使得建表加载数据更加灵活方便。</p></li> <li><p>语法：LOCATION '&lt;hdfs_location&gt;'。</p></li> <li><p>对于已经生成好的数据文件，使用location指定路径将会很方便。</p></li></ul> <p><img src="/study/assets/img/image-20210819221951614.3f2fadff.png" alt="image-20210819221951614"></p> <h3 id="案例-数据hive建表映射"><a href="#案例-数据hive建表映射" class="header-anchor">#</a> 案例-数据Hive建表映射</h3> <h4 id="原生数据类型案例"><a href="#原生数据类型案例" class="header-anchor">#</a> 原生数据类型案例</h4> <p>文件archer.txt中记录了手游《王者荣耀》射手的相关信息，内容如下所示，其中<strong>字段之间分隔符为制表符\t</strong>,要求在Hive中建表映射成功该文件。</p> <div class="language-txt extra-class"><pre class="language-text"><code>1	后羿	5986	1784	396	336	remotely	archer
2	马可波罗	5584	200	362	344	remotely	archer
3	鲁班七号	5989	1756	400	323	remotely	archer
4	李元芳	5725	1770	396	340	remotely	archer
5	孙尚香	6014	1756	411	346	remotely	archer
6	黄忠	5898	1784	403	319	remotely	archer
7	狄仁杰	5710	1770	376	338	remotely	archer
8	虞姬	5669	1770	407	329	remotely	archer
9	成吉思汗	5799	1742	394	329	remotely	archer
10	百里守约	5611	1784	410	329	remotely	archer	assassin
</code></pre></div><p>字段含义：id、name（英雄名称）、hp_max（最大生命）、mp_max（最大法力）、attack_max（最高物攻）、defense_max（最大物防）、attack_range（攻击范围）、role_main（主要定位）、role_assist（次要定位）。</p> <p>分析一下：字段都是基本类型，字段的顺序需要注意一下。字段之间的分隔符是制表符，需要使用row format语法进行指定。</p> <p><strong>建表语句：</strong></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 创建数据库并切换使用</span>
<span class="token keyword">create</span> <span class="token keyword">database</span> honor_of_kings<span class="token punctuation">;</span>
<span class="token keyword">use</span> honor_of_kings<span class="token punctuation">;</span>

<span class="token comment">-- ddl create table</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> t_archer<span class="token punctuation">(</span>
    id <span class="token keyword">int</span> <span class="token keyword">comment</span> <span class="token string">&quot;ID&quot;</span><span class="token punctuation">,</span>
    name string <span class="token keyword">comment</span> <span class="token string">&quot;英雄名称&quot;</span><span class="token punctuation">,</span>
    hp_max <span class="token keyword">int</span> <span class="token keyword">comment</span> <span class="token string">&quot;最大生命&quot;</span><span class="token punctuation">,</span>
    mp_max <span class="token keyword">int</span> <span class="token keyword">comment</span> <span class="token string">&quot;最大法力&quot;</span><span class="token punctuation">,</span>
    attack_max <span class="token keyword">int</span> <span class="token keyword">comment</span> <span class="token string">&quot;最高物攻&quot;</span><span class="token punctuation">,</span>
    defense_max <span class="token keyword">int</span> <span class="token keyword">comment</span> <span class="token string">&quot;最大物防&quot;</span><span class="token punctuation">,</span>
    attack_range string <span class="token keyword">comment</span> <span class="token string">&quot;攻击范围&quot;</span><span class="token punctuation">,</span>
    role_main string <span class="token keyword">comment</span> <span class="token string">&quot;主要定位&quot;</span><span class="token punctuation">,</span>
    role_assist string <span class="token keyword">comment</span> <span class="token string">&quot;次要定位&quot;</span>
<span class="token punctuation">)</span> <span class="token keyword">comment</span> <span class="token string">&quot;王者荣耀射手信息&quot;</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">&quot;\t&quot;</span><span class="token punctuation">;</span>

<span class="token keyword">show</span> <span class="token keyword">tables</span><span class="token punctuation">;</span>
</code></pre></div><p>建表成功之后，在Hive的默认存储路径下就生成了表对应的文件夹，把archer.txt文件上传到对应的表文件夹下。</p> <div class="language-shell extra-class"><pre class="language-shell"><code>hadoop fs -put archer.txt  /user/hive/warehouse/honor_of_kings.db/t_archer
</code></pre></div><p>执行查询操作，可以看出数据已经映射成功。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_archer<span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210828165159057.de75fdac.png" alt="image-20210828165159057"></p> <p><strong>总结：</strong></p> <p>核心语法：row format delimited fields terminated by 指定字段之间的分隔符</p> <blockquote><p>想一想：Hive这种直接映射文件的能力是不是比mysql一条一条insert插入数据方便多了？</p></blockquote> <h4 id="复杂数据类型案例"><a href="#复杂数据类型案例" class="header-anchor">#</a> 复杂数据类型案例</h4> <p>文件hot_hero_skin_price.txt中记录了手游《王者荣耀》热门英雄的相关皮肤价格信息，内容如下,要求在Hive中建表映射成功该文件。</p> <div class="language-txt extra-class"><pre class="language-text"><code>1,孙悟空,53,西部大镖客:288-大圣娶亲:888-全息碎片:0-至尊宝:888-地狱火:1688
2,鲁班七号,54,木偶奇遇记:288-福禄兄弟:288-黑桃队长:60-电玩小子:2288-星空梦想:0
3,后裔,53,精灵王:288-阿尔法小队:588-辉光之辰:888-黄金射手座:1688-如梦令:1314
4,铠,52,龙域领主:288-曙光守护者:1776
5,韩信,52,飞衡:1788-逐梦之影:888-白龙吟:1188-教廷特使:0-街头霸王:888
</code></pre></div><p>字段：id、name（英雄名称）、win_rate（胜率）、skin_price（皮肤及价格）</p> <p>分析一下：前3个字段原生数据类型、最后一个字段复杂类型map。需要指定<strong>字段之间分隔符</strong>、<strong>集合元素之间分隔符</strong>、<strong>map kv之间分隔符</strong>。</p> <p><strong>建表语句：</strong></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">create</span> <span class="token keyword">table</span> t_hot_hero_skin_price<span class="token punctuation">(</span>
    id <span class="token keyword">int</span><span class="token punctuation">,</span>
    name string<span class="token punctuation">,</span>
    win_rate <span class="token keyword">int</span><span class="token punctuation">,</span>
    skin_price map<span class="token operator">&lt;</span>string<span class="token punctuation">,</span><span class="token keyword">int</span><span class="token operator">&gt;</span>
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span> <span class="token comment">-- 字段之间分隔符</span>
collection items <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'-'</span> <span class="token comment">-- 集合元素之间分隔符</span>
map <span class="token keyword">keys</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">':'</span> <span class="token punctuation">;</span> <span class="token comment">-- 集合元素kv之间分隔符</span>
</code></pre></div><p>建表成功后，把hot_hero_skin_price.txt文件上传到对应的表文件夹下。</p> <div class="language-shell extra-class"><pre class="language-shell"><code>hadoop fs -put hot_hero_skin_price.txt /user/hive/warehouse/honor_of_kings.db/t_hot_hero_skin_price
</code></pre></div><p>执行查询操作，可以看出数据已经映射成功。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_hot_hero_skin_price<span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210828170058133.2791d31b.png" alt="image-20210828170058133"></p> <blockquote><p>想一想：如果最后一个字段以String类型来定义，后续使用方便吗？</p></blockquote> <h4 id="默认分隔符案例"><a href="#默认分隔符案例" class="header-anchor">#</a> 默认分隔符案例</h4> <p>文件team_ace_player.txt中记录了手游《王者荣耀》主要战队内最受欢迎的王牌选手信息，内容如下,要求在Hive中建表映射成功该文件。</p> <p><img src="/study/assets/img/image-20210828170459981.84dfc64e.png" alt="image-20210828170459981"></p> <p>字段：id、team_name（战队名称）、ace_player_name（王牌选手名字）</p> <p>分析一下：数据都是原生数据类型，且字段之间分隔符是\001，因此在建表的时候可以省去row format语句，因为hive默认的分隔符就是\001。</p> <p><strong>建表语句：</strong></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">create</span> <span class="token keyword">table</span> t_team_ace_player<span class="token punctuation">(</span>
    id <span class="token keyword">int</span><span class="token punctuation">,</span>
    team_name string<span class="token punctuation">,</span>
    ace_player_name string
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p>建表成功后，把team_ace_player.txt文件上传到对应的表文件夹下。</p> <div class="language-shell extra-class"><pre class="language-shell"><code>hadoop fs -put team_ace_player.txt /user/hive/warehouse/honor_of_kings.db/t_team_ace_player
</code></pre></div><p>执行查询操作，可以看出数据已经映射成功。</p> <p><img src="/study/assets/img/image-20210828170848408.aa489363.png" alt="image-20210828170848408"></p> <blockquote><p>想一想：字段以\001分隔建表时很方便，那么采集、清洗数据时对数据格式追求有什么启发？你青睐于什么分隔符？</p> <p>优先考虑\001分隔符</p></blockquote> <h4 id="指定数据存储路径"><a href="#指定数据存储路径" class="header-anchor">#</a> 指定数据存储路径</h4> <p>文件team_ace_player.txt中记录了手游《王者荣耀》主要战队内最受欢迎的王牌选手信息，字段之间使用的是\001作为分隔符。</p> <img src="/study/assets/img/image-20210828172027396.dba5efb5.png" alt="image-20210828172027396" style="zoom:50%;"> <p>要求把文件上传到<strong>HDFS任意路径</strong>下，不能移动复制，并在Hive中建表映射成功该文件。</p> <div class="language-shell extra-class"><pre class="language-shell"><code>hadoop fs -put team_ace_player.txt /data
</code></pre></div><p><img src="/study/assets/img/image-20210828172417542.b72aad5d.png" alt="image-20210828172417542"></p> <p><strong>建表语句：</strong></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">create</span> <span class="token keyword">table</span> t_team_ace_player_location<span class="token punctuation">(</span>
    id <span class="token keyword">int</span><span class="token punctuation">,</span>
    team_name string<span class="token punctuation">,</span>
    ace_player_name string
<span class="token punctuation">)</span>
location <span class="token string">'/data'</span><span class="token punctuation">;</span>
</code></pre></div><img src="/study/assets/img/image-20210828172331638.40ada649.png" alt="image-20210828172331638" style="zoom:50%;"> <h2 id="hive-ddl-建表高级"><a href="#hive-ddl-建表高级" class="header-anchor">#</a> Hive DDL 建表高级</h2> <h3 id="hive-内、外部表"><a href="#hive-内、外部表" class="header-anchor">#</a> Hive 内、外部表</h3> <p><img src="/study/assets/img/image-20210828172548514.bab04d8c.png" alt="image-20210828172548514"></p> <h4 id="什么是内部表"><a href="#什么是内部表" class="header-anchor">#</a> 什么是内部表</h4> <p><strong>内部表（Internal table）<strong>也称为被Hive拥有和管理的</strong>托管表（Managed table）</strong>。</p> <p>默认情况下创建的表就是内部表，Hive拥有该表的结构和文件。换句话说，Hive完全管理表（元数据和数据）的生命周期，类似于RDBMS中的表。</p> <p>当您<strong>删除内部表</strong>时，它<strong>会删除数据以及表的元数据</strong>。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 默认情况下 创建的表就是内部表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> student<span class="token punctuation">(</span>
    num <span class="token keyword">int</span><span class="token punctuation">,</span>
    name string<span class="token punctuation">,</span>
    sex string<span class="token punctuation">,</span>
    age <span class="token keyword">int</span><span class="token punctuation">,</span>
    dept string<span class="token punctuation">)</span> 
<span class="token keyword">row</span> format delimited 
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>
</code></pre></div><p>可以使用 DESCRIBE FORMATTED tablename 来获取表的描述信息，从中可以看出表的类型。</p> <p><img src="/study/assets/img/image-20210828173325790.021564b1.png" alt="image-20210828173325790"></p> <h4 id="什么是外部表"><a href="#什么是外部表" class="header-anchor">#</a> 什么是外部表</h4> <p><strong>外部表（External table）<strong>中的数据</strong>不是Hive拥有或管理</strong>的，<strong>只管理</strong>表<strong>元数据</strong>的生命周期。</p> <p>要创建一个外部表，需要使用<strong>EXTERNAL</strong>语法关键字。</p> <p>删除外部表<strong>只会删除元数据</strong>，而<strong>不会删除实际数据</strong>。在Hive外部仍然可以访问实际数据。</p> <p>实际场景中，外部表<strong>搭配location语法指定数据</strong>的路径，可以让数据更安全。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 创建外部表 需要关键字 external</span>
<span class="token comment">-- 外部表数据存储路径不指定 默认规则和内部表一直</span>
<span class="token comment">-- 也可以使用 location 关键字指定 HDFS 任意路径</span>
<span class="token keyword">create</span> external <span class="token keyword">table</span> student_ext<span class="token punctuation">(</span>   
    num <span class="token keyword">int</span><span class="token punctuation">,</span>   
    name string<span class="token punctuation">,</span>   
    sex string<span class="token punctuation">,</span>   
    age <span class="token keyword">int</span><span class="token punctuation">,</span>   
    dept string<span class="token punctuation">)</span>
    <span class="token keyword">row</span> format delimited
        <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span>
    location <span class="token string">'/stu'</span><span class="token punctuation">;</span>
</code></pre></div><p>可以使用DESCRIBE FORMATTED tablename,来获取表的元数据描述信息，从中可以看出表的类型。</p> <p><img src="/study/assets/img/image-20210828174039192.2f2540fb.png" alt="image-20210828174039192"></p> <h4 id="内、外部表差异"><a href="#内、外部表差异" class="header-anchor">#</a> 内、外部表差异</h4> <p>无论内部表还是外部表，Hive都在Hive Metastore中管理表定义、字段类型等元数据信息。</p> <p>删除内部表时，除了会从Metastore中删除表元数据，还会从HDFS中删除其所有数据文件。</p> <p>删除外部表时，只会从Metastore中删除表的元数据，并保持HDFS位置中的实际数据不变。</p> <p><img src="/study/assets/img/image-20210828174211133.8387652f.png" alt="image-20210828174211133"></p> <h4 id="如何选择内部表、外部表"><a href="#如何选择内部表、外部表" class="header-anchor">#</a> 如何选择内部表、外部表</h4> <p>当需要通过Hive完全管理控制表的整个生命周期时，请使用内部表。</p> <p>当数据来之不易，防止误删，请使用外部表，因为即使删除表，文件也会被保留。</p> <h3 id="hive-分区表"><a href="#hive-分区表" class="header-anchor">#</a> Hive 分区表</h3> <h4 id="分区表产生的背景"><a href="#分区表产生的背景" class="header-anchor">#</a> 分区表产生的背景</h4> <p>现有6份结构化数据文件，分别记录了《王者荣耀》中6种位置的英雄相关信息。</p> <p>现要求通过建立一张表t_all_hero，把6份文件同时映射加载。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">create</span> <span class="token keyword">table</span> t_all_hero<span class="token punctuation">(</span>
    id <span class="token keyword">int</span><span class="token punctuation">,</span>
    name string<span class="token punctuation">,</span>
    hp_max <span class="token keyword">int</span><span class="token punctuation">,</span>
    mp_max <span class="token keyword">int</span><span class="token punctuation">,</span>
    attack_max <span class="token keyword">int</span><span class="token punctuation">,</span>
    defense_max <span class="token keyword">int</span><span class="token punctuation">,</span>
    attack_range string<span class="token punctuation">,</span>
    role_main string<span class="token punctuation">,</span>
    role_assist string
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">&quot;\t&quot;</span><span class="token punctuation">;</span>
</code></pre></div><p>建表并且加载数据文件到HDFS指定路径下</p> <p><img src="/study/assets/img/image-20210828192009342.be54fd05.png" alt="image-20210828192009342"></p> <p>查看表数据</p> <p><img src="/study/assets/img/image-20210828192355267.55874742.png" alt="image-20210828192355267"></p> <p>现要求查询role_main主要定位是射手并且hp_max最大生命大于6000的有几个，sql语句如下：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">from</span> t_all_hero <span class="token keyword">where</span> role_main<span class="token operator">=</span><span class="token string">&quot;archer&quot;</span> <span class="token operator">and</span> hp_max <span class="token operator">&gt;</span><span class="token number">6000</span><span class="token punctuation">;</span>
</code></pre></div><p><strong>思考一下：</strong></p> <p>where语句的背后需要进行<strong>全表扫描</strong>才能过滤出结果，对于hive来说需要扫描表下面的每一个文件。如果数据文件特别多的话，效率很慢也没必要。</p> <p>本需求中，只需要扫描archer.txt文件即可，<strong>如何优化可以加快查询，减少全表扫描呢</strong>？</p> <p>指定文件扫描和全表扫描，效率还是存在差异的。</p> <h4 id="分区表的概念和创建"><a href="#分区表的概念和创建" class="header-anchor">#</a> 分区表的概念和创建</h4> <p><strong>概念</strong></p> <p>当Hive表对应的数据量大、文件个数多时，为了避免查询时全表扫描数据，Hive支持<strong>根据指定的字段对表进行分区</strong>，分区的字段可以是日期、地域、种类等具有标识意义的字段。</p> <p>比如把一整年的数据根据月份划分12个月（12个分区），后续就可以查询指定月份分区的数据，尽可能避免了全表扫描查询。</p> <p><img src="/study/assets/img/image-20210828192816908.dcda881d.png" alt="image-20210828192816908"></p> <p><strong>创建</strong></p> <p><img src="/study/assets/img/image-20210828193118647.6cc943ed.png" alt="image-20210828193118647"></p> <p><strong>示例：</strong></p> <p>针对《王者荣耀》英雄数据，重新创建一张分区表t_all_hero_part，以role角色作为分区字段。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">create</span> <span class="token keyword">table</span> t_all_hero_part<span class="token punctuation">(</span>
       id <span class="token keyword">int</span><span class="token punctuation">,</span>
       name string<span class="token punctuation">,</span>
       hp_max <span class="token keyword">int</span><span class="token punctuation">,</span>
       mp_max <span class="token keyword">int</span><span class="token punctuation">,</span>
       attack_max <span class="token keyword">int</span><span class="token punctuation">,</span>
       defense_max <span class="token keyword">int</span><span class="token punctuation">,</span>
       attack_range string<span class="token punctuation">,</span>
       role_main string<span class="token punctuation">,</span>
       role_assist string
<span class="token punctuation">)</span> partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span>role string<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">&quot;\t&quot;</span><span class="token punctuation">;</span>
</code></pre></div><p>需要注意：<strong>分区字段不能是表中已经存在的字段</strong>，因为分区字段最终也会以虚拟字段的形式显示在表结构上。</p> <p><img src="/study/assets/img/image-20210828193622315.438060c2.png" alt="image-20210828193622315"></p> <h4 id="分区表数据加载-静态分区"><a href="#分区表数据加载-静态分区" class="header-anchor">#</a> 分区表数据加载 - 静态分区</h4> <p>所谓<strong>静态分区</strong>指的是<strong>分区的属性值</strong>是由用户在<strong>加载数据的时候手动指定</strong>的。</p> <p>语法如下：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token punctuation">[</span><span class="token keyword">local</span><span class="token punctuation">]</span> inpath <span class="token string">'filepath '</span> <span class="token keyword">into</span> <span class="token keyword">table</span> tablename <span class="token keyword">partition</span><span class="token punctuation">(</span>分区字段<span class="token operator">=</span><span class="token string">'分区值'</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><ul><li><strong>local</strong>参数用于指定<strong>待加载的数据是位于本地文件系统还是HDFS文件系统</strong>。关于load语句后续详细展开讲解。</li></ul> <p>静态加载数据操作如下，文件都位于Hive服务器所在机器本地文件系统上。</p> <p><img src="/study/assets/img/image-20210828194525911.f282477b.png" alt="image-20210828194525911"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/t_all_hero/archer.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_all_hero_part <span class="token keyword">partition</span><span class="token punctuation">(</span>role<span class="token operator">=</span><span class="token string">'sheshou'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/t_all_hero/assassin.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_all_hero_part <span class="token keyword">partition</span><span class="token punctuation">(</span>role<span class="token operator">=</span><span class="token string">'cike'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/t_all_hero/mage.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_all_hero_part <span class="token keyword">partition</span><span class="token punctuation">(</span>role<span class="token operator">=</span><span class="token string">'fashi'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/t_all_hero/support.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_all_hero_part <span class="token keyword">partition</span><span class="token punctuation">(</span>role<span class="token operator">=</span><span class="token string">'fuzhu'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/t_all_hero/tank.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_all_hero_part <span class="token keyword">partition</span><span class="token punctuation">(</span>role<span class="token operator">=</span><span class="token string">'tanke'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/t_all_hero/warrior.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_all_hero_part <span class="token keyword">partition</span><span class="token punctuation">(</span>role<span class="token operator">=</span><span class="token string">'zhanshi'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p>执行load命令后，查询表数据</p> <p><img src="/study/assets/img/image-20210828194730218.b4fba151.png" alt="image-20210828194730218"></p> <p><strong>思考</strong></p> <ol><li>在向Hive分区表加载数据的时候，我们把使用load命令手动指定分区值的方式叫做静态加载，那么有没有动态加载？</li> <li>如果创建的分区很多，是否意味着复制粘贴修改很多load命令去执行，效率低。有没有高效的方法？</li></ol> <h4 id="分区表数据加载-动态分区"><a href="#分区表数据加载-动态分区" class="header-anchor">#</a> 分区表数据加载 - 动态分区</h4> <p>所谓<strong>动态分区</strong>指的是<strong>分区的字段值是基于查询结果</strong>（参数位置）自动推断出来的。核心语法就是<strong>insert+select</strong>。</p> <p>启用hive动态分区，需要在hive会话中设置两个参数：</p> <ul><li>set hive.exec.dynamic.partition=true;</li> <li>set hive.exec.dynamic.partition.mode=nonstrict;</li></ul> <p>第一个参数表示<strong>开启动态分区功能</strong>，第二个参数<strong>指定动态分区的模式</strong>。分为nonstick非严格模式和strict严格模式。<strong>strict严格模式要求至少有一个分区为静态分区</strong>。</p> <p>创建一张新的分区表，执行动态分区插入。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">create</span> <span class="token keyword">table</span> t_all_hero_part_dynamic<span class="token punctuation">(</span>
         id <span class="token keyword">int</span><span class="token punctuation">,</span>
         name string<span class="token punctuation">,</span>
         hp_max <span class="token keyword">int</span><span class="token punctuation">,</span>
         mp_max <span class="token keyword">int</span><span class="token punctuation">,</span>
         attack_max <span class="token keyword">int</span><span class="token punctuation">,</span>
         defense_max <span class="token keyword">int</span><span class="token punctuation">,</span>
         attack_range string<span class="token punctuation">,</span>
         role_main string<span class="token punctuation">,</span>
         role_assist string
<span class="token punctuation">)</span> partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span>role string<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">&quot;\t&quot;</span><span class="token punctuation">;</span>
</code></pre></div><p>执行动态分区插入</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_all_hero_part_dynamic <span class="token keyword">partition</span><span class="token punctuation">(</span>role<span class="token punctuation">)</span> <span class="token keyword">select</span> tmp<span class="token punctuation">.</span><span class="token operator">*</span><span class="token punctuation">,</span>tmp<span class="token punctuation">.</span>role_main <span class="token keyword">from</span> t_all_hero tmp<span class="token punctuation">;</span>
</code></pre></div><p>动态分区插入时，分区值是根据查询返回字段位置自动推断的，同时会把数据存放在不同分区HDFS文件夹下面</p> <h4 id="分区表的本质"><a href="#分区表的本质" class="header-anchor">#</a> 分区表的本质</h4> <p>外表上看起来分区表好像没多大变化，只不过多了一个分区字段。实际上分区表在底层管理数据的方式发生了改变。这里直接去HDFS查看区别。</p> <p><img src="/study/assets/img/image-20210828195553879.7e1e36ff.png" alt="image-20210828195553879"></p> <ul><li><p>分区的概念提供了一种将Hive表数据分离为多个文件/目录的方法。</p></li> <li><p>不同分区对应着不同的文件夹，同一分区的数据存储在同一个文件夹下。</p></li> <li><p>查询过滤的时候只需要根据分区值找到对应的文件夹，扫描本文件夹下本分区下的文件即可，避免全表数据扫描。</p></li> <li><p>这种指定分区查询的方式叫做<strong>分区裁剪</strong>。</p></li></ul> <img src="/study/assets/img/image-20210828202322405.f7013bfc.png" alt="image-20210828202322405" style="zoom:60%;"> <h4 id="分区表的使用"><a href="#分区表的使用" class="header-anchor">#</a> 分区表的使用</h4> <p>分区表的使用重点在于</p> <ul><li>建表时根据业务场景<strong>设置合适的分区字段</strong>。比如日期、地域、类别等；</li> <li>查询的时候<strong>尽量先使用where进行分区过滤</strong>，查询指定分区的数据，避免全表扫描。</li></ul> <p>比如：查询英雄主要定位是射手并且最大生命大于6000的个数。使用分区表查询和使用非分区表进行查询，SQL如下，想一想：底层执行性能来说，分区表的优势在哪里？</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 非分区表 全表扫描过滤查询</span>
<span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">from</span> t_all_hero <span class="token keyword">where</span> role_main<span class="token operator">=</span><span class="token string">&quot;archer&quot;</span> <span class="token operator">and</span> hp_max <span class="token operator">&gt;</span><span class="token number">6000</span><span class="token punctuation">;</span>
<span class="token comment">-- 分区表 先基于分区过滤 再查询</span>
<span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">from</span> t_all_hero_part <span class="token keyword">where</span> role<span class="token operator">=</span><span class="token string">&quot;sheshou&quot;</span> <span class="token operator">and</span> hp_max <span class="token operator">&gt;</span><span class="token number">6000</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="多重分区表"><a href="#多重分区表" class="header-anchor">#</a> 多重分区表</h4> <p>通过建表语句中关于分区的相关语法可以发现，Hive支持多个分区字段：
PARTITIONED BY (partition1 data_type, partition2 data_type,….)。</p> <p><strong>多重分区</strong>下，分区之间是一种<strong>递进关系</strong>，可以理解为在前一个分区的基础上继续分区。从HDFS的角度来看就是文件夹下继续划分子文件夹。</p> <p><img src="/study/assets/img/image-20210828202907409.448fefe5.png" alt="image-20210828202907409"></p> <p>比如：把全国人口数据首先根据省进行分区，然后根据市进行划分，如果你需要甚至可以继续根据区县再划分，此时就是3分区表。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 单分区表，按省份分区</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> t_user_province <span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">,</span>age <span class="token keyword">int</span><span class="token punctuation">)</span> partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span>province string<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 双分区表，按省份和市分区</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> t_user_province_city <span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">,</span>age <span class="token keyword">int</span><span class="token punctuation">)</span> partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span>province string<span class="token punctuation">,</span> city string<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 三分区表，按省份、市、县分区</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> t_user_province_city_county <span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">,</span>age <span class="token keyword">int</span><span class="token punctuation">)</span> partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span>province string<span class="token punctuation">,</span> city string<span class="token punctuation">,</span>county string<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p>多分区表的数据插入和查询使用</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 插入数据</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'文件路径'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_user_province <span class="token keyword">partition</span><span class="token punctuation">(</span>province<span class="token operator">=</span><span class="token string">'shanghai'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'文件路径'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_user_province_city_county <span class="token keyword">partition</span><span class="token punctuation">(</span>province<span class="token operator">=</span><span class="token string">'zhejiang'</span><span class="token punctuation">,</span>city<span class="token operator">=</span><span class="token string">'hangzhou'</span><span class="token punctuation">,</span>county<span class="token operator">=</span><span class="token string">'xiaoshan'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 查询数据</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_user_province_city_county <span class="token keyword">where</span> province<span class="token operator">=</span><span class="token string">'zhejiang'</span> <span class="token operator">and</span> city<span class="token operator">=</span><span class="token string">'hangzhou'</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="分区表的注意事项"><a href="#分区表的注意事项" class="header-anchor">#</a> 分区表的注意事项</h4> <ul><li>分区表不是建表的必要语法规则，是一种<strong>优化手段表</strong>，可选；</li> <li>分区字段<strong>不能是表中已有的字段</strong>，不能重复；</li> <li>分区字段是<strong>虚拟字段</strong>，其数据并<strong>不存储在底层的文件中</strong>；</li> <li>分区字段值的确定来自于用户价值数据手动指定（<strong>静态分区</strong>）或者根据查询结果位置自动推断（<strong>动态分区</strong>）；</li> <li>Hive<strong>支持多重分区</strong>，也就是说在分区的基础上继续分区，划分更加细粒度</li></ul> <h3 id="hive-分桶表"><a href="#hive-分桶表" class="header-anchor">#</a> Hive 分桶表</h3> <h4 id="分桶概念"><a href="#分桶概念" class="header-anchor">#</a> 分桶概念</h4> <p>分桶表也叫做桶表，叫法源自建表语法中bucket单词，是一种用于<strong>优化查询</strong>而设计的表类型。</p> <p>分桶表对应的<strong>数据文件</strong>在底层会被<strong>分解为若干个部分</strong>，通俗来说就是被拆<strong>分成若干个独立的小文件</strong>。</p> <p>在分桶时，要指定根据哪个字段将数据分为几桶（几个部分）。</p> <p><img src="/study/assets/img/image-20210828203659886.d5e2edc0.png" alt="image-20210828203659886"></p> <h4 id="分桶规则"><a href="#分桶规则" class="header-anchor">#</a> 分桶规则</h4> <p>分桶规则如下：<strong>桶编号相同的数据会被分到同一个桶当中</strong>。</p> <p><img src="/study/assets/img/image-20210828203807521.17eaa54f.png" alt="image-20210828203807521"></p> <p>hash_function取决于分桶字段bucketing_column的类型：</p> <ul><li>如果是int类型，hash_function(int) == int;</li> <li>如果是其他比如bigint,string或者复杂数据类型，hash_function比较棘手，将是从该类型派生的某个数字，比如hashcode值。</li></ul> <p><img src="/study/assets/img/image-20210828203909586.9b18ef2b.png" alt="image-20210828203909586"></p> <h4 id="分桶语法"><a href="#分桶语法" class="header-anchor">#</a> 分桶语法</h4> <p><img src="/study/assets/img/image-20210828204503539.0617cfe3.png" alt="image-20210828204503539"></p> <ul><li>CLUSTERED BY (col_name)表示根据哪个字段进行分；</li> <li>INTO num BUCKETS表示分为几桶（也就是几个部分）</li> <li>需要注意的是，<strong>分桶的字段</strong>必须是表中<strong>已经存在的字段</strong>。</li></ul> <h4 id="分桶表的创建"><a href="#分桶表的创建" class="header-anchor">#</a> 分桶表的创建</h4> <p>现有美国2021-1-28号，各个县county的新冠疫情累计案例信息，包括确诊病例和死亡病例，数据格式如下所示：</p> <div class="language-txt extra-class"><pre class="language-text"><code>2021-01-28,Juneau City and Borough,Alaska,02110,1108,3
2021-01-28,Kenai Peninsula Borough,Alaska,02122,3866,18
2021-01-28,Ketchikan Gateway Borough,Alaska,02130,272,1
2021-01-28,Kodiak Island Borough,Alaska,02150,1021,5
2021-01-28,Kusilvak Census Area,Alaska,02158,1099,3
2021-01-28,Lake and Peninsula Borough,Alaska,02164,5,0
2021-01-28,Matanuska-Susitna Borough,Alaska,02170,7406,27
2021-01-28,Nome Census Area,Alaska,02180,307,0
2021-01-28,North Slope Borough,Alaska,02185,973,3
2021-01-28,Northwest Arctic Borough,Alaska,02188,567,1
2021-01-28,Petersburg Borough,Alaska,02195,43,0
</code></pre></div><p>字段含义如下：count_date（统计日期）,county（县）,state（州）,fips（县编码code）,cases（累计确诊病例）,deaths（累计死亡病例）。</p> <p>根据state州把数据分为5桶，建表语句如下：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 根据state州分为5桶</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> testdb<span class="token punctuation">.</span>t_usa_covid19_bucket<span class="token punctuation">(</span>
    count_date string<span class="token punctuation">,</span>
    county string<span class="token punctuation">,</span>
    state string<span class="token punctuation">,</span>
    fips <span class="token keyword">int</span><span class="token punctuation">,</span>
    cases <span class="token keyword">int</span><span class="token punctuation">,</span>
    deaths <span class="token keyword">int</span><span class="token punctuation">)</span>
<span class="token keyword">CLUSTERED</span> <span class="token keyword">BY</span><span class="token punctuation">(</span>state<span class="token punctuation">)</span> <span class="token keyword">INTO</span> <span class="token number">5</span> BUCKETS<span class="token punctuation">;</span>
</code></pre></div><p>在创建分桶表时，还可以指定分桶内的数据排序规则</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 根据state州分为5桶 每个桶内根据cases确诊病例数倒序排序</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> testdb<span class="token punctuation">.</span>t_usa_covid19_bucket_sort<span class="token punctuation">(</span>
      count_date string<span class="token punctuation">,</span>
      county string<span class="token punctuation">,</span>
      state string<span class="token punctuation">,</span>
      fips <span class="token keyword">int</span><span class="token punctuation">,</span>
      cases <span class="token keyword">int</span><span class="token punctuation">,</span>
      deaths <span class="token keyword">int</span><span class="token punctuation">)</span>
<span class="token keyword">CLUSTERED</span> <span class="token keyword">BY</span><span class="token punctuation">(</span>state<span class="token punctuation">)</span> sorted <span class="token keyword">by</span> <span class="token punctuation">(</span>cases <span class="token keyword">desc</span><span class="token punctuation">)</span> <span class="token keyword">INTO</span> <span class="token number">5</span> BUCKETS<span class="token punctuation">;</span>
</code></pre></div><h4 id="分桶数据的加载"><a href="#分桶数据的加载" class="header-anchor">#</a> 分桶数据的加载</h4> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- step1:开启分桶的功能 从Hive2.0开始不再需要设置</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>enforce<span class="token punctuation">.</span>bucketing<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>

<span class="token comment">-- step2:把源数据加载到普通hive表中</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> testdb<span class="token punctuation">.</span>t_usa_covid19<span class="token punctuation">(</span>
       count_date string<span class="token punctuation">,</span>
       county string<span class="token punctuation">,</span>
       state string<span class="token punctuation">,</span>
       fips <span class="token keyword">int</span><span class="token punctuation">,</span>
       cases <span class="token keyword">int</span><span class="token punctuation">,</span>
       deaths <span class="token keyword">int</span><span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">&quot;,&quot;</span><span class="token punctuation">;</span>
<span class="token comment">-- 将源数据上传到HDFS，普通表t_usa_covid19表对应的路径下</span>
hadoop fs <span class="token operator">-</span>put us<span class="token operator">-</span>covid19<span class="token operator">-</span>counties<span class="token punctuation">.</span>dat <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>testdb<span class="token punctuation">.</span>db<span class="token operator">/</span>t_usa_covid19

<span class="token comment">-- step3:使用insert+select语法将数据加载到分桶表中</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> t_usa_covid19_bucket <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19<span class="token punctuation">;</span>
</code></pre></div><p>到HDFS上查看t_usa_covid19_bucket底层数据结构可以发现，数据被分为了5个部分。</p> <p>并且从结果可以发现，分桶字段一样的数据就一定被分到同一个桶中。</p> <p><img src="/study/assets/img/image-20210828210647142.59ae6217.png" alt="image-20210828210647142"></p> <h4 id="分桶表好处"><a href="#分桶表好处" class="header-anchor">#</a> 分桶表好处</h4> <ul><li><p>基于分桶字段查询时，<strong>减少全表扫描</strong></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 基于分桶字段state查询来自于New York州的数据</span>
<span class="token comment">-- 不再需要进行全表扫描过滤</span>
<span class="token comment">-- 根据分桶的规则hash_function(New York) mod 5计算出分桶编号</span>
<span class="token comment">-- 查询指定分桶里面的数据 就可以找出结果  此时是分桶扫描而不是全表扫描</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19_bucket <span class="token keyword">where</span> state<span class="token operator">=</span><span class="token string">&quot;New York&quot;</span><span class="token punctuation">;</span>
</code></pre></div></li> <li><p>JOIN时可以提高MR程序效率，<strong>减少笛卡尔积数量</strong></p> <p>对于JOIN操作两个表有一个相同的列，如果对这两个表都进行了分桶操作。那么将保存相同列值的桶进行JOIN操作就可以，可以大大较少JOIN的数据量。（比如下图中id是join的字段）</p> <p><img src="/study/assets/img/image-20210828211007857.09602fa4.png" alt="image-20210828211007857"></p></li> <li><p>分桶表数据进行高效抽样</p> <p>当数据量特别大时，对全体数据进行处理存在困难时，抽样就显得尤其重要了。<strong>抽样可以从被抽取的数据中估计和推断出整体的特性</strong>，是科学实验、质量检验、社会调查普遍采用的一种经济有效的工作和研究方法。</p></li></ul> <h3 id="hive-事务表"><a href="#hive-事务表" class="header-anchor">#</a> Hive 事务表</h3> <h4 id="hive-事务背景知识"><a href="#hive-事务背景知识" class="header-anchor">#</a> Hive 事务背景知识</h4> <p>Hive设计之初时，是<strong>不支持事务</strong>的，原因：</p> <ul><li>Hive的<strong>核心目标</strong>是将已经存在的<strong>结构化数据</strong>文件<strong>映射</strong>成为表，然后提供基于表的SQL分析处理，是一款面向历史、面向分析的工具；</li> <li>Hive作为数据仓库，是分析数据规律的，而不是创造数据规律的；</li> <li>Hive中表的数据存储于HDFS上，而HDFS是<strong>不支持随机修改文件</strong>数据的，其常见的模型是<strong>一次写入，多次读取</strong>。</li></ul> <p>这个定位就意味着在早期的Hive的SQL语法中是没有update，delete操作的，也就没有所谓事务支持了，因为都是select查询分析操作。</p> <p>从Hive0.14版本开始，具有ACID语义的事务已添加到Hive中，以解决以下场景下遇到的问题：</p> <ul><li><p>流式传输数据</p> <p>使用如Apache Flume、Apache Kafka之类的工具将数据流式传输到Hadoop集群中。虽然这些工具可以每秒数百行或更多行的速度写入数据，但是Hive只能每隔15分钟到一个小时添加一次分区。如果每分甚至每秒频繁添加分区会很快导致表中大量的分区,并将许多小文件留在目录中，这将给NameNode带来压力。</p> <p>因此通常使用这些工具将数据流式传输到已有分区中，但这有<strong>可能会造成脏读</strong>（数据传输一半失败，回滚了）。
需要通过事务功能，允许用户获得一致的数据视图并避免过多的小文件产生。</p></li> <li><p>尺寸变化缓慢</p> <p>星型模式数据仓库中，维度表随时间缓慢变化。例如，零售商将开设新商店，需要将其添加到商店表中，或者现有商店可能会更改其平方英尺或某些其他跟踪的特征。这些更改导致<strong>需要插入单个记录或更新单条记录</strong>（取决于所选策略）。</p></li> <li><p>数据重述</p> <p>有时发现收集的<strong>数据不正确</strong>，<strong>需要更正</strong>。</p></li></ul> <h4 id="hive-事务表局限性"><a href="#hive-事务表局限性" class="header-anchor">#</a> Hive 事务表局限性</h4> <p>虽然Hive支持了具有ACID语义的事务，但是在使用起来，并没有像在MySQL中使用那样方便，有很多局限性。原因很简单，毕竟Hive的设计目标不是为了支持事务操作，而是支持分析操作，且最终基于HDFS的底层存储机制使得文件的增加删除修改操作需要动一些小心思。</p> <ul><li>尚<strong>不支持BEGIN，COMMIT和ROLLBACK</strong>。所有语言操作都是自动提交的。</li> <li>仅支持ORC文件格式（STORED AS ORC）。</li> <li><strong>默认</strong>情况下事务配置为<strong>关闭</strong>。需要配置参数开启使用。</li> <li><strong>表必须是分桶表</strong>（Bucketed）才可以使用事务功能。</li> <li>表参数transactional必须为true；</li> <li>外部表不能成为ACID表，不允许从非ACID会话读取/写入ACID表。</li></ul> <h4 id="案例-创建和使用-hive-事务表"><a href="#案例-创建和使用-hive-事务表" class="header-anchor">#</a> 案例 - 创建和使用 Hive 事务表</h4> <p>如果不做任何配置修改，直接针对Hive中已有的表进行Update、Delete、Insert操作，可以发现，只有insert语句可以执行，Update和Delete操作会报错。</p> <p><img src="/study/assets/img/image-20210828212218981.44d88123.png" alt="image-20210828212218981"></p> <p>Insert插入操作能够成功的原因在于，底层是直接把数据写在一个新的文件中的。</p> <p>下面看一下如何在Hive中配置开启事务表，并且进行操作</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- Hive中事务表的创建使用</span>
<span class="token comment">-- 1、开启事务配置（可以使用set设置当前session生效 也可以配置在hive-site.xml中）</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>support<span class="token punctuation">.</span>concurrency <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">--Hive是否支持并发</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>enforce<span class="token punctuation">.</span>bucketing <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">--从Hive2.0开始不再需要  是否开启分桶功能</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span><span class="token keyword">mode</span> <span class="token operator">=</span> nonstrict<span class="token punctuation">;</span> <span class="token comment">--动态分区模式  非严格</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>txn<span class="token punctuation">.</span>manager <span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>lockmgr<span class="token punctuation">.</span>DbTxnManager<span class="token punctuation">;</span> <span class="token comment">--</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>compactor<span class="token punctuation">.</span>initiator<span class="token punctuation">.</span><span class="token keyword">on</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">--是否在Metastore实例上运行启动线程和清理线程</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>compactor<span class="token punctuation">.</span>worker<span class="token punctuation">.</span>threads <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token comment">--在此metastore实例上运行多少个压缩程序工作线程。</span>

<span class="token comment">-- 2、创建Hive事务表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> trans_student<span class="token punctuation">(</span>
    id <span class="token keyword">int</span><span class="token punctuation">,</span>
    name String<span class="token punctuation">,</span>
    age <span class="token keyword">int</span>
<span class="token punctuation">)</span><span class="token keyword">clustered</span> <span class="token keyword">by</span> <span class="token punctuation">(</span>id<span class="token punctuation">)</span> <span class="token keyword">into</span> <span class="token number">2</span> buckets stored <span class="token keyword">as</span> orc TBLPROPERTIES<span class="token punctuation">(</span><span class="token string">'transactional'</span><span class="token operator">=</span><span class="token string">'true'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 3、针对事务表进行insert update delete操作</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> trans_student <span class="token punctuation">(</span>id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">)</span> <span class="token keyword">values</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">&quot;allen&quot;</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">update</span> trans_student <span class="token keyword">set</span> age <span class="token operator">=</span> <span class="token number">20</span> <span class="token keyword">where</span> id <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>

<span class="token keyword">delete</span> <span class="token keyword">from</span> trans_student <span class="token keyword">where</span> id <span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span>

<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> trans_student<span class="token punctuation">;</span>
</code></pre></div><h4 id="hive-事务表实现原理"><a href="#hive-事务表实现原理" class="header-anchor">#</a> Hive 事务表实现原理</h4> <p>Hive的文件是存储在HDFS上的，而<strong>HDFS上又不支持对文件的任意修改</strong>，只能是采取另外的手段来完成。</p> <ul><li>用HDFS文件作为原始数据（基础数据），用delta保存事务操作的记录增量数据；</li> <li>正在执行中的事务，是以一个staging开头的文件夹维护的，执行结束就是delta文件夹。每次执行一次事务操作都会有这样的一个delta增量文件夹;</li> <li>当访问Hive数据时，根据<strong>HDFS原始文件和delta增量文件做合并</strong>，查询最新的数据。</li></ul> <p><img src="/study/assets/img/image-20210829225902229.993f91ad.png" alt="image-20210829225902229"></p> <ul><li><p>INSERT语句会直接创建delta目录；</p></li> <li><p>DELETE目录的前缀是delete_delta；</p></li> <li><p>UPDATE语句采用了split-update特性，即先删除、后插入；</p></li></ul> <p><img src="/study/assets/img/image-20210829230049282.b3cc63c8.png" alt="image-20210829230049282"></p> <p><strong>delta文件夹命名格式</strong></p> <ul><li><strong>delta_minWID_maxWID_stmtID</strong>，即delta前缀、写事务的ID范围、以及语句ID；删除时前缀是delete_delta，里面包含了要删除的文件；</li> <li>Hive会为写事务（INSERT、DELETE等）创建一个<strong>写事务ID</strong>（Write ID），该ID在表范围内唯一；</li> <li><strong>语句ID</strong>（Statement ID）则是当一个事务中有多条写入语句时使用的，用作唯一标识。</li></ul> <p><img src="/study/assets/img/image-20210829230423121.95478f9a.png" alt="image-20210829230423121"></p> <p>每个事务的delta文件夹下，都有两个文件：每个事务的delta文件夹下，都有两个文件：</p> <ul><li>_orc_acid_version的内容是2,即当前ACID版本号是2。和版本1的主要区别是UPDATE语句采用了split-update特性，即先删除、后插入。这个文件不是ORC文件，可以下载下来直接查看。</li></ul> <p><img src="/study/assets/img/image-20210829230528534.74e77942.png" alt="image-20210829230528534"></p> <ul><li><p>bucket_00000文件则是写入的数据内容。如果事务表没有分区和分桶，就只有一个这样的文件。文件都以ORC格式存储，底层二级制，需要使用ORC TOOLS查看。</p> <p><img src="/study/assets/img/image-20210829230702111.18c38ae7.png" alt="image-20210829230702111"></p> <ul><li>operation：0 表示插入，1 表示更新，2 表示删除。由于使用了split-update，UPDATE是不会出现的，所以delta文件中的operation是0 ， delete_delta 文件中的operation是2。</li> <li>originalTransaction、currentTransaction：该条记录的原始写事务ID，当前的写事务ID。</li> <li>rowId：一个自增的唯一ID，在写事务和分桶的组合中唯一。</li> <li>row：具体数据。对于DELETE语句，则为null，对于INSERT就是插入的数据，对于UPDATE就是更新后的数据。</li></ul></li></ul> <p><strong>合并器(Compactor)</strong></p> <ul><li>随着表的修改操作，创建了越来越多的delta增量文件，就需要合并以保持足够的性能。</li> <li>合并器Compactor是一套在Hive Metastore内运行，支持ACID系统的后台进程。所有合并都是在后台完成的，不会阻止数据的并发读、写。合并后，系统将等待所有旧文件的读操作完成后，删除旧文件。</li> <li>合并操作分为两种，minor compaction（小合并）、major compaction（大合并）：
<ul><li>小合并会将一组delta增量文件重写为单个增量文件，默认触发条件为10个delta文件；</li> <li>大合并将一个或多个增量文件和基础文件重写为新的基础文件，默认触发条件为delta文件相应于基础文件占比，10%</li></ul></li></ul> <p><img src="/study/assets/img/image-20210829231023443.885f9c57.png" alt="image-20210829231023443"></p> <h3 id="hive-view-视图"><a href="#hive-view-视图" class="header-anchor">#</a> Hive View 视图</h3> <h4 id="视图概念"><a href="#视图概念" class="header-anchor">#</a> 视图概念</h4> <p>Hive中的视图（view）是一种虚拟表，只保存定义，不实际存储数据。通常从真实的物理表查询中创建生成视图，也可以从已经存在的视图上创建新视图。</p> <p>创建视图时，将冻结视图的架构，如果删除或更改基础表，则视图将失败，并且视图不能存储数据，操作数据，只能查询。</p> <p><strong>视图是用来简化操作的，它其实是一张虚表，在视图中不缓冲记录，也没有提高查询性能。</strong></p> <p><img src="/study/assets/img/image-20210828212814705.4225792f.png" alt="image-20210828212814705"></p> <h4 id="相关语法"><a href="#相关语法" class="header-anchor">#</a> 相关语法</h4> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- hive中有一张真实的基础表t_usa_covid19</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> test<span class="token punctuation">.</span>t_usa_covid19<span class="token punctuation">;</span>

<span class="token comment">-- 1、创建视图</span>
<span class="token keyword">create</span> <span class="token keyword">view</span> v_usa_covid19 <span class="token keyword">as</span> <span class="token keyword">select</span> count_date<span class="token punctuation">,</span> county<span class="token punctuation">,</span>state<span class="token punctuation">,</span>deaths <span class="token keyword">from</span> t_usa_covid19 <span class="token keyword">limit</span> <span class="token number">5</span><span class="token punctuation">;</span>

<span class="token comment">-- 能否从已有的视图中创建视图呢  可以的</span>
<span class="token keyword">create</span> <span class="token keyword">view</span> v_usa_covid19_from_view <span class="token keyword">as</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> v_usa_covid19 <span class="token keyword">limit</span> <span class="token number">2</span><span class="token punctuation">;</span>

<span class="token comment">-- 2、显示当前已有的视图 </span>
<span class="token keyword">show</span> <span class="token keyword">tables</span><span class="token punctuation">;</span>
<span class="token keyword">show</span> views<span class="token punctuation">;</span><span class="token comment">-- hive v2.2.0之后支持</span>

<span class="token comment">-- 3、视图的查询使用</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> v_usa_covid19<span class="token punctuation">;</span>

<span class="token comment">-- 能否插入数据到视图中呢？</span>
<span class="token comment">-- 不行 报错  SemanticException:A view cannot be used as target table for LOAD or INSERT</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> v_usa_covid19 <span class="token keyword">select</span> count_date<span class="token punctuation">,</span>county<span class="token punctuation">,</span>state<span class="token punctuation">,</span>deaths <span class="token keyword">from</span> t_usa_covid19<span class="token punctuation">;</span>

<span class="token comment">-- 4、查看视图定义</span>
<span class="token keyword">show</span> <span class="token keyword">create</span> <span class="token keyword">table</span> v_usa_covid19<span class="token punctuation">;</span>

<span class="token comment">-- 5、删除视图</span>
<span class="token keyword">drop</span> <span class="token keyword">view</span> v_usa_covid19_from_view<span class="token punctuation">;</span>

<span class="token comment">-- 6、更改视图属性</span>
<span class="token keyword">alter</span> <span class="token keyword">view</span> v_usa_covid19 <span class="token keyword">set</span> TBLPROPERTIES <span class="token punctuation">(</span><span class="token string">'comment'</span> <span class="token operator">=</span> <span class="token string">'This is a view'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 7、更改视图定义</span>
<span class="token keyword">alter</span> <span class="token keyword">view</span> v_usa_covid19 <span class="token keyword">as</span>  <span class="token keyword">select</span> county<span class="token punctuation">,</span>deaths <span class="token keyword">from</span> t_usa_covid19 <span class="token keyword">limit</span> <span class="token number">2</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="视图好处"><a href="#视图好处" class="header-anchor">#</a> 视图好处</h4> <ul><li>将真实表中特定的列数据提供给用户，保护数据隐式</li></ul> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 通过视图来限制数据访问可以用来保护信息不被随意查询:</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> userinfo<span class="token punctuation">(</span>firstname string<span class="token punctuation">,</span> lastname string<span class="token punctuation">,</span> ssn string<span class="token punctuation">,</span> password string<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">create</span> <span class="token keyword">view</span> safer_user_info <span class="token keyword">as</span> <span class="token keyword">select</span> firstname<span class="token punctuation">,</span> lastname <span class="token keyword">from</span> userinfo<span class="token punctuation">;</span>

<span class="token comment">-- 可以通过where子句限制数据访问，比如，提供一个员工表视图，只暴露来自特定部门的员工信息:</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> employee<span class="token punctuation">(</span>firstname string<span class="token punctuation">,</span> lastname string<span class="token punctuation">,</span> ssn string<span class="token punctuation">,</span> password string<span class="token punctuation">,</span> department string<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">create</span> <span class="token keyword">view</span> techops_employee <span class="token keyword">as</span> <span class="token keyword">select</span> firstname<span class="token punctuation">,</span> lastname<span class="token punctuation">,</span> ssn <span class="token keyword">from</span> userinfo <span class="token keyword">where</span> department <span class="token operator">=</span> <span class="token string">'java'</span><span class="token punctuation">;</span>
</code></pre></div><ul><li><p>降低查询的复杂度，优化查询语句</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 使用视图优化嵌套查询</span>
<span class="token keyword">from</span> <span class="token punctuation">(</span>
   <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> people <span class="token keyword">join</span> cart
   <span class="token keyword">on</span><span class="token punctuation">(</span>cart<span class="token punctuation">.</span>pepople_id <span class="token operator">=</span> people<span class="token punctuation">.</span>id<span class="token punctuation">)</span> <span class="token keyword">where</span> firstname <span class="token operator">=</span> <span class="token string">'join'</span>
     <span class="token punctuation">)</span>a <span class="token keyword">select</span> a<span class="token punctuation">.</span>lastname <span class="token keyword">where</span> a<span class="token punctuation">.</span>id <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span>

<span class="token comment">-- 把嵌套子查询变成一个视图</span>
<span class="token keyword">create</span> <span class="token keyword">view</span> shorter_join <span class="token keyword">as</span>
	<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> people <span class="token keyword">join</span> cart <span class="token keyword">on</span> <span class="token punctuation">(</span>cart<span class="token punctuation">.</span>pepople_id <span class="token operator">=</span> people<span class="token punctuation">.</span>id<span class="token punctuation">)</span> <span class="token keyword">where</span> firstname <span class="token operator">=</span> <span class="token string">'join'</span><span class="token punctuation">;</span>
	
<span class="token comment">-- 基于视图查询</span>
<span class="token keyword">select</span> lastname <span class="token keyword">from</span> shorter_join <span class="token keyword">where</span> id <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span>
</code></pre></div></li></ul> <h3 id="hive3-0-新特性-物化视图"><a href="#hive3-0-新特性-物化视图" class="header-anchor">#</a> Hive3.0 新特性 - 物化视图</h3> <h4 id="物化视图概念"><a href="#物化视图概念" class="header-anchor">#</a> 物化视图概念</h4> <p><strong>物化视图</strong>（Materialized View）是一个<strong>包括查询结果</strong>的数据库对像，可以用于<strong>预先计算</strong>并保存表连接或聚集等耗时较多的操作的结果。在执行查询时，就可以避免进行这些耗时的操作，而从快速的得到结果。</p> <p>使用物化视图的目的就是<strong>通过预计算，提高查询性能</strong>，<strong>当然需要占用一定的存储空间。</strong></p> <p><img src="/study/assets/img/image-20210828213557663.3f53345f.png" alt="image-20210828213557663"></p> <p>Hive3.0开始尝试引入物化视图，并提供对于<strong>物化视图的查询自动重写机制</strong>（基于Apache Calcite实现）。</p> <p>Hive的物化视图还提供了<strong>物化视图存储选择机制</strong>，可以本地存储在Hive，也可以通过用户自定义storage handlers存储在其他系统（如Druid）。</p> <p>Hive引入物化视图的目的就是为了<strong>优化数据查询访问的效率,相当于从数据预处理的角度优化数据访问</strong>。</p> <p>Hive从3.0丢弃了index索引的语法支持，推荐使用物化视图和列式存储文件格式来加快查询的速度。</p> <h4 id="物化视图、视图区别"><a href="#物化视图、视图区别" class="header-anchor">#</a> 物化视图、视图区别</h4> <ul><li><p><strong>视图是虚拟</strong>的，逻辑存在的，只有定义没有存储数据。</p></li> <li><p><strong>物化视图是真实</strong>的，物理存在的，<strong>里面存储着预计算的数据</strong>。</p> <p>物化视图能够缓存数据，在创建物化视图的时候就把数据缓存起来了，Hive把物化视图当成一张“表”，将数据缓存。而视图只是创建一个虚表，只有表结构，没有数据，实际查询的时候再去改写SQL去访问实际的数据表。</p></li> <li><p><strong>视图的目的</strong>是<strong>简化</strong>降低查询的<strong>复杂度</strong>，而<strong>物化视图</strong>的<strong>目的</strong>是<strong>提高查询性能</strong>。</p></li></ul> <h4 id="物化视图语法"><a href="#物化视图语法" class="header-anchor">#</a> 物化视图语法</h4> <p><img src="/study/assets/img/image-20210828214031346.e5e57fc9.png" alt="image-20210828214031346"></p> <ul><li><p>物化视图创建后，select查询执行数据自动落地，“自动”也即在query的执行期间，任何用户对该物化视图是不可见的,执行完毕之后物化视图可用；</p></li> <li><p>默认情况下，创建好的物化视图可被用于查询优化器optimizer查询重写，在物化视图创建期间可以通过 DISABLE REWRITE 参数设置禁止使用。</p></li> <li><p>默认SerDe和storage format为hive.materializedview.serde、 hive.materializedview.fileformat；</p></li> <li><p>物化视图支持将数据存储在外部系统（如druid），如下述语法所示：</p> <p><img src="/study/assets/img/image-20210828214135953.746caa65.png" alt="image-20210828214135953"></p></li> <li><p>目前支持物化视图的drop和show操作，后续会增加其他操作</p> <p><img src="/study/assets/img/image-20210828214210421.8e82163b.png" alt="image-20210828214210421"></p></li> <li><p>当数据源变更（新数据插入inserted、数据修改modified），物化视图也需要更新以保持数据一致性，目前需要用户主动触发rebuild重构。</p> <p><img src="data:image/png;base64,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" alt="image-20210828214229864"></p></li></ul> <h4 id="基于物化视图的查询重写"><a href="#基于物化视图的查询重写" class="header-anchor">#</a> 基于物化视图的查询重写</h4> <p>物化视图创建后即可用于相关查询的加速，即：用户提交查询query，若该query经过重写后可以命中已经存在的物化视图，则直接通过物化视图查询数据返回结果，以实现查询加速。</p> <p>是否重写查询使用物化视图可以通过全局参数控制，默认为true： hive.materializedview.rewriting=true;</p> <p>用户可选择性的控制指定的物化视图查询重写机制，语法如下：</p> <p><img src="data:image/png;base64,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" alt="image-20210828214426657"></p> <h4 id="案例-基于物化视图的重写查询"><a href="#案例-基于物化视图的重写查询" class="header-anchor">#</a> 案例 - 基于物化视图的重写查询</h4> <ol><li>用户提交查询query</li> <li>若该query经过重写后可以命中已经存在的物化视图</li> <li>则直接通过物化视图查询数据返回结果，以实现查询加速</li></ol> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 1、新建一张事务表 student_trans</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>support<span class="token punctuation">.</span>concurrency <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">--Hive是否支持并发</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>enforce<span class="token punctuation">.</span>bucketing <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">--从Hive2.0开始不再需要  是否开启分桶功能</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span><span class="token keyword">mode</span> <span class="token operator">=</span> nonstrict<span class="token punctuation">;</span> <span class="token comment">--动态分区模式  非严格</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>txn<span class="token punctuation">.</span>manager <span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>lockmgr<span class="token punctuation">.</span>DbTxnManager<span class="token punctuation">;</span> <span class="token comment">--</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>compactor<span class="token punctuation">.</span>initiator<span class="token punctuation">.</span><span class="token keyword">on</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">--是否在Metastore实例上运行启动线程和清理线程</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>compactor<span class="token punctuation">.</span>worker<span class="token punctuation">.</span>threads <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token comment">--在此metastore实例上运行多少个压缩程序工作线程。</span>

<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> student_trans <span class="token punctuation">(</span>
      sno <span class="token keyword">int</span><span class="token punctuation">,</span>
      sname string<span class="token punctuation">,</span>
      sdept string<span class="token punctuation">)</span>
<span class="token keyword">clustered</span> <span class="token keyword">by</span> <span class="token punctuation">(</span>sno<span class="token punctuation">)</span> <span class="token keyword">into</span> <span class="token number">2</span> buckets stored <span class="token keyword">as</span> orc TBLPROPERTIES<span class="token punctuation">(</span><span class="token string">'transactional'</span><span class="token operator">=</span><span class="token string">'true'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


<span class="token comment">-- 2、导入数据到student_trans中</span>
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> student_trans
<span class="token keyword">select</span> sno<span class="token punctuation">,</span>sname<span class="token punctuation">,</span>sdept
<span class="token keyword">from</span> student<span class="token punctuation">;</span>

<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student_trans<span class="token punctuation">;</span>

<span class="token comment">-- 3、对student_trans建立聚合物化视图</span>
<span class="token keyword">CREATE</span> MATERIALIZED <span class="token keyword">VIEW</span> student_trans_agg
<span class="token keyword">AS</span> <span class="token keyword">SELECT</span> sdept<span class="token punctuation">,</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sdept_cnt <span class="token keyword">from</span> student_trans <span class="token keyword">group</span> <span class="token keyword">by</span> sdept<span class="token punctuation">;</span>

<span class="token comment">-- 注意 这里当执行CREATE MATERIALIZED VIEW，会启动一个MR对物化视图进行构建</span>
<span class="token comment">-- 可以发现当下的数据库中有了一个物化视图</span>
<span class="token keyword">show</span> <span class="token keyword">tables</span><span class="token punctuation">;</span>
<span class="token keyword">show</span> materialized views<span class="token punctuation">;</span>

<span class="token comment">-- 4、对原始表student_trans查询</span>
<span class="token comment">-- 由于会命中物化视图，重写query查询物化视图，查询速度会加快（没有启动MR，只是普通的table scan）</span>
<span class="token keyword">SELECT</span> sdept<span class="token punctuation">,</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sdept_cnt <span class="token keyword">from</span> student_trans <span class="token keyword">group</span> <span class="token keyword">by</span> sdept<span class="token punctuation">;</span>

<span class="token comment">-- 5、查询执行计划可以发现 查询被自动重写为TableScan alias: test.student_trans_agg</span>
<span class="token comment">-- 转换成了对物化视图的查询  提高了查询效率</span>
<span class="token keyword">explain</span> <span class="token keyword">SELECT</span> sdept<span class="token punctuation">,</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sdept_cnt <span class="token keyword">from</span> student_trans <span class="token keyword">group</span> <span class="token keyword">by</span> sdept<span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210828214847293.ed2bc7b8.png" alt="image-20210828214847293"></p> <h2 id="hive-ddl-其它语法"><a href="#hive-ddl-其它语法" class="header-anchor">#</a> Hive DDL 其它语法</h2> <h3 id="database-schema-数据库-ddl操作"><a href="#database-schema-数据库-ddl操作" class="header-anchor">#</a> Database|Schema （数据库）DDL操作</h3> <h4 id="整体概述-2"><a href="#整体概述-2" class="header-anchor">#</a> 整体概述</h4> <p>在Hive中，DATABASE的概念和RDBMS中类似，我们称之为数据库，DATABASE和SCHEMA是可互换的，都可以使用。</p> <p>默认的数据库叫做default，存储数据位置位于/user/hive/warehouse下。</p> <p>用户自己创建的数据库存储位置是/user/hive/warehouse/database_name.db下。</p> <h4 id="create-database"><a href="#create-database" class="header-anchor">#</a> create database</h4> <p>create database用于创建新的数据库</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">CREATE</span> <span class="token punctuation">(</span><span class="token keyword">DATABASE</span><span class="token operator">|</span><span class="token keyword">SCHEMA</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token operator">NOT</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> database_name
<span class="token punctuation">[</span><span class="token keyword">COMMENT</span> database_comment<span class="token punctuation">]</span>
<span class="token punctuation">[</span>LOCATION hdfs_path<span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token keyword">WITH</span> DBPROPERTIES <span class="token punctuation">(</span>property_name<span class="token operator">=</span>property_value<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
</code></pre></div><ul><li>COMMENT：数据库的注释说明语句</li> <li>LOCATION：指定数据库在HDFS存储位置，默认/user/hive/warehouse/dbname.db</li> <li>WITH DBPROPERTIES：用于指定一些数据库的属性配置。</li></ul> <p>例子：创建数据库testdb</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">create</span> <span class="token keyword">database</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> firstdb
<span class="token keyword">comment</span> <span class="token string">&quot;this is my first db&quot;</span>
<span class="token keyword">with</span> dbproperties <span class="token punctuation">(</span><span class="token string">'createdBy'</span><span class="token operator">=</span><span class="token string">'AllenWoon'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210829132026903.2b1ee8cf.png" alt="image-20210829132026903"></p> <p>**注意：**如果需要使用location指定路径的时候，最好指向的是一个新创建的空文件夹。</p> <h4 id="describe-database"><a href="#describe-database" class="header-anchor">#</a> describe database</h4> <p>显示Hive中数据库的名称，注释（如果已设置）及其在文件系统上的位置等信息。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">DESCRIBE</span> <span class="token keyword">DATABASE</span><span class="token operator">/</span><span class="token keyword">SCHEMA</span> <span class="token punctuation">[</span><span class="token keyword">EXTENDED</span><span class="token punctuation">]</span> db_name<span class="token punctuation">;</span>
</code></pre></div><ul><li>EXTENDED：用于显示更多信息。可以将关键字describe简写成desc使用。</li></ul> <p><img src="/study/assets/img/image-20210829132224442.bcb414a4.png" alt="image-20210829132224442"></p> <p><img src="/study/assets/img/image-20210829132303837.3e034ff5.png" alt="image-20210829132303837"></p> <h4 id="use-database"><a href="#use-database" class="header-anchor">#</a> use database</h4> <p>选择特定的数据库，切换当前会话使用哪一个数据库进行操作</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">USE</span> database_name<span class="token punctuation">;</span>
</code></pre></div><h4 id="drop-database"><a href="#drop-database" class="header-anchor">#</a> drop database</h4> <p>删除数据库</p> <ul><li>默认行为是RESTRICT，这意味着仅在数据库为空时才删除它。<strong>要删除带有表的数据库（不为空的数据库），我们可以使用CASCADE</strong>。</li></ul> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">DROP</span> <span class="token punctuation">(</span><span class="token keyword">DATABASE</span><span class="token operator">|</span><span class="token keyword">SCHEMA</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> database_name <span class="token punctuation">[</span><span class="token keyword">RESTRICT</span><span class="token operator">|</span><span class="token keyword">CASCADE</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="alter-database"><a href="#alter-database" class="header-anchor">#</a> alter database</h4> <p>更改与Hive中的数据库关联的元数据</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 更改数据库属性</span>
<span class="token keyword">ALTER</span> <span class="token punctuation">(</span><span class="token keyword">DATABASE</span><span class="token operator">|</span><span class="token keyword">SCHEMA</span><span class="token punctuation">)</span> database_name <span class="token keyword">SET</span> DBPROPERTIES <span class="token punctuation">(</span>property_name<span class="token operator">=</span>property_value<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 更改数据库所有者</span>
<span class="token keyword">ALTER</span> <span class="token punctuation">(</span><span class="token keyword">DATABASE</span><span class="token operator">|</span><span class="token keyword">SCHEMA</span><span class="token punctuation">)</span> database_name <span class="token keyword">SET</span> OWNER <span class="token punctuation">[</span><span class="token keyword">USER</span><span class="token operator">|</span>ROLE<span class="token punctuation">]</span> user_or_role<span class="token punctuation">;</span>

<span class="token comment">-- 更改数据库位置</span>
<span class="token keyword">ALTER</span> <span class="token punctuation">(</span><span class="token keyword">DATABASE</span><span class="token operator">|</span><span class="token keyword">SCHEMA</span><span class="token punctuation">)</span> database_name <span class="token keyword">SET</span> LOCATION hdfs_path<span class="token punctuation">;</span>
</code></pre></div><h3 id="table-表-ddl操作"><a href="#table-表-ddl操作" class="header-anchor">#</a> Table（表）DDL操作</h3> <h4 id="整体概述-3"><a href="#整体概述-3" class="header-anchor">#</a> 整体概述</h4> <p>Hive中针对表的DDL操作可以说是DDL中的核心操作，包括建表、修改表、删除表、描述表元数据信息。</p> <p>其中以建表语句为核心中的核心，详见Hive DDL建表语句。</p> <p>可以说表的定义是否成功直接影响着数据能够成功映射，进而影响是否可以顺利的使用Hive开展数据分析。</p> <p>由于Hive建表之后加载映射数据很快，实际中如果建表有问题，可以不用修改，直接删除重建。</p> <h4 id="describe-table"><a href="#describe-table" class="header-anchor">#</a> describe table</h4> <p>显示Hive中表的元数据信息</p> <ul><li>如果指定了EXTENDED关键字，则它将以Thrift序列化形式显示表的所有元数据。</li> <li>如果指定了FORMATTED关键字，则它将以表格格式显示元数据。</li></ul> <p><img src="/study/assets/img/image-20210829133207884.c4541a63.png" alt="image-20210829133207884"></p> <p><img src="/study/assets/img/image-20210829133236534.5b282cd8.png" alt="image-20210829133236534"></p> <p><img src="/study/assets/img/image-20210829133300018.a37f94c4.png" alt="image-20210829133300018"></p> <h4 id="drop-table"><a href="#drop-table" class="header-anchor">#</a> drop table</h4> <p>删除该表的元数据和数据</p> <ul><li>如果已配置垃圾桶且未指定PURGE，则该表对应的数据实际上将移动到HDFS垃圾桶，而元数据完全丢失。</li> <li>删除EXTERNAL表时，该表中的数据不会从文件系统中删除，只删除元数据。</li> <li>如果指定了PURGE，则表数据跳过HDFS垃圾桶直接被删除。因此如果DROP失败，则无法挽回该表数据。</li></ul> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">DROP</span> <span class="token keyword">TABLE</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> table_name <span class="token punctuation">[</span><span class="token keyword">PURGE</span><span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token comment">-- (Note: PURGE available in Hive 0.14.0 and later)</span>
</code></pre></div><h4 id="truncate-table"><a href="#truncate-table" class="header-anchor">#</a> truncate table</h4> <p>从表中删除所有行。</p> <ul><li>可以简单理解为<strong>清空表的所有数据</strong>但是<strong>保留表的元数据结构</strong>。</li> <li>如果HDFS启用了垃圾桶，数据将被丢进垃圾桶，否则将被删除。</li></ul> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">TRUNCATE</span> <span class="token punctuation">[</span><span class="token keyword">TABLE</span><span class="token punctuation">]</span> table_name<span class="token punctuation">;</span>
</code></pre></div><h4 id="alter-table"><a href="#alter-table" class="header-anchor">#</a> alter table</h4> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 1、更改表名</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">RENAME</span> <span class="token keyword">TO</span> new_table_name<span class="token punctuation">;</span>

<span class="token comment">-- 2、更改表属性</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">SET</span> TBLPROPERTIES <span class="token punctuation">(</span>property_name <span class="token operator">=</span> property_value<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">-- 更改表注释</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> student <span class="token keyword">SET</span> TBLPROPERTIES <span class="token punctuation">(</span><span class="token string">'comment'</span> <span class="token operator">=</span> <span class="token string">&quot;new comment for student table&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 3、更改SerDe属性</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">SET</span> SERDE serde_class_name <span class="token punctuation">[</span><span class="token keyword">WITH</span> SERDEPROPERTIES <span class="token punctuation">(</span>property_name <span class="token operator">=</span> property_value<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token punctuation">[</span><span class="token keyword">PARTITION</span> partition_spec<span class="token punctuation">]</span> <span class="token keyword">SET</span> SERDEPROPERTIES serde_properties<span class="token punctuation">;</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">SET</span> SERDEPROPERTIES <span class="token punctuation">(</span><span class="token string">'field.delim'</span> <span class="token operator">=</span> <span class="token string">','</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">-- 移除SerDe属性</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token punctuation">[</span><span class="token keyword">PARTITION</span> partition_spec<span class="token punctuation">]</span> UNSET SERDEPROPERTIES <span class="token punctuation">(</span>property_name<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 4、更改表的文件存储格式 该操作仅更改表元数据。现有数据的任何转换都必须在Hive之外进行。</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name  <span class="token keyword">SET</span> FILEFORMAT file_format<span class="token punctuation">;</span>

<span class="token comment">-- 5、更改表的存储位置路径</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">SET</span> LOCATION <span class="token string">&quot;new location&quot;</span><span class="token punctuation">;</span>

<span class="token comment">-- 6、更改列名称/类型/位置/注释</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> test_change <span class="token punctuation">(</span>a <span class="token keyword">int</span><span class="token punctuation">,</span> b <span class="token keyword">int</span><span class="token punctuation">,</span> c <span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// First change column a's name to a1.</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> test_change CHANGE a a1 <span class="token keyword">INT</span><span class="token punctuation">;</span>
<span class="token comment">// Next change column a1's name to a2, its data type to string, and put it after column b.</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> test_change CHANGE a1 a2 STRING <span class="token keyword">AFTER</span> b<span class="token punctuation">;</span>
<span class="token comment">// The new table's structure is:  b int, a2 string, c int.</span>
<span class="token comment">// Then change column c's name to c1, and put it as the first column.</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> test_change CHANGE c c1 <span class="token keyword">INT</span> <span class="token keyword">FIRST</span><span class="token punctuation">;</span>
<span class="token comment">// The new table's structure is:  c1 int, b int, a2 string.</span>
<span class="token comment">// Add a comment to column a1</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> test_change CHANGE a1 a1 <span class="token keyword">INT</span> <span class="token keyword">COMMENT</span> <span class="token string">'this is column a1'</span><span class="token punctuation">;</span>

<span class="token comment">-- 7、添加/替换列</span>
<span class="token comment">-- 使用ADD COLUMNS，您可以将新列添加到现有列的末尾但在分区列之前。</span>
<span class="token comment">-- REPLACE COLUMNS 将删除所有现有列，并添加新的列集。</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">ADD</span><span class="token operator">|</span><span class="token keyword">REPLACE</span> <span class="token keyword">COLUMNS</span> <span class="token punctuation">(</span>col_name data_type<span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h3 id="partition-分区-ddl操作"><a href="#partition-分区-ddl操作" class="header-anchor">#</a> Partition（分区）DDL操作</h3> <h4 id="整体概述-4"><a href="#整体概述-4" class="header-anchor">#</a> 整体概述</h4> <p>Hive中针对分区Partition的操作主要包括：增加分区、删除分区、重命名分区、修复分区、修改分区。</p> <h4 id="add-partition"><a href="#add-partition" class="header-anchor">#</a> add partition</h4> <p>分区值仅在为字符串时才应加引号。位置必须是数据文件所在的目录。</p> <p>ADD PARTITION会更改表元数据，但不会加载数据。如果分区位置中不存在数据，查询时将不会返回结果。因此需要保证增加的分区位置路径下，数据已经存在，或者增加完分区之后导入分区数据。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 1、增加分区</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">ADD</span> <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'20170101'</span><span class="token punctuation">)</span> location <span class="token string">'/user/hadoop/warehouse/table_name/dt=20170101'</span><span class="token punctuation">;</span> 
<span class="token comment">-- 一次添加一个分区</span>

<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">ADD</span> <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'2008-08-08'</span><span class="token punctuation">,</span> country<span class="token operator">=</span><span class="token string">'us'</span><span class="token punctuation">)</span> location <span class="token string">'/path/to/us/part080808'</span>
                       <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'2008-08-09'</span><span class="token punctuation">,</span> country<span class="token operator">=</span><span class="token string">'us'</span><span class="token punctuation">)</span> location <span class="token string">'/path/to/us/part080809'</span><span class="token punctuation">;</span>  
<span class="token comment">-- 一次添加多个分区</span>
</code></pre></div><h4 id="rename-partition"><a href="#rename-partition" class="header-anchor">#</a> rename partition</h4> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 2、重命名分区</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">PARTITION</span> partition_spec <span class="token keyword">RENAME</span> <span class="token keyword">TO</span> <span class="token keyword">PARTITION</span> partition_spec<span class="token punctuation">;</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'2008-08-09'</span><span class="token punctuation">)</span> <span class="token keyword">RENAME</span> <span class="token keyword">TO</span> <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'20080809'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="delete-partition"><a href="#delete-partition" class="header-anchor">#</a> delete partition</h4> <p>可以使用ALTER TABLE DROP PARTITION删除表的分区。这将删除该分区的数据和元数据。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 3、删除分区</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">DROP</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'2008-08-08'</span><span class="token punctuation">,</span> country<span class="token operator">=</span><span class="token string">'us'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">DROP</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'2008-08-08'</span><span class="token punctuation">,</span> country<span class="token operator">=</span><span class="token string">'us'</span><span class="token punctuation">)</span> <span class="token keyword">PURGE</span><span class="token punctuation">;</span> <span class="token comment">-- 直接删除数据 不进垃圾桶</span>
</code></pre></div><h4 id="alter-partition"><a href="#alter-partition" class="header-anchor">#</a> alter partition</h4> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 4、修改分区</span>
<span class="token comment">-- 更改分区文件存储格式</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'2008-08-09'</span><span class="token punctuation">)</span> <span class="token keyword">SET</span> FILEFORMAT file_format<span class="token punctuation">;</span>
<span class="token comment">-- 更改分区位置</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'2008-08-09'</span><span class="token punctuation">)</span> <span class="token keyword">SET</span> LOCATION <span class="token string">&quot;new location&quot;</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="mack-partition"><a href="#mack-partition" class="header-anchor">#</a> mack partition</h4> <p>Hive将每个表的分区列表信息存储在其metastore中。但是，如果将新分区直接添加到HDFS（例如通过使用hadoop fs -put命令）或从HDFS中直接删除分区文件夹，则除非用户ALTER TABLE table_name ADD/DROP PARTITION在每个新添加的分区上运行命令，否则metastore（也就是Hive）将不会意识到分区信息的这些更改。</p> <p><strong>MSCK是metastore check</strong>的缩写，表示<strong>元数据检查操作</strong>，可用于元数据的修复。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 5、修复分区</span>
MSCK <span class="token punctuation">[</span>REPAIR<span class="token punctuation">]</span> <span class="token keyword">TABLE</span> table_name <span class="token punctuation">[</span><span class="token keyword">ADD</span><span class="token operator">/</span><span class="token keyword">DROP</span><span class="token operator">/</span>SYNC PARTITIONS<span class="token punctuation">]</span><span class="token punctuation">;</span>
</code></pre></div><ul><li><p>MSCK默认行为ADD PARTITIONS，使用此选项，它将把HDFS上存在但元存储中不存在的所有分区添加到metastore。</p></li> <li><p>DROP PARTITIONS选项将从已经从HDFS中删除的metastore中删除分区信息。</p></li> <li><p>SYNC PARTITIONS选项等效于调用ADD和DROP PARTITIONS。</p></li> <li><p>如果存在大量未跟踪的分区，则可以批量运行MSCK REPAIR TABLE，以避免OOME（内存不足错误）。</p></li></ul> <h4 id="案例-msck-修复parttion"><a href="#案例-msck-修复parttion" class="header-anchor">#</a> 案例 - MSCK 修复parttion</h4> <ol><li><p>创建一张分区表，直接使用HDFS命令在表文件夹下创建分区文件夹并上传数据，此时在Hive中查询是无法显示表数据的，因为metastore中没有记录，使用<strong>MSCK ADD PARTITIONS</strong>进行修复。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">--Step1：创建分区表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> t_all_hero_part_msck<span class="token punctuation">(</span>       
    id <span class="token keyword">int</span><span class="token punctuation">,</span>       
    name string<span class="token punctuation">,</span>       
    hp_max <span class="token keyword">int</span><span class="token punctuation">,</span>       
    mp_max <span class="token keyword">int</span><span class="token punctuation">,</span>       
    attack_max <span class="token keyword">int</span><span class="token punctuation">,</span>       
    defense_max <span class="token keyword">int</span><span class="token punctuation">,</span>       
    attack_range string<span class="token punctuation">,</span>       
    role_main string<span class="token punctuation">,</span>       
    role_assist string<span class="token punctuation">)</span> 
partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span>role string<span class="token punctuation">)</span> 
<span class="token keyword">row</span> format delimited 
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">&quot;\t&quot;</span><span class="token punctuation">;</span>

<span class="token comment">-- Step2：在linux上，使用HDFS命令创建分区文件夹</span>
<span class="token comment"># hadoop fs -mkdir -p /user/hive/warehouse/t_all_hero.db/t_all_hero_part_msck/role=sheshou</span>
<span class="token comment"># hadoop fs -mkdir -p /user/hive/warehouse/t_all_hero.db/t_all_hero_part_msck/role=tanke</span>
<span class="token comment">-- Step3：把数据文件上传到对应的分区文件夹下</span>
<span class="token comment"># hadoop fs -put archer.txt /user/hive/warehouse/t_all_hero.db/t_all_hero_part_msck/role=sheshou</span>
<span class="token comment"># hadoop fs -put tank.txt /user/hive/warehouse/itheima.db/t_all_hero_part_msck/role=tanke</span>
<span class="token comment">-- Step4：查询表 可以发现没有数据</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_all_hero_part_msck<span class="token punctuation">;</span>

<span class="token comment">--Step5：使用MSCK命令进行修复--add partitions可以不写 因为默认就是增加分区</span>
MSCK repair <span class="token keyword">table</span> t_all_hero_part_msck <span class="token keyword">add</span> partitions<span class="token punctuation">;</span>
</code></pre></div></li> <li><p>针对分区表，直接使用HDFS命令删除分区文件夹，此时在Hive中查询显示分区还在，因为metastore中还没有被删除，使用<strong>MSCK DROP PARTITIONS</strong>进行修复。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- Step1：直接使用HDFS命令删除分区表的某一个分区文件夹</span>
<span class="token comment"># hadoop fs -rm -r /user/hive/warehouse/t_all_hero.db/t_all_hero_part_msck/role=sheshou</span>

<span class="token comment">-- Step2：查询发现还有分区信息</span>
<span class="token comment">-- 因为元数据信息没有删除</span>
<span class="token keyword">show</span> partitions t_all_hero_part_msck<span class="token punctuation">;</span>

<span class="token comment">-- Step3：使用MSCK命令进行修复</span>
MSCK repair <span class="token keyword">table</span> t_all_hero_part_msck <span class="token keyword">drop</span> partitions<span class="token punctuation">;</span>
</code></pre></div></li></ol> <h2 id="hive-show-显示语法"><a href="#hive-show-显示语法" class="header-anchor">#</a> Hive Show 显示语法</h2> <h3 id="整体概述-5"><a href="#整体概述-5" class="header-anchor">#</a> 整体概述</h3> <p>Show相关的语句提供了一种查询Hive metastore的方法。可以帮助用户查询相关信息。</p> <p>比如我们最常使用的查询当前数据库下有哪些表 show tables.</p> <h3 id="常用语句"><a href="#常用语句" class="header-anchor">#</a> 常用语句</h3> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 1、显示所有数据库 SCHEMAS和DATABASES的用法 功能一样</span>
<span class="token keyword">show</span> <span class="token keyword">databases</span><span class="token punctuation">;</span>
<span class="token keyword">show</span> schemas<span class="token punctuation">;</span>

<span class="token comment">-- 2、显示当前数据库所有表/视图/物化视图/分区/索引</span>
<span class="token keyword">show</span> <span class="token keyword">tables</span><span class="token punctuation">;</span>
<span class="token keyword">SHOW</span> <span class="token keyword">TABLES</span> <span class="token punctuation">[</span><span class="token operator">IN</span> database_name<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">--指定某个数据库</span>

<span class="token comment">-- 3、显示当前数据库下所有视图</span>
<span class="token keyword">Show</span> Views<span class="token punctuation">;</span>
<span class="token keyword">SHOW</span> VIEWS <span class="token string">'test_*'</span><span class="token punctuation">;</span> <span class="token comment">-- show all views that start with &quot;test_&quot;</span>
<span class="token keyword">SHOW</span> VIEWS <span class="token keyword">FROM</span> test1<span class="token punctuation">;</span> <span class="token comment">-- show views from database test1</span>
<span class="token keyword">SHOW</span> VIEWS <span class="token punctuation">[</span><span class="token operator">IN</span><span class="token operator">/</span><span class="token keyword">FROM</span> database_name<span class="token punctuation">]</span><span class="token punctuation">;</span>

<span class="token comment">-- 4、显示当前数据库下所有物化视图</span>
<span class="token keyword">SHOW</span> MATERIALIZED VIEWS <span class="token punctuation">[</span><span class="token operator">IN</span><span class="token operator">/</span><span class="token keyword">FROM</span> database_name<span class="token punctuation">]</span><span class="token punctuation">;</span>

<span class="token comment">-- 5、显示表分区信息，分区按字母顺序列出，不是分区表执行该语句会报错</span>
<span class="token keyword">show</span> partitions table_name<span class="token punctuation">;</span>

<span class="token comment">-- 6、显示表/分区的扩展信息</span>
<span class="token keyword">SHOW</span> <span class="token keyword">TABLE</span> <span class="token keyword">EXTENDED</span> <span class="token punctuation">[</span><span class="token operator">IN</span><span class="token operator">|</span><span class="token keyword">FROM</span> database_name<span class="token punctuation">]</span> <span class="token operator">LIKE</span> table_name<span class="token punctuation">;</span>
<span class="token keyword">show</span> <span class="token keyword">table</span> <span class="token keyword">extended</span> <span class="token operator">like</span> student<span class="token punctuation">;</span>

<span class="token comment">-- 7、显示表的属性信息</span>
<span class="token keyword">SHOW</span> TBLPROPERTIES table_name<span class="token punctuation">;</span>
<span class="token keyword">show</span> tblproperties student<span class="token punctuation">;</span>

<span class="token comment">-- 8、显示表、视图的创建语句</span>
<span class="token keyword">SHOW</span> <span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token punctuation">(</span><span class="token punctuation">[</span>db_name<span class="token punctuation">.</span><span class="token punctuation">]</span>table_name<span class="token operator">|</span>view_name<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">show</span> <span class="token keyword">create</span> <span class="token keyword">table</span> student<span class="token punctuation">;</span>

<span class="token comment">-- 9、显示表中的所有列，包括分区列。</span>
<span class="token keyword">SHOW</span> <span class="token keyword">COLUMNS</span> <span class="token punctuation">(</span><span class="token keyword">FROM</span><span class="token operator">|</span><span class="token operator">IN</span><span class="token punctuation">)</span> table_name <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token keyword">FROM</span><span class="token operator">|</span><span class="token operator">IN</span><span class="token punctuation">)</span> db_name<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token keyword">show</span> <span class="token keyword">columns</span>  <span class="token operator">in</span> student<span class="token punctuation">;</span>

<span class="token comment">-- 10、显示当前支持的所有自定义和内置的函数</span>
<span class="token keyword">show</span> functions<span class="token punctuation">;</span>

<span class="token comment">-- 11、Describe desc</span>
<span class="token comment">-- 查看表信息</span>
<span class="token keyword">desc</span> <span class="token keyword">extended</span> table_name<span class="token punctuation">;</span>
<span class="token comment">-- 查看表信息（格式化美观）</span>
<span class="token keyword">desc</span> formatted table_name<span class="token punctuation">;</span>
<span class="token comment">-- 查看数据库相关信息</span>
<span class="token keyword">describe</span> <span class="token keyword">database</span> database_name<span class="token punctuation">;</span>
</code></pre></div><h2 id="hive-dml-load-加载数据"><a href="#hive-dml-load-加载数据" class="header-anchor">#</a> Hive DML Load 加载数据</h2> <h3 id="背景"><a href="#背景" class="header-anchor">#</a> 背景</h3> <p>在Hive中建表成功之后，就会在HDFS上创建一个与之对应的文件夹，且<strong>文件夹名字就是表名</strong>；</p> <p>文件夹父路径是由参数hive.metastore.warehouse.dir控制，默认值是/user/hive/warehouse；</p> <p>也可以在建表的时候使用location语句指定任意路径。</p> <p><img src="/study/assets/img/image-20210829141543730.a21352eb.png" alt="image-20210829141543730"></p> <p>不管路径在哪里，只有把数据文件移动到对应的表文件夹下面，Hive才能映射解析成功;</p> <p>最原始暴力的方式就是使用<strong>hadoop fs –put|-mv</strong>等方式直接将数据移动到表文件夹下；</p> <p>但是，Hive官方<strong>推荐使用Load命令</strong>将数据加载到表中。</p> <p><img src="/study/assets/img/image-20210829141828268.27c3ac4f.png" alt="image-20210829141828268"></p> <h3 id="load-语法"><a href="#load-语法" class="header-anchor">#</a> Load 语法</h3> <p>Load英文单词的含义为：<strong>加载、装载</strong>；</p> <p>所谓加载是指：将数据文件移动到与Hive表对应的位置，移动时是<strong>纯复制、移动</strong>操作。</p> <p><strong>纯复制、移动</strong>指在数据load加载到表中时，Hive不会对表中的数据内容进行任何转换，任何操作。</p> <h4 id="语法规则"><a href="#语法规则" class="header-anchor">#</a> 语法规则</h4> <p><img src="/study/assets/img/image-20210829142912250.9b7c5217.png" alt="image-20210829142912250"></p> <h4 id="filepath"><a href="#filepath" class="header-anchor">#</a> filepath</h4> <p>filepath表示<strong>待移动数据的路径</strong>。可以指向<strong>文件</strong>（在这种情况下，Hive将文件移动到表中），也可以指向<strong>目录</strong>（在这种情况下，Hive将把该目录中的所有文件移动到表中）。</p> <p>filepath文件路径支持下面三种形式，要结合LOCAL关键字一起考虑：</p> <ul><li>相对路径，例如：project/data1</li> <li>绝对路径，例如：/user/hive/project/data1</li> <li>具有schema的完整URI，例如：hdfs://namenode:9000/user/hive/project/data1</li></ul> <h4 id="local"><a href="#local" class="header-anchor">#</a> LOCAL</h4> <p>指定LOCAL， 将在本地文件系统中查找文件路径。</p> <ul><li>若指定相对路径，将相对于用户的当前工作目录进行解释；</li> <li>用户也可以为本地文件指定完整的URI-例如：file:///user/hive/project/data1。</li></ul> <p>没有指定LOCAL关键字。</p> <ul><li>如果filepath指向的是一个完整的URI，会直接使用这个URI；</li> <li>如果没有指定schema，Hive会使用在hadoop配置文件中参数fs.default.name指定的（不出意外，都是HDFS）。</li></ul> <p><strong>LOCAL本地是哪里？</strong></p> <p>如果对HiveServer2服务运行此命令</p> <p><strong>本地文件系统</strong>指的是Hiveserver2服务所在机器的本地Linux文件系统，不是Hive客户端所在的本地文件系统。</p> <p><img src="/study/assets/img/image-20210829142653564.4624dde1.png" alt="image-20210829142653564"></p> <h4 id="overwrite"><a href="#overwrite" class="header-anchor">#</a> OVERWRITE</h4> <p>如果使用了OVERWRITE关键字，则目标表（或者分区）中的已经存在的数据会被删除，然后再将filepath指向的文件/目录中的内容添加到表/分区中。</p> <h3 id="案例-load-data-from-local-fs-or-hdfs"><a href="#案例-load-data-from-local-fs-or-hdfs" class="header-anchor">#</a> 案例 - Load Data From Local FS or HDFS</h3> <ol><li>练习Load Data From Local FS</li> <li>练习Load Data From HDFS</li> <li>理解Local关键字的含义</li> <li>练习Load Dada To Partition Table</li></ol> <p>案例数据：students.txt</p> <div class="language-txt extra-class"><pre class="language-text"><code>95001,李勇,男,20,CS
95002,刘晨,女,19,IS
95003,王敏,女,22,MA
95004,张立,男,19,IS
95005,刘刚,男,18,MA
95006,孙庆,男,23,CS
95007,易思玲,女,19,MA
95008,李娜,女,18,CS
95009,梦圆圆,女,18,MA
95010,孔小涛,男,19,CS
95011,包小柏,男,18,MA
95012,孙花,女,20,CS
95013,冯伟,男,21,CS
95014,王小丽,\N,19,CS
95015,王君,男,18,MA
95016,钱国,男,21,MA
95017,王风娟,女,18,IS
95018,王一,女,19,IS
95019,邢小丽,女,19,IS
95020,赵钱,男,21,IS
95021,周二,男,17,MA
95022,郑明,男,20,MA
</code></pre></div><div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-------- 练习:Load Data From Local FS or HDFS------</span>
<span class="token comment">-- step1:建表</span>
<span class="token comment">-- 建表student_local 用于演示从本地加载数据</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> student_local<span class="token punctuation">(</span>
  num <span class="token keyword">int</span><span class="token punctuation">,</span>
  name string<span class="token punctuation">,</span>
  sex string<span class="token punctuation">,</span>
  age <span class="token keyword">int</span><span class="token punctuation">,</span>
  dept string<span class="token punctuation">)</span> 
  <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>
  
<span class="token comment">-- 建表student_HDFS  用于演示从HDFS加载数据</span>
<span class="token keyword">create</span> external <span class="token keyword">table</span> student_HDFS<span class="token punctuation">(</span>
  num <span class="token keyword">int</span><span class="token punctuation">,</span>
  name string<span class="token punctuation">,</span>
  sex string<span class="token punctuation">,</span>
  age <span class="token keyword">int</span><span class="token punctuation">,</span>
  dept string<span class="token punctuation">)</span> 
  <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>
  
<span class="token comment">-- 建表student_HDFS_p 用于演示从HDFS加载数据到分区表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> student_HDFS_p<span class="token punctuation">(</span>
  num <span class="token keyword">int</span><span class="token punctuation">,</span>
  name string<span class="token punctuation">,</span>
  sex string<span class="token punctuation">,</span>
  age <span class="token keyword">int</span><span class="token punctuation">,</span>
  dept string<span class="token punctuation">)</span> 
  partitioned <span class="token keyword">by</span><span class="token punctuation">(</span>country string<span class="token punctuation">)</span> 
  <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>
</code></pre></div><div class="language-shell extra-class"><pre class="language-shell"><code>-- 建议使用beeline客户端 可以显示出加载过程日志信息
-- 从本地加载数据  数据位于HS2（node1）本地文件系统  本质是hadoop fs -put上传操作
LOAD DATA LOCAL INPATH <span class="token string">'/opt/hivedata/students.txt'</span> INTO TABLE student_local<span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210829161435320.ee69fdf5.png" alt="image-20210829161435320"></p> <div class="language-shell extra-class"><pre class="language-shell"><code> -- 从HDFS加载数据  数据位于HDFS文件系统根目录下  本质是hadoop fs -mv 移动操作
-- 先把数据上传到HDFS上  
hadoop fs -put /opt/hivedata/students.txt /
LOAD DATA INPATH <span class="token string">'/students.txt'</span> INTO TABLE student_HDFS<span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210829161758936.6e735e84.png" alt="image-20210829161758936"></p> <div class="language-shell extra-class"><pre class="language-shell"><code>---- 从HDFS加载数据到分区表中并制定分区  数据位于HDFS文件系统根目录下
-- 先把数据上传到HDFS上 
hadoop fs -put /opt/hivedata/students.txt /
LOAD DATA INPATH <span class="token string">'/students.txt'</span> INTO TABLE student_HDFS_p partition<span class="token punctuation">(</span>country <span class="token operator">=</span><span class="token string">&quot;CHina&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210829161907579.8e31e6b1.png" alt="image-20210829161907579"></p> <h3 id="hive3-0-load新特性"><a href="#hive3-0-load新特性" class="header-anchor">#</a> Hive3.0 Load新特性</h3> <ul><li><p>Hive3.0+，load加载数据时除了移动、复制操作之外，在<strong>某些场合下还会将加载重写为INSERT AS SELECT</strong>。</p></li> <li><p>Hive3.0+，还支持使用inputformat、SerDe指定输入格式，例如Text，ORC等。</p></li></ul> <p>比如，如果表具有分区，则load命令没有指定分区，则将load转换为INSERT AS SELECT，并假定最后一组列为分区列，如果文件不符合预期，则报错。</p> <h4 id="案例-3"><a href="#案例-3" class="header-anchor">#</a> 案例</h4> <p>本来加载的时候没有指定分区，语句是报错的，但是文件的格式符合表的结构，前两个是col1,col2,最后一个是分区字段col3，则此时会将load语句转换成为insert as select语句。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">------hive 3.0 load命令新特性------------------</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> tab1 <span class="token punctuation">(</span>
  col1 <span class="token keyword">int</span><span class="token punctuation">,</span> 
  col2 <span class="token keyword">int</span><span class="token punctuation">)</span>
PARTITIONED <span class="token keyword">BY</span> <span class="token punctuation">(</span>col3 <span class="token keyword">int</span><span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>

<span class="token keyword">LOAD</span> <span class="token keyword">DATA</span> <span class="token keyword">LOCAL</span> INPATH <span class="token string">'/opt/hivedata/tab1.txt'</span> <span class="token keyword">INTO</span> <span class="token keyword">TABLE</span> tab1<span class="token punctuation">;</span>
<span class="token comment">-- tab1.txt内容如下</span>
<span class="token number">11</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">,</span><span class="token number">1</span>
<span class="token number">33</span><span class="token punctuation">,</span><span class="token number">44</span><span class="token punctuation">,</span><span class="token number">2</span>
</code></pre></div><p>本来加载的时候没有指定分区，语句是报错的，但是文件的格式符合表的结构，前两个是col1,col2,最后一个是分区字段col3，则此时会将load语句转换成为insert as select语句。</p> <p>在Hive3.0中，还支持使用inputformat、SerDe指定任何Hive输入格式，例如文本，ORC等。</p> <h2 id="hive-dml-insert-插入数据"><a href="#hive-dml-insert-插入数据" class="header-anchor">#</a> Hive DML Insert 插入数据</h2> <h3 id="背景-2"><a href="#背景-2" class="header-anchor">#</a> 背景</h3> <p>在MySQL这样的RDBMS中，通常使用insert+values的方式来向表插入数据，并且执行速度很快。</p> <p>这也是RDBMS中表插入数据的核心方式。</p> <p><img src="data:image/png;base64,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" alt="image-20210829220618326"></p> <p>假如说对Hive的定位不清，把Hive当成RDBMS来使用，也使用insert+values的方式插入数据，会如何呢？</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- hive中insert+values</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> t_test_insert<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name string<span class="token punctuation">,</span>age <span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_test_insert <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">&quot;allen&quot;</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p>你会发现执行过程非常非常慢，底层是使用MapReduce把数据写入HDFS的。</p> <p><img src="/study/assets/img/image-20210829220735622.f9e475de.png" alt="image-20210829220735622"></p> <p>试想一下，如何在Hive中这样玩，对于大数据分析，海量数据一条条插入是不是非常刺激。因此在Hive中我们通过将数据清洗成为结构化文件，再Load加载到表中。</p> <p>但是并不意味着insert语法在Hive中没有使用地位了，通常在Hive中我们使用insert+select语句。即插入表的数据来自于后续select查询语句返回的结果。</p> <h3 id="insert-select"><a href="#insert-select" class="header-anchor">#</a> insert + select</h3> <p>insert+select表示：将后面<strong>查询</strong>返回的<strong>结果</strong>作为内容<strong>插入</strong>到<strong>指定表</strong>中，注意<strong>OVERWRITE</strong>将覆盖已有数据。</p> <ul><li>需要保证查询结果列的数目和需要插入数据表格的列数目一致。</li> <li>如果查询出来的<strong>数据类型</strong>和插入表格对应的列数据类型<strong>不一致</strong>，将会进行转换，但是不能保证转换一定成功，转换失败的数据将会为NULL。</li></ul> <p><img src="/study/assets/img/image-20210829220926996.74e639c8.png" alt="image-20210829220926996"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- step1:创建一张源表student</span>
<span class="token keyword">drop</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token keyword">exists</span> student<span class="token punctuation">;</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> student<span class="token punctuation">(</span>
  num <span class="token keyword">int</span><span class="token punctuation">,</span>
  name string<span class="token punctuation">,</span>
  sex string<span class="token punctuation">,</span>
  age <span class="token keyword">int</span><span class="token punctuation">,</span>
  dept string<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>
<span class="token comment">-- 加载数据</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/hivedata/students.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> student<span class="token punctuation">;</span>

<span class="token comment">-- step2：创建一张目标表  只有两个字段</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> student_from_insert<span class="token punctuation">(</span>
  sno <span class="token keyword">int</span><span class="token punctuation">,</span>
  sname string<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">-- 使用insert+select插入数据到新表中</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> student_from_insert <span class="token keyword">select</span> num<span class="token punctuation">,</span>name <span class="token keyword">from</span> student<span class="token punctuation">;</span>

<span class="token keyword">select</span> <span class="token operator">*</span><span class="token keyword">from</span> student_insert1<span class="token punctuation">;</span>
</code></pre></div><h3 id="multiple-inserts-多重插入"><a href="#multiple-inserts-多重插入" class="header-anchor">#</a> multiple inserts 多重插入</h3> <p>翻译为多次插入，多重插入，其核心功能是：<strong>一次扫描，多次插入</strong>。</p> <p>语法目的就是<strong>减少扫描的次数</strong>，在一次扫描中。完成多次insert操作。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">------------multiple inserts----------------------</span>
<span class="token comment">-- 当前库下已有一张表student</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>
<span class="token comment">-- 创建两张新表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> student_insert1<span class="token punctuation">(</span>sno <span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> student_insert2<span class="token punctuation">(</span>sname string<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 多重插入</span>
<span class="token keyword">from</span> student
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> student_insert1
<span class="token keyword">select</span> num
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> student_insert2
<span class="token keyword">select</span> name<span class="token punctuation">;</span>
</code></pre></div><h3 id="dynamic-partition-insert-动态分区插入"><a href="#dynamic-partition-insert-动态分区插入" class="header-anchor">#</a> dynamic partition insert 动态分区插入</h3> <p>对于分区表的数据导入加载，最基础的是通过load命令加载数据。</p> <p>在load过程中，分区值是手动指定写死的，叫做<strong>静态分区</strong>。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">create</span> <span class="token keyword">table</span> student_HDFS_p<span class="token punctuation">(</span>
  Sno <span class="token keyword">int</span><span class="token punctuation">,</span>
  Sname string<span class="token punctuation">,</span>
  Sex string<span class="token punctuation">,</span>
  Sage <span class="token keyword">int</span><span class="token punctuation">,</span>
  Sdept string<span class="token punctuation">)</span> 
  partitioned <span class="token keyword">by</span><span class="token punctuation">(</span>country string<span class="token punctuation">)</span> 
  <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>
<span class="token comment">-- 注意 分区字段country的值是在导入数据的时候手动指定的 China</span>
<span class="token keyword">LOAD</span> <span class="token keyword">DATA</span> INPATH <span class="token string">'/students.txt'</span> <span class="token keyword">INTO</span> <span class="token keyword">TABLE</span> student_HDFS_p <span class="token keyword">partition</span><span class="token punctuation">(</span>country <span class="token operator">=</span><span class="token string">&quot;China&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p>接下来我们考虑一下性能问题：</p> <p>假如说现在有全球224个国家的人员名单（每个国家名单单独一个文件），让你导入数据到分区表中，不同国家不同分区，如何高效实现？使用load语法导入224次？</p> <p>再假如，现在有一份名单students.txt，内容如下：</p> <div class="language-txt extra-class"><pre class="language-text"><code>95001,李勇,男,20,CS
95002,刘晨,女,19,IS
95003,王敏,女,22,MA
95004,张立,男,19,IS
95005,刘刚,男,18,MA
95006,孙庆,男,23,CS
95007,易思玲,女,19,MA
95008,李娜,女,18,CS
95009,梦圆圆,女,18,MA
95010,孔小涛,男,19,CS
95011,包小柏,男,18,MA
95012,孙花,女,20,CS
95013,冯伟,男,21,CS
95014,王小丽,女,19,CS
95015,王君,男,18,MA
95016,钱国,男,21,MA
95017,王风娟,女,18,IS
95018,王一,女,19,IS
95019,邢小丽,女,19,IS
95020,赵钱,男,21,IS
95021,周二,男,17,MA
95022,郑明,男,20,MA
</code></pre></div><p>让你创建一张分区表，根据最后一个字段（选修专业）进行分区，同一个专业的同学分到同一个分区中，如何实现？如果还是load加载手动指定，即使最终可以成功，效率也是极慢的。</p> <p>为此，Hive提供了<strong>动态分区插入</strong>的语法。</p> <p>所谓动态分区插入指的是：<strong>分区的值是由后续的select查询语句的结果来动态确定的</strong>。<strong>根据查询结果自动分区</strong>。</p> <p><strong>配置参数</strong></p> <table><thead><tr><th>hive.exec.dynamic.partition</th> <th>true</th> <th>需要设置true为启用动态分区插入</th></tr></thead> <tbody><tr><td>hive.exec.dynamic.partition.mode</td> <td>strict</td> <td>在strict模式下，用户必须至少指定一个静态分区，以防用户意外覆盖所有分区；在nonstrict模式下，允许所有分区都是动态的</td></tr></tbody></table> <p>关于严格模式、非严格模式，演示如下：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">FROM</span> page_view_stg pvs
<span class="token keyword">INSERT</span> OVERWRITE <span class="token keyword">TABLE</span> page_view <span class="token keyword">PARTITION</span><span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'2008-06-08'</span><span class="token punctuation">,</span> country<span class="token punctuation">)</span>
<span class="token keyword">SELECT</span> pvs<span class="token punctuation">.</span>viewTime<span class="token punctuation">,</span> pvs<span class="token punctuation">.</span>userid<span class="token punctuation">,</span> pvs<span class="token punctuation">.</span>page_url<span class="token punctuation">,</span> pvs<span class="token punctuation">.</span>referrer_url<span class="token punctuation">,</span> <span class="token boolean">null</span><span class="token punctuation">,</span> <span class="token boolean">null</span><span class="token punctuation">,</span> pvs<span class="token punctuation">.</span>ip<span class="token punctuation">,</span> pvs<span class="token punctuation">.</span>cnt

<span class="token comment">--在这里，country分区将由SELECT子句（即pvs.cnt）的最后一列动态创建。</span>
<span class="token comment">--而dt分区是手动指定写死的。</span>
<span class="token comment">--如果是nonstrict模式下，dt分区也可以动态创建。</span>
</code></pre></div><p><strong>案例 - 动态分区插入</strong></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 动态分区插入</span>
<span class="token comment">-- 1、首先设置动态分区模式为非严格模式 默认已经开启了动态分区功能</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span><span class="token keyword">mode</span> <span class="token operator">=</span> nonstrict<span class="token punctuation">;</span>

<span class="token comment">-- 2、当前库下已有一张表student</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>

<span class="token comment">-- 3、创建分区表 以sdept作为分区字段</span>
<span class="token comment">-- 注意：分区字段名不能和表中的字段名重复。</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> student_partition<span class="token punctuation">(</span>Sno <span class="token keyword">int</span><span class="token punctuation">,</span>Sname string<span class="token punctuation">,</span>Sex string<span class="token punctuation">,</span>Sage <span class="token keyword">int</span><span class="token punctuation">)</span> partitioned <span class="token keyword">by</span><span class="token punctuation">(</span>Sdept string<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 4、执行动态分区插入操作</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> student_partition <span class="token keyword">partition</span><span class="token punctuation">(</span>Sdept<span class="token punctuation">)</span>
<span class="token keyword">select</span> Sno<span class="token punctuation">,</span>Sname<span class="token punctuation">,</span>Sex<span class="token punctuation">,</span>Sage<span class="token punctuation">,</span>Sdept <span class="token keyword">from</span> student<span class="token punctuation">;</span>
<span class="token comment">-- 其中，Sno,Sname,Sex,Sage作为表的字段内容插入表中</span>
<span class="token comment">-- Sdept作为分区字段值</span>
</code></pre></div><p>最终执行结果如下，可以发现实现了自动分区：</p> <p><img src="/study/assets/img/image-20210829222924118.cb0292b6.png" alt="image-20210829222924118"></p> <h3 id="insert-directory-导出数据"><a href="#insert-directory-导出数据" class="header-anchor">#</a> insert + directory 导出数据</h3> <p><strong>语法格式</strong>：</p> <ul><li>Hive支持将select查询的结果导出成文件存放在文件系统中。语法格式如下；</li></ul> <p><img src="/study/assets/img/image-20210829223147944.6ff0b8ac.png" alt="image-20210829223147944"></p> <p>**注意：**导出操作是一个OVERWRITE覆盖操作，慎重。</p> <p>目录可以是完整的URI。如果未指定scheme，则Hive将使用hadoop配置变量fs.default.name来决定导出位置；</p> <p>如果使用LOCAL关键字，则Hive会将数据写入本地文件系统上的目录；</p> <p><strong>写入文件系统的数据被序列化为文本，列之间用\001隔开，行之间用换行符隔开</strong>。如果列都不是原始数据类型，那么这些列将序列化为JSON格式。也可以在导出的时候指定分隔符换行符和文件格式。</p> <p><strong>演示：</strong></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 当前库下已有一张表student</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>

<span class="token comment">-- 1、导出查询结果到HDFS指定目录下</span>
<span class="token keyword">insert</span> overwrite directory <span class="token string">'/tmp/hive_export/e1'</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>

<span class="token comment">-- 2、导出时指定分隔符和文件存储格式</span>
<span class="token keyword">insert</span> overwrite directory <span class="token string">'/tmp/hive_export/e2'</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span>
stored <span class="token keyword">as</span> orc
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>

<span class="token comment">-- 3、导出数据到本地文件系统指定目录下</span>
<span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/root/hive_export/e1'</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210829223612046.15985836.png" alt="image-20210829223612046"></p> <p><img src="/study/assets/img/image-20210829223701581.1a27ecea.png" alt="image-20210829223701581"></p> <h2 id="hive-dml-update、delete-更新删除数据"><a href="#hive-dml-update、delete-更新删除数据" class="header-anchor">#</a> Hive DML Update、Delete 更新删除数据</h2> <p>首先，必须明确，你理解的Hive这款软件，定位是什么？是面向事务支持事务的RDBMS?还是面向分析，支持分析的数据仓库。这很重要。</p> <p>Hive是基于Hadoop的数据仓库，面向分析支持分析工具。因此在Hive中常见的操作的就是分析查询select操作。将已有的结构化数据文件映射成为表，然后提供SQL分析数据的能力。</p> <p>因此Hive刚出现的时候是不支持update和delete语法支持的，因为Hive所处理的数据都是已经存在的结构化文件，加载到hive表中即可。</p> <p>后续Hive支持了相关的update和delete操作，不过有很多约束。详见Hive事务的支持。</p> <h3 id="update-操作"><a href="#update-操作" class="header-anchor">#</a> update 操作</h3> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 1、开启事务配置（可以使用set设置当前session生效 也可以配置在hive-site.xml中）</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>support<span class="token punctuation">.</span>concurrency <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">--Hive是否支持并发</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>enforce<span class="token punctuation">.</span>bucketing <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">--从Hive2.0开始不再需要  是否开启分桶功能</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span><span class="token keyword">mode</span> <span class="token operator">=</span> nonstrict<span class="token punctuation">;</span> <span class="token comment">--动态分区模式  非严格</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>txn<span class="token punctuation">.</span>manager <span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>lockmgr<span class="token punctuation">.</span>DbTxnManager<span class="token punctuation">;</span> <span class="token comment">--</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>compactor<span class="token punctuation">.</span>initiator<span class="token punctuation">.</span><span class="token keyword">on</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">--是否在Metastore实例上运行启动压缩合并</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>compactor<span class="token punctuation">.</span>worker<span class="token punctuation">.</span>threads <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token comment">--在此metastore实例上运行多少个压缩程序工作线程。</span>

<span class="token comment">--2、创建Hive事务表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> trans_student<span class="token punctuation">(</span>
    id <span class="token keyword">int</span><span class="token punctuation">,</span>
    name String<span class="token punctuation">,</span>
    age <span class="token keyword">int</span>
<span class="token punctuation">)</span><span class="token keyword">clustered</span> <span class="token keyword">by</span> <span class="token punctuation">(</span>id<span class="token punctuation">)</span> <span class="token keyword">into</span> <span class="token number">2</span> buckets stored <span class="token keyword">as</span> orc TBLPROPERTIES<span class="token punctuation">(</span><span class="token string">'transactional'</span><span class="token operator">=</span><span class="token string">'true'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 3、针对事务表进行insert update delete操作</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> trans_student <span class="token punctuation">(</span>id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">)</span>
<span class="token keyword">values</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">&quot;allen&quot;</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> trans_student<span class="token punctuation">;</span>

<span class="token keyword">update</span> trans_student
<span class="token keyword">set</span> age <span class="token operator">=</span> <span class="token number">20</span>
<span class="token keyword">where</span> id <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
</code></pre></div><h3 id="delete-操作"><a href="#delete-操作" class="header-anchor">#</a> delete 操作</h3> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">--1、开启事务配置（可以使用set设置当前session生效 也可以配置在hive-site.xml中）</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>support<span class="token punctuation">.</span>concurrency <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">--Hive是否支持并发</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>enforce<span class="token punctuation">.</span>bucketing <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">--从Hive2.0开始不再需要  是否开启分桶功能</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span><span class="token keyword">mode</span> <span class="token operator">=</span> nonstrict<span class="token punctuation">;</span> <span class="token comment">--动态分区模式  非严格</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>txn<span class="token punctuation">.</span>manager <span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>lockmgr<span class="token punctuation">.</span>DbTxnManager<span class="token punctuation">;</span> <span class="token comment">--</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>compactor<span class="token punctuation">.</span>initiator<span class="token punctuation">.</span><span class="token keyword">on</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">--是否在Metastore实例上运行启动压缩合并</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>compactor<span class="token punctuation">.</span>worker<span class="token punctuation">.</span>threads <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token comment">--在此metastore实例上运行多少个压缩程序工作线程。</span>

<span class="token comment">--2、创建Hive事务表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> trans_student<span class="token punctuation">(</span>
   id <span class="token keyword">int</span><span class="token punctuation">,</span>
   name String<span class="token punctuation">,</span>
   age <span class="token keyword">int</span>
<span class="token punctuation">)</span><span class="token keyword">clustered</span> <span class="token keyword">by</span> <span class="token punctuation">(</span>id<span class="token punctuation">)</span> <span class="token keyword">into</span> <span class="token number">2</span> buckets stored <span class="token keyword">as</span> orc TBLPROPERTIES<span class="token punctuation">(</span><span class="token string">'transactional'</span><span class="token operator">=</span><span class="token string">'true'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">--3、针对事务表进行insert update delete操作</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> trans_student <span class="token punctuation">(</span>id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">)</span>
<span class="token keyword">values</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">&quot;allen&quot;</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> trans_student<span class="token punctuation">;</span>

<span class="token keyword">delete</span> <span class="token keyword">from</span> trans_student <span class="token keyword">where</span> id <span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span>
</code></pre></div><h2 id="hive-dql-select-查询数据"><a href="#hive-dql-select-查询数据" class="header-anchor">#</a> Hive DQL Select 查询数据</h2> <h3 id="数据环境准备"><a href="#数据环境准备" class="header-anchor">#</a> 数据环境准备</h3> <p>准备一下select语法测试环境，在附件资料中有一份数据文件《us-covid19-counties.dat》，里面记录了2021-01-28美国各个县累计新冠确诊病例数和累计死亡病例数。</p> <p><a href="img/us-covid19-counties.dat">us-covid19-counties.dat</a></p> <p>在Hive中创建表，加载该文件到表中：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- step1:创建普通表t_usa_covid19</span>
<span class="token keyword">drop</span> <span class="token keyword">table</span> t_usa_covid19<span class="token punctuation">;</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> t_usa_covid19<span class="token punctuation">(</span>
       count_date string<span class="token punctuation">,</span>
       county string<span class="token punctuation">,</span>
       state string<span class="token punctuation">,</span>
       fips <span class="token keyword">int</span><span class="token punctuation">,</span>
       cases <span class="token keyword">int</span><span class="token punctuation">,</span>
       deaths <span class="token keyword">int</span><span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">&quot;,&quot;</span><span class="token punctuation">;</span>
<span class="token comment">-- 将源数据load加载到t_usa_covid19表对应的路径下</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/hivedata/us-covid19-counties.dat'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_usa_covid19<span class="token punctuation">;</span>

<span class="token comment">-- step2:创建一张分区表 基于count_date日期,state州进行分区</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> t_usa_covid19_p<span class="token punctuation">(</span>
     county string<span class="token punctuation">,</span>
     fips <span class="token keyword">int</span><span class="token punctuation">,</span>
     cases <span class="token keyword">int</span><span class="token punctuation">,</span>
     deaths <span class="token keyword">int</span><span class="token punctuation">)</span>
partitioned <span class="token keyword">by</span><span class="token punctuation">(</span>count_date string<span class="token punctuation">,</span>state string<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">&quot;,&quot;</span><span class="token punctuation">;</span>

<span class="token comment">-- step3:使用动态分区插入将数据导入t_usa_covid19_p中</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span><span class="token keyword">mode</span> <span class="token operator">=</span> nonstrict<span class="token punctuation">;</span>

<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> t_usa_covid19_p <span class="token keyword">partition</span> <span class="token punctuation">(</span>count_date<span class="token punctuation">,</span>state<span class="token punctuation">)</span>
<span class="token keyword">select</span> county<span class="token punctuation">,</span>fips<span class="token punctuation">,</span>cases<span class="token punctuation">,</span>deaths<span class="token punctuation">,</span>count_date<span class="token punctuation">,</span>state <span class="token keyword">from</span> t_usa_covid19<span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210904132711964.e6bc2d78.png" alt="image-20210904132711964"></p> <h3 id="语法树"><a href="#语法树" class="header-anchor">#</a> 语法树</h3> <img src="/study/assets/img/image-20210829235506602.deb32f2a.png" alt="image-20210829235506602" style="zoom:40%;"> <ul><li>从哪里查询取决于FROM关键字后面的table_reference。可以是普通物理表、视图、join结果或子查询结果。</li> <li>表名和列名<strong>不区分大小写</strong>。</li></ul> <h3 id="基础查询"><a href="#基础查询" class="header-anchor">#</a> 基础查询</h3> <h4 id="select-expr"><a href="#select-expr" class="header-anchor">#</a> select_expr</h4> <p>select_expr表示检索查询返回的列，必须至少有一个select_expr。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- select_expr</span>
<span class="token comment">-- 查询所有字段或者指定字段</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19_p<span class="token punctuation">;</span>
<span class="token keyword">select</span> county<span class="token punctuation">,</span> cases<span class="token punctuation">,</span> deaths <span class="token keyword">from</span> t_usa_covid19_p<span class="token punctuation">;</span>

<span class="token comment">-- 查询匹配正则表达式的所有字段</span>
<span class="token keyword">SET</span> hive<span class="token punctuation">.</span>support<span class="token punctuation">.</span>quoted<span class="token punctuation">.</span>identifiers <span class="token operator">=</span> none<span class="token punctuation">;</span> <span class="token comment">-- 带反引号的名称被解释为正则表达式</span>
<span class="token keyword">select</span> <span class="token punctuation">`</span><span class="token operator">^</span>c<span class="token punctuation">.</span><span class="token operator">*</span><span class="token punctuation">`</span> <span class="token keyword">from</span> t_usa_covid19_p<span class="token punctuation">;</span>

<span class="token comment">-- 查询当前数据库</span>
<span class="token keyword">select</span> current_database<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">--省去from关键字</span>

<span class="token comment">-- 查询使用函数</span>
<span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span>county<span class="token punctuation">)</span> <span class="token keyword">from</span> t_usa_covid19_p<span class="token punctuation">;</span>
</code></pre></div><h4 id="all、distinct"><a href="#all、distinct" class="header-anchor">#</a> All、DISTINCT</h4> <p>用于指定查询返回结果中重复的行如何处理。</p> <p>如果没有给出这些选项，则<strong>默认值为ALL</strong>（返回所有匹配的行）。</p> <p>DISTINCT指定从结果集中删除重复的行。</p> <div class="language-SQL extra-class"><pre class="language-sql"><code><span class="token comment">-- ALL DISTINCT</span>
<span class="token comment">-- 返回所有匹配的行</span>
<span class="token keyword">select</span> state <span class="token keyword">from</span> t_usa_covid19_p<span class="token punctuation">;</span>
<span class="token comment">-- 相当于</span>
<span class="token keyword">select</span> <span class="token keyword">all</span> state <span class="token keyword">from</span> t_usa_covid19_p<span class="token punctuation">;</span>
<span class="token comment">-- 返回所有匹配的行 去除重复的结果</span>
<span class="token keyword">select</span> <span class="token keyword">distinct</span> state <span class="token keyword">from</span> t_usa_covid19_p<span class="token punctuation">;</span>
<span class="token comment">-- 多个字段distinct 整体去重</span>
<span class="token keyword">select</span> <span class="token keyword">distinct</span> county<span class="token punctuation">,</span> state <span class="token keyword">from</span> t_usa_covid19_p<span class="token punctuation">;</span>
</code></pre></div><h4 id="where"><a href="#where" class="header-anchor">#</a> WHERE</h4> <p>WHERE后面是一个布尔表达式，用于<strong>查询过滤。</strong></p> <p>在WHERE表达式中，可以使用Hive支持的任何函数和运算符，但<strong>聚合函数除外</strong>。</p> <p>从Hive 0.13开始，WHERE子句支持某些类型的子查询。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19_p <span class="token keyword">where</span> state <span class="token operator">=</span><span class="token string">&quot;California&quot;</span> <span class="token operator">and</span> deaths <span class="token operator">&gt;</span> <span class="token number">1000</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19_p <span class="token keyword">where</span> <span class="token number">1</span> <span class="token operator">&gt;</span> <span class="token number">2</span><span class="token punctuation">;</span>  <span class="token comment">-- 1 &gt; 2 返回false</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19_p <span class="token keyword">where</span> <span class="token number">1</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>  <span class="token comment">-- 1 = 1 返回true</span>

<span class="token comment">-- where条件中使用函数 找出州名字母超过10个</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19_p <span class="token keyword">where</span> length<span class="token punctuation">(</span>state<span class="token punctuation">)</span> <span class="token operator">&gt;</span><span class="token number">10</span> <span class="token punctuation">;</span>

<span class="token comment">-- WHERE子句支持子查询</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span>
<span class="token keyword">FROM</span> A
<span class="token keyword">WHERE</span> A<span class="token punctuation">.</span>a <span class="token operator">IN</span> <span class="token punctuation">(</span><span class="token keyword">SELECT</span> foo <span class="token keyword">FROM</span> B<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- where条件中不能使用聚合函数</span>
<span class="token comment">-- 报错 SemanticException:Not yet supported place for UDAF 'sum'</span>
<span class="token keyword">select</span> state<span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span>deaths<span class="token punctuation">)</span>
<span class="token keyword">from</span> t_usa_covid19_p 
<span class="token keyword">where</span> <span class="token function">sum</span><span class="token punctuation">(</span>deaths<span class="token punctuation">)</span> <span class="token operator">&gt;</span><span class="token number">100</span> <span class="token keyword">group</span> <span class="token keyword">by</span> state<span class="token punctuation">;</span>
</code></pre></div><blockquote><p><strong>那么为什么不能在where子句中使用聚合函数呢？</strong></p></blockquote> <blockquote><p>因为聚合函数要使用它的前提是结果集已经确定。而where子句还处于“确定”结果集的过程中，因而不能使用聚合函数。</p></blockquote> <h4 id="分区查询-分区裁剪"><a href="#分区查询-分区裁剪" class="header-anchor">#</a> 分区查询（分区裁剪）</h4> <p>针对Hive分区表，在查询时可以<strong>指定分区查询</strong>，<strong>减少全表扫描</strong>，也叫做<strong>分区裁剪</strong>。</p> <p>所谓<strong>分区裁剪</strong>指：对分区表进行查询时，会检查WHERE子句或JOIN中的ON子句中是否存在对分区字段的过滤，如果存在，则仅<strong>访问查询符合条件的分区</strong>，即<strong>裁剪掉没必要访问的分区</strong>。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 找出来自加州，累计死亡人数大于1000的县 state字段就是分区字段 进行分区裁剪 避免全表扫描</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19_p 
<span class="token keyword">where</span> state <span class="token operator">=</span><span class="token string">&quot;California&quot;</span> <span class="token operator">and</span> deaths <span class="token operator">&gt;</span> <span class="token number">1000</span><span class="token punctuation">;</span>

<span class="token comment">-- 多分区裁剪</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19_p 
<span class="token keyword">where</span> count_date <span class="token operator">=</span> <span class="token string">&quot;2021-01-28&quot;</span> <span class="token operator">and</span> state <span class="token operator">=</span><span class="token string">&quot;California&quot;</span> <span class="token operator">and</span> deaths <span class="token operator">&gt;</span> <span class="token number">1000</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="group-by"><a href="#group-by" class="header-anchor">#</a> GROUP BY</h4> <p>GROUP BY语句用于结合聚合函数，根据一个或多个列对结果集进行分组。</p> <p>注意：出现在GROUP BY中select_expr的字段：<strong>要么是GROUP BY分组的字段</strong>；<strong>要么是被聚合函数应用的字段</strong>。</p> <p>原因：<strong>避免出现一个字段多个值的歧义。</strong></p> <ul><li>分组字段出现select_expr中，一定没有歧义，因为就是基于该字段分组的，同一组中必相同；</li> <li>被聚合函数应用的字段，也没歧义，因为聚合函数的本质就是多进一出，最终返回一个结果。</li></ul> <p><img src="/study/assets/img/image-20210904141521453.6b379982.png" alt="image-20210904141521453"></p> <div class="language-SQL extra-class"><pre class="language-sql"><code><span class="token comment">-- 根据state州进行分组</span>

<span class="token comment">-- SemanticException:Expression not in GROUP BY key 'deaths'</span>
<span class="token comment">-- deaths不是分组字段 报错</span>
<span class="token comment">-- state是分组字段 可以直接出现在select_expr中</span>
<span class="token keyword">select</span> state<span class="token punctuation">,</span>deaths
<span class="token keyword">from</span> t_usa_covid19_p 
<span class="token keyword">where</span> count_date <span class="token operator">=</span> <span class="token string">&quot;2021-01-28&quot;</span> 
<span class="token keyword">group</span> <span class="token keyword">by</span> state<span class="token punctuation">;</span>

<span class="token comment">-- 被聚合函数应用</span>
<span class="token keyword">select</span> state<span class="token punctuation">,</span><span class="token function">count</span><span class="token punctuation">(</span>deaths<span class="token punctuation">)</span>
<span class="token keyword">from</span> t_usa_covid19_p 
<span class="token keyword">where</span> count_date <span class="token operator">=</span> <span class="token string">&quot;2021-01-28&quot;</span> 
<span class="token keyword">group</span> <span class="token keyword">by</span> state<span class="token punctuation">;</span>
</code></pre></div><h4 id="having"><a href="#having" class="header-anchor">#</a> HAVING</h4> <p>在SQL中增加HAVING子句原因是，<strong>WHERE关键字无法与聚合函数一起使用</strong>。</p> <p>HAVING子句可以让我们筛选分组后的各组数据,并且可以在Having中使用聚合函数，因为此时where，group by已经执行结束，<strong>结果集已经确定</strong>。</p> <div class="language-SQL extra-class"><pre class="language-sql"><code><span class="token comment">-- having</span>
<span class="token comment">-- 统计死亡病例数大于10000的州</span>
<span class="token comment">-- where语句中不能使用聚合函数 语法报错</span>
<span class="token keyword">select</span> state<span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span>deaths<span class="token punctuation">)</span>
<span class="token keyword">from</span> t_usa_covid19_p
<span class="token keyword">where</span> count_date <span class="token operator">=</span> <span class="token string">&quot;2021-01-28&quot;</span> <span class="token operator">and</span> <span class="token function">sum</span><span class="token punctuation">(</span>deaths<span class="token punctuation">)</span> <span class="token operator">&gt;</span><span class="token number">10000</span> <span class="token keyword">group</span> <span class="token keyword">by</span> state<span class="token punctuation">;</span>

<span class="token comment">-- 先where分组前过滤（此处是分区裁剪），再进行group by分组（含聚合）， </span>
<span class="token comment">-- 分组后每个分组结果集确定 再使用having过滤</span>
<span class="token keyword">select</span> state<span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span>deaths<span class="token punctuation">)</span>
<span class="token keyword">from</span> t_usa_covid19_p
<span class="token keyword">where</span> count_date <span class="token operator">=</span> <span class="token string">&quot;2021-01-28&quot;</span>
<span class="token keyword">group</span> <span class="token keyword">by</span> state
<span class="token keyword">having</span> <span class="token function">sum</span><span class="token punctuation">(</span>deaths<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">10000</span><span class="token punctuation">;</span>

<span class="token comment">-- 这样写更好 即在group by的时候聚合函数已经作用得出结果 having直接引用结果过滤 不需要再单独计算一次了</span>
<span class="token keyword">select</span> state<span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span>deaths<span class="token punctuation">)</span> <span class="token keyword">as</span> cnts
<span class="token keyword">from</span> t_usa_covid19_p
<span class="token keyword">where</span> count_date <span class="token operator">=</span> <span class="token string">&quot;2021-01-28&quot;</span>
<span class="token keyword">group</span> <span class="token keyword">by</span> state
<span class="token keyword">having</span> cnts<span class="token operator">&gt;</span> <span class="token number">10000</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="having与where区别"><a href="#having与where区别" class="header-anchor">#</a> HAVING与WHERE区别</h4> <ul><li>having是在<strong>分组后</strong>对数据进行<strong>过滤</strong></li> <li>where是在<strong>分组前</strong>对数据进行过滤</li> <li>having后面<strong>可以使用聚合函数</strong></li> <li>where后面不可以使用聚合函数</li></ul> <h4 id="limit"><a href="#limit" class="header-anchor">#</a> LIMIT</h4> <p>LIMIT用于<strong>限制SELECT语句返回的行数</strong>。</p> <p>LIMIT接受一个或两个数字参数，这两个参数都必须是<strong>非负整数常量</strong>。</p> <p>第一个参数指定要返回的<strong>第一行的偏移量</strong>（从 Hive 2.0.0开始），第二个参数指定要返回的<strong>最大行数</strong>。当给出<strong>单个参数</strong>时，它代表<strong>最大行数</strong>，并且<strong>偏移量默认为0</strong>。</p> <div class="language-SQL extra-class"><pre class="language-sql"><code><span class="token comment">-- limit</span>
<span class="token comment">-- 没有限制返回2021.1.28 加州的所有记录</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19_p
<span class="token keyword">where</span> count_date <span class="token operator">=</span> <span class="token string">&quot;2021-01-28&quot;</span>
<span class="token operator">and</span> state <span class="token operator">=</span><span class="token string">&quot;California&quot;</span><span class="token punctuation">;</span>

<span class="token comment">-- 返回结果集的前5条</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19_p
<span class="token keyword">where</span> count_date <span class="token operator">=</span> <span class="token string">&quot;2021-01-28&quot;</span>
<span class="token operator">and</span> state <span class="token operator">=</span><span class="token string">&quot;California&quot;</span>
<span class="token keyword">limit</span> <span class="token number">5</span><span class="token punctuation">;</span>

<span class="token comment">-- 返回结果集从第1行开始 共3行</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19_p
<span class="token keyword">where</span> count_date <span class="token operator">=</span> <span class="token string">&quot;2021-01-28&quot;</span>
<span class="token operator">and</span> state <span class="token operator">=</span><span class="token string">&quot;California&quot;</span>
<span class="token keyword">limit</span> <span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">;</span> <span class="token comment">-- 注意 第一个参数偏移量是从0开始的</span>
</code></pre></div><h4 id="hive-sql-查询执行顺序"><a href="#hive-sql-查询执行顺序" class="header-anchor">#</a> Hive SQL 查询执行顺序</h4> <p>在查询过程中执行顺序：<strong>from &gt; where &gt; group（含聚合）&gt; having &gt;order &gt; select；</strong></p> <ul><li>聚合语句(sum,min,max,avg,count)要比having子句优先执行</li> <li>where子句在查询过程中执行优先级别优先于聚合语句(sum,min,max,avg,count)</li></ul> <p>结合下面SQL感受一下：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">select</span> state<span class="token punctuation">,</span><span class="token function">sum</span><span class="token punctuation">(</span>deaths<span class="token punctuation">)</span> <span class="token keyword">as</span> cnts
<span class="token keyword">from</span> t_usa_covid19_p
<span class="token keyword">where</span> count_date <span class="token operator">=</span> <span class="token string">&quot;2021-01-28&quot;</span>
<span class="token keyword">group</span> <span class="token keyword">by</span> state
<span class="token keyword">having</span> cnts<span class="token operator">&gt;</span> <span class="token number">10000</span><span class="token punctuation">;</span>
</code></pre></div><h3 id="高阶查询"><a href="#高阶查询" class="header-anchor">#</a> 高阶查询</h3> <h4 id="order-by"><a href="#order-by" class="header-anchor">#</a> ORDER BY</h4> <p>Hive SQL中的ORDER BY语法类似于标准SQL语言中的ORDER BY语法，会对<strong>输出的结果进行全局排序</strong>。</p> <p>因此当底层使用MapReduce引擎执行的时候，只会有一个reducetask执行。如果输出的行数太大，会导致需要很长的时间才能完成全局排序。</p> <p><strong>默认</strong>排序为<strong>升序（ASC）</strong>，也可以指定为DESC降序。</p> <p>在Hive 2.1.0和更高版本中，支持在ORDER BY子句中为每个列指定null类型结果排序顺序。</p> <ul><li>ASC顺序的默认空排序顺序为<strong>NULLS FIRST</strong>，而DESC顺序的默认空排序顺序为<strong>NULLS LAST</strong>。</li></ul> <div class="language-SQL extra-class"><pre class="language-sql"><code><span class="token comment">--- order by</span>
<span class="token comment">-- 根据字段进行排序</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19_p
<span class="token keyword">where</span> count_date <span class="token operator">=</span> <span class="token string">&quot;2021-01-28&quot;</span>
<span class="token operator">and</span> state <span class="token operator">=</span><span class="token string">&quot;California&quot;</span>
<span class="token keyword">order</span> <span class="token keyword">by</span> deaths<span class="token punctuation">;</span> <span class="token comment">-- 默认asc null first</span>

<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19_p
<span class="token keyword">where</span> count_date <span class="token operator">=</span> <span class="token string">&quot;2021-01-28&quot;</span>
<span class="token operator">and</span> state <span class="token operator">=</span><span class="token string">&quot;California&quot;</span>
<span class="token keyword">order</span> <span class="token keyword">by</span> deaths <span class="token keyword">desc</span><span class="token punctuation">;</span> <span class="token comment">-- 指定desc null last</span>

<span class="token comment">-- 强烈建议将LIMIT与ORDER BY一起使用。避免数据集行数过大</span>
<span class="token comment">-- 当hive.mapred.mode设置为strict严格模式时，使用不带LIMIT的ORDER BY时会引发异常。</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t_usa_covid19_p
<span class="token keyword">where</span> count_date <span class="token operator">=</span> <span class="token string">&quot;2021-01-28&quot;</span>
  <span class="token operator">and</span> state <span class="token operator">=</span><span class="token string">&quot;California&quot;</span>
<span class="token keyword">order</span> <span class="token keyword">by</span> deaths <span class="token keyword">desc</span>
<span class="token keyword">limit</span> <span class="token number">3</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="cluster-by"><a href="#cluster-by" class="header-anchor">#</a> CLUSTER BY</h4> <p>根据指定字段将数据分组，每组内再根据该字段正序排序（只能正序, 不允许指定排序规则）。</p> <p>概况起来就是：根据同一个字段，<strong>分且排序</strong>。</p> <p>分组规则hash散列（分桶表规则一样）：Hash_Func(col_name) % reducetask个数</p> <p>分为几组取决于reducetask的个数</p> <p><img src="/study/assets/img/image-20210904145214001.07a400ac.png" alt="image-20210904145214001"></p> <div class="language-SQL extra-class"><pre class="language-sql"><code><span class="token comment">-- cluster by</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>
<span class="token comment">-- 不指定reduce task个数</span>
<span class="token comment">-- 日志显示：Number of reduce tasks not specified. Estimated from input data size: 1</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student cluster <span class="token keyword">by</span> sno<span class="token punctuation">;</span>

<span class="token comment">-- 手动设置reduce task个数</span>
<span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>job<span class="token punctuation">.</span>reduces <span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student cluster <span class="token keyword">by</span> sno<span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210904150054758.ed85698c.png" alt="image-20210904150054758"></p> <p>​	  默认情况下，reduce task的个数由Hive在编译期间自己决定。</p> <p><img src="/study/assets/img/image-20210904150117534.3c62eff4.png" alt="image-20210904150117534"></p> <p>​	  设置set mapreduce.job.reduces =2;</p> <p><img src="/study/assets/img/image-20210904150141710.8efb0238.png" alt="image-20210904150141710"></p> <p>​	  执行结果如下：分为两个部分，每个部分内正序排序。</p> <p><img src="/study/assets/img/image-20210904150237943.1486f333.png" alt="image-20210904150237943"></p> <p><strong>CLUSTER BY 局限性</strong></p> <p>假如说，现在想法如下：把学生表数据根据性别分为两个部分，每个分组内根据年龄的倒序排序。你会发现CLUSTER BY无法完成了。而order by更不能在这里使用，因为它是全局排序，一旦使用order by，编译期间就会强制把reduce task个数设置为1。无法满足分组的需求。</p> <h4 id="distribute-by-sort-by"><a href="#distribute-by-sort-by" class="header-anchor">#</a> DISTRIBUTE BY + SORT BY</h4> <p>DISTRIBUTE BY + SORT BY就相当于把CLUSTER BY的功能一分为二：</p> <ul><li>DISTRIBUTE BY负责根据指定字段分组；</li> <li>SORT BY负责分组内排序规则。</li></ul> <p>分组和排序的字段可以不同。如果DISTRIBUTE BY +SORT BY的字段一样，可以得出下列结论：</p> <p>​								<strong>CLUSTER BY=DISTRIBUTE BY +SORT BY</strong></p> <p>案例：把学生表数据根据性别分为两个部分，每个分组内根据年龄的倒序排序。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student distribute <span class="token keyword">by</span> sex sort <span class="token keyword">by</span> sage <span class="token keyword">desc</span><span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210904151350694.ff633873.png" alt="image-20210904151350694"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 下面两个语句执行结果一样</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student distribute <span class="token keyword">by</span> sno sort <span class="token keyword">by</span> sno<span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student cluster <span class="token keyword">by</span> sno<span class="token punctuation">;</span>
</code></pre></div><h4 id="排序总结"><a href="#排序总结" class="header-anchor">#</a> 排序总结</h4> <ul><li><strong>order by全局排序</strong>，因此<strong>只有一个reducer，结果输出在一个文件中</strong>，当输入规模大时，需要较长的计算时间。</li> <li>distribute by根据指定字段将数据分组，算法是hash散列。sort by是在分组之后，每个组内局部排序。</li> <li>cluster by既有分组，又有排序，但是两个字段只能是同一个字段。</li> <li>如果distribute和sort的字段是同一个时，此时，cluster by = distribute by + sort by</li></ul> <h4 id="union-联合查询"><a href="#union-联合查询" class="header-anchor">#</a> Union 联合查询</h4> <p>UNION用于将来自于<strong>多个SELECT语句的结果合并为一个结果集</strong>。</p> <p><img src="/study/assets/img/image-20210904152640374.fb4dc88b.png" alt="image-20210904152640374"></p> <ul><li>使用DISTINCT关键字与只使用UNION默认值效果一样，都会删除重复行。1.2.0之前的Hive版本仅支持UNION ALL，在这种情况下不会消除重复的行。</li> <li>使用ALL关键字，不会删除重复行，结果集包括所有SELECT语句的匹配行（包括重复行）。</li> <li>每个select_statement返回的列的数量和名称必须相同。</li></ul> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- union</span>
<span class="token comment">-- 使用DISTINCT关键字与使用UNION默认值效果一样，都会删除重复行。</span>
<span class="token keyword">select</span> num<span class="token punctuation">,</span>name <span class="token keyword">from</span> student_local
<span class="token keyword">UNION</span>
<span class="token keyword">select</span> num<span class="token punctuation">,</span>name <span class="token keyword">from</span> student_hdfs<span class="token punctuation">;</span>
<span class="token comment">-- 和上面一样</span>
<span class="token keyword">select</span> num<span class="token punctuation">,</span>name <span class="token keyword">from</span> student_local
<span class="token keyword">UNION</span> <span class="token keyword">DISTINCT</span>
<span class="token keyword">select</span> num<span class="token punctuation">,</span>name <span class="token keyword">from</span> student_hdfs<span class="token punctuation">;</span>

<span class="token comment">-- 使用ALL关键字会保留重复行。</span>
<span class="token keyword">select</span> num<span class="token punctuation">,</span>name <span class="token keyword">from</span> student_local
<span class="token keyword">UNION</span> <span class="token keyword">ALL</span>
<span class="token keyword">select</span> num<span class="token punctuation">,</span>name <span class="token keyword">from</span> student_hdfs<span class="token punctuation">;</span>

<span class="token comment">-- 如果要将ORDER BY，SORT BY，CLUSTER BY，DISTRIBUTE BY或LIMIT应用于单个SELECT</span>
<span class="token comment">-- 请将子句放在括住SELECT的括号内</span>
<span class="token keyword">SELECT</span> sno<span class="token punctuation">,</span>sname <span class="token keyword">FROM</span> <span class="token punctuation">(</span><span class="token keyword">select</span> sno<span class="token punctuation">,</span>sname <span class="token keyword">from</span> student_local <span class="token keyword">LIMIT</span> <span class="token number">2</span><span class="token punctuation">)</span> subq1
<span class="token keyword">UNION</span>
<span class="token keyword">SELECT</span> sno<span class="token punctuation">,</span>sname <span class="token keyword">FROM</span> <span class="token punctuation">(</span><span class="token keyword">select</span> sno<span class="token punctuation">,</span>sname <span class="token keyword">from</span> student_hdfs <span class="token keyword">LIMIT</span> <span class="token number">3</span><span class="token punctuation">)</span> subq2

<span class="token comment">-- 如果要将ORDER BY，SORT BY，CLUSTER BY，DISTRIBUTE BY或LIMIT子句应用于整个UNION结果</span>
<span class="token comment">-- 请将ORDER BY，SORT BY，CLUSTER BY，DISTRIBUTE BY或LIMIT放在最后一个之后。</span>
<span class="token keyword">select</span> sno<span class="token punctuation">,</span>sname <span class="token keyword">from</span> student_local
<span class="token keyword">UNION</span>
<span class="token keyword">select</span> sno<span class="token punctuation">,</span>sname <span class="token keyword">from</span> student_hdfs
<span class="token keyword">order</span> <span class="token keyword">by</span> sno <span class="token keyword">desc</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="子查询"><a href="#子查询" class="header-anchor">#</a> 子查询</h4> <h5 id="from-子句中子查询"><a href="#from-子句中子查询" class="header-anchor">#</a> from 子句中子查询</h5> <p>在Hive0.12版本，仅在FROM子句中支持子查询。</p> <ul><li>必须要给子查询一个名称，因为FROM子句中的每个表都必须有一个名称。子查询返回结果中的列必须具有唯一的名称。子查询返回结果中的列在外部查询中可用，就像真实表的列一样。子查询也可以是带有UNION的查询表达式。</li></ul> <p>Hive支持任意级别的子查询，也就是所谓的<strong>嵌套子查询</strong>。</p> <p>Hive 0.13.0和更高版本中的子查询名称之前可以包含可选关键字AS。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- from子句中子查询（Subqueries）</span>
<span class="token comment">-- 子查询</span>
<span class="token keyword">SELECT</span> num
<span class="token keyword">FROM</span> <span class="token punctuation">(</span>
         <span class="token keyword">select</span> num<span class="token punctuation">,</span>name <span class="token keyword">from</span> student_local
     <span class="token punctuation">)</span> tmp<span class="token punctuation">;</span>

<span class="token comment">-- 包含UNION ALL的子查询的示例</span>
<span class="token keyword">SELECT</span> t3<span class="token punctuation">.</span>name
<span class="token keyword">FROM</span> <span class="token punctuation">(</span>
         <span class="token keyword">select</span> num<span class="token punctuation">,</span>name <span class="token keyword">from</span> student_local
         <span class="token keyword">UNION</span> <span class="token keyword">distinct</span>
         <span class="token keyword">select</span> num<span class="token punctuation">,</span>name <span class="token keyword">from</span> student_hdfs
     <span class="token punctuation">)</span> t3<span class="token punctuation">;</span>
</code></pre></div><h5 id="where-子句中子查询"><a href="#where-子句中子查询" class="header-anchor">#</a> where 子句中子查询</h5> <p>从Hive 0.13开始，WHERE子句支持下述类型的子查询：</p> <ul><li>不相关子查询：该子查询不引用父查询中的列，可以将查询结果视为IN和NOT IN语句的常量；</li> <li>相关子查询：子查询引用父查询中的列；</li></ul> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- where子句中子查询（Subqueries）</span>
<span class="token comment">-- 不相关子查询，相当于IN、NOT IN,子查询只能选择一个列。</span>
<span class="token comment">--（1）执行子查询，其结果不被显示，而是传递给外部查询，作为外部查询的条件使用。</span>
<span class="token comment">--（2）执行外部查询，并显示整个结果。　　</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span>
<span class="token keyword">FROM</span> student_hdfs
<span class="token keyword">WHERE</span> student_hdfs<span class="token punctuation">.</span>num <span class="token operator">IN</span> <span class="token punctuation">(</span><span class="token keyword">select</span> num <span class="token keyword">from</span> student_local <span class="token keyword">limit</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 相关子查询，指EXISTS和NOT EXISTS子查询</span>
<span class="token comment">-- 子查询的WHERE子句中支持对父查询的引用</span>
<span class="token keyword">SELECT</span> A
<span class="token keyword">FROM</span> T1
<span class="token keyword">WHERE</span> <span class="token keyword">EXISTS</span> <span class="token punctuation">(</span><span class="token keyword">SELECT</span> B <span class="token keyword">FROM</span> T2 <span class="token keyword">WHERE</span> T1<span class="token punctuation">.</span>X <span class="token operator">=</span> T2<span class="token punctuation">.</span>Y<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="common-table-expressions-cte"><a href="#common-table-expressions-cte" class="header-anchor">#</a> Common Table Expressions（CTE）</h4> <p>**公用表表达式（CTE）**是一个临时结果集：该结果集是从WITH子句中指定的简单查询派生而来的，紧接在SELECT或INSERT关键字之前。</p> <p>CTE仅在<strong>单个语句的执行范围内</strong>定义。</p> <p>CTE可以在 SELECT，INSERT， CREATE TABLE AS SELECT或CREATE VIEW AS SELECT语句中使用。</p> <p><img src="/study/assets/img/image-20210904153339265.87878bfc.png" alt="image-20210904153339265"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 选择语句中的CTE</span>
<span class="token keyword">with</span> q1 <span class="token keyword">as</span> <span class="token punctuation">(</span><span class="token keyword">select</span> sno<span class="token punctuation">,</span>sname<span class="token punctuation">,</span>sage <span class="token keyword">from</span> student <span class="token keyword">where</span> sno <span class="token operator">=</span> <span class="token number">95002</span><span class="token punctuation">)</span>
<span class="token keyword">select</span> <span class="token operator">*</span>
<span class="token keyword">from</span> q1<span class="token punctuation">;</span>

<span class="token comment">-- from风格</span>
<span class="token keyword">with</span> q1 <span class="token keyword">as</span> <span class="token punctuation">(</span><span class="token keyword">select</span> sno<span class="token punctuation">,</span>sname<span class="token punctuation">,</span>sage <span class="token keyword">from</span> student <span class="token keyword">where</span> sno <span class="token operator">=</span> <span class="token number">95002</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> q1
<span class="token keyword">select</span> <span class="token operator">*</span><span class="token punctuation">;</span>

<span class="token comment">-- chaining CTEs 链式</span>
<span class="token keyword">with</span> q1 <span class="token keyword">as</span> <span class="token punctuation">(</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student <span class="token keyword">where</span> sno <span class="token operator">=</span> <span class="token number">95002</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     q2 <span class="token keyword">as</span> <span class="token punctuation">(</span> <span class="token keyword">select</span> sno<span class="token punctuation">,</span>sname<span class="token punctuation">,</span>sage <span class="token keyword">from</span> q1<span class="token punctuation">)</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> <span class="token punctuation">(</span><span class="token keyword">select</span> sno <span class="token keyword">from</span> q2<span class="token punctuation">)</span> a<span class="token punctuation">;</span>


<span class="token comment">-- union案例</span>
<span class="token keyword">with</span> q1 <span class="token keyword">as</span> <span class="token punctuation">(</span><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student <span class="token keyword">where</span> sno <span class="token operator">=</span> <span class="token number">95002</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
     q2 <span class="token keyword">as</span> <span class="token punctuation">(</span><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student <span class="token keyword">where</span> sno <span class="token operator">=</span> <span class="token number">95004</span><span class="token punctuation">)</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> q1 <span class="token keyword">union</span> <span class="token keyword">all</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> q2<span class="token punctuation">;</span>

<span class="token comment">--视图，CTAS和插入语句中的CTE</span>
<span class="token comment">-- insert</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> s1 <span class="token operator">like</span> student<span class="token punctuation">;</span>

<span class="token keyword">with</span> q1 <span class="token keyword">as</span> <span class="token punctuation">(</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student <span class="token keyword">where</span> sno <span class="token operator">=</span> <span class="token number">95002</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> q1
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> s1
<span class="token keyword">select</span> <span class="token operator">*</span><span class="token punctuation">;</span>

<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> s1<span class="token punctuation">;</span>

<span class="token comment">-- ctas</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> s2 <span class="token keyword">as</span>
<span class="token keyword">with</span> q1 <span class="token keyword">as</span> <span class="token punctuation">(</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student <span class="token keyword">where</span> sno <span class="token operator">=</span> <span class="token number">95002</span><span class="token punctuation">)</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> q1<span class="token punctuation">;</span>

<span class="token comment">-- view</span>
<span class="token keyword">create</span> <span class="token keyword">view</span> v1 <span class="token keyword">as</span>
<span class="token keyword">with</span> q1 <span class="token keyword">as</span> <span class="token punctuation">(</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student <span class="token keyword">where</span> sno <span class="token operator">=</span> <span class="token number">95002</span><span class="token punctuation">)</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> q1<span class="token punctuation">;</span>

<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> v1<span class="token punctuation">;</span>
</code></pre></div><h3 id="join-连接查询"><a href="#join-连接查询" class="header-anchor">#</a> join 连接查询</h3> <h4 id="join概念回顾"><a href="#join概念回顾" class="header-anchor">#</a> join概念回顾</h4> <p>根据数据库的<strong>三范式设计</strong>要求和日常工作习惯来说，我们通常不会设计一张大表把所有类型的数据都放在一起，而是<strong>不同类型的数据设计不同的表</strong>存储。</p> <p>比如在设计一个订单数据表的时候，可以将客户编号作为一个外键和订单表建立相应的关系。而不可以在订单表中添加关于客户其它信息（比如姓名、所属公司等）的字段。</p> <p><img src="/study/assets/img/image-20210904153604476.0acc30d0.png" alt="image-20210904153604476">
在这种情况下，有时需要基于多张表查询才能得到最终完整的结果；</p> <p>join语法的出现是<strong>用于根据两个或多个表中的列之间的关系，从这些表中共同组合查询数据</strong>。</p> <h4 id="join语法规则"><a href="#join语法规则" class="header-anchor">#</a> join语法规则</h4> <p>在Hive中，当下版本3.1.2总共支持6种join语法。分别是：</p> <ul><li><p><strong>inner join（内连接）</strong></p></li> <li><p><strong>left join（左连接）</strong></p></li> <li><p>right join（右连接）</p></li> <li><p>full outer join（全外连接）</p></li> <li><p>left semi join（左半开连接）</p></li> <li><p>cross join（交叉连接，也叫做笛卡尔乘积）</p></li></ul> <h4 id="语法树-2"><a href="#语法树-2" class="header-anchor">#</a> 语法树</h4> <p><img src="/study/assets/img/image-20210904153839018.7ed301a2.png" alt="image-20210904153839018"></p> <ul><li>**table_reference：**是join查询中使用的表名，也可以是子查询别名（查询结果当成表参与join）。</li> <li>**table_factor：**与table_reference相同,是联接查询中使用的表名,也可以是子查询别名。</li> <li>**join_condition：**join查询关联的条件，如果在两个以上的表上需要连接，则使用AND关键字。</li></ul> <h4 id="join语法丰富化"><a href="#join语法丰富化" class="header-anchor">#</a> join语法丰富化</h4> <p>Hive中join语法从面世开始其实并不丰富，不像在RDBMS中那么灵活。</p> <p>从Hive 0.13.0开始，<strong>支持隐式联接表示法</strong>（请参阅HIVE-5558）。允许FROM子句连接以逗号分隔的表列表，而省略JOIN关键字。例如：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">SELECT</span> <span class="token operator">*</span>
<span class="token keyword">FROM</span> table1 t1<span class="token punctuation">,</span> table2 t2<span class="token punctuation">,</span> table3 t3
<span class="token keyword">WHERE</span> t1<span class="token punctuation">.</span>id <span class="token operator">=</span> t2<span class="token punctuation">.</span>id <span class="token operator">AND</span> t2<span class="token punctuation">.</span>id <span class="token operator">=</span> t3<span class="token punctuation">.</span>id <span class="token operator">AND</span> t1<span class="token punctuation">.</span>zipcode <span class="token operator">=</span> <span class="token string">'02535'</span><span class="token punctuation">;</span>
</code></pre></div><p>从Hive 2.2.0开始，支持ON子句中的复杂表达式，支持不相等连接（请参阅HIVE-15211和HIVE-15251）。在此之前，Hive不支持不是相等条件的联接条件。例如：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">SELECT</span> a<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">FROM</span> a <span class="token keyword">JOIN</span> b <span class="token keyword">ON</span> <span class="token punctuation">(</span>a<span class="token punctuation">.</span>id <span class="token operator">=</span> b<span class="token punctuation">.</span>id<span class="token punctuation">)</span>
<span class="token keyword">SELECT</span> a<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">FROM</span> a <span class="token keyword">JOIN</span> b <span class="token keyword">ON</span> <span class="token punctuation">(</span>a<span class="token punctuation">.</span>id <span class="token operator">=</span> b<span class="token punctuation">.</span>id <span class="token operator">AND</span> a<span class="token punctuation">.</span>department <span class="token operator">=</span> b<span class="token punctuation">.</span>department<span class="token punctuation">)</span>
<span class="token keyword">SELECT</span> a<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">FROM</span> a <span class="token keyword">LEFT</span> <span class="token keyword">OUTER</span> <span class="token keyword">JOIN</span> b <span class="token keyword">ON</span> <span class="token punctuation">(</span>a<span class="token punctuation">.</span>id <span class="token operator">&lt;&gt;</span> b<span class="token punctuation">.</span>id<span class="token punctuation">)</span>
</code></pre></div><h4 id="join查询数据环境准备"><a href="#join查询数据环境准备" class="header-anchor">#</a> join查询数据环境准备</h4> <p>为了更好的练习、学习掌握Hive中的join语法，下面我们去创建3张表并且加载数据到表中。</p> <p>表1：employee 员工表；
表2：employee_address 员工住址信息表；
表3：employee_connection 员工联系方式表；</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- table1: 员工表</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> employee<span class="token punctuation">(</span>
   id <span class="token keyword">int</span><span class="token punctuation">,</span>
   name string<span class="token punctuation">,</span>
   deg string<span class="token punctuation">,</span>
   salary <span class="token keyword">int</span><span class="token punctuation">,</span>
   dept string
 <span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>

<span class="token comment">-- table2:员工住址信息表</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> employee_address <span class="token punctuation">(</span>
    id <span class="token keyword">int</span><span class="token punctuation">,</span>
    hno string<span class="token punctuation">,</span>
    street string<span class="token punctuation">,</span>
    city string
<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>

<span class="token comment">-- table3:员工联系方式表</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> employee_connection <span class="token punctuation">(</span>
    id <span class="token keyword">int</span><span class="token punctuation">,</span>
    phno string<span class="token punctuation">,</span>
    email string
<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>

<span class="token comment">-- 加载数据到表中</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/hivedata/employee.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> employee<span class="token punctuation">;</span>

<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/hivedata/employee_address.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> employee_address<span class="token punctuation">;</span>

<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/hivedata/employee_connection.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> employee_connection<span class="token punctuation">;</span>
</code></pre></div><p><img src="/study/assets/img/image-20210904154810623.aea8859b.png" alt="image-20210904154810623"></p> <h4 id="inner-join-内连接"><a href="#inner-join-内连接" class="header-anchor">#</a> inner join 内连接</h4> <p><strong>内连接</strong>是最常见的一种连接，它也被称为普通连接，其中inner可以省略：inner join == join ；</p> <p>只有进行连接的两个表中都存在与连接条件相匹配的数据才会被留下来。</p> <p><img src="/study/assets/img/image-20210904154856305.e92ea50a.png" alt="image-20210904154856305"></p> <p><img src="/study/assets/img/image-20210904155627123.67fc4c69.png" alt="image-20210904155627123"></p> <h4 id="left-join-左连接"><a href="#left-join-左连接" class="header-anchor">#</a> left join 左连接</h4> <p>left join中文叫做是<strong>左外连接</strong>(Left Outer Join)或者左连接，其中outer可以省略，left outer join是早期的写法。</p> <p>left join的核心就在于left左。左指的是join关键字左边的表，简称左表。</p> <p>通俗解释：join时以左表的全部数据为准，右边与之关联；左表数据全部返回，右表关联上的显示返回，关联不上的显示null返回。</p> <p><img src="/study/assets/img/image-20210904155136765.5377ca3a.png" alt="image-20210904155136765"></p> <p><img src="/study/assets/img/image-20210904155724528.1255ab03.png" alt="image-20210904155724528"></p> <h4 id="right-join-右连接"><a href="#right-join-右连接" class="header-anchor">#</a> right join 右连接</h4> <p>right join中文叫做是右外连接(Right Outer Jion)或者右连接，其中outer可以省略。</p> <p>right join的核心就在于Right右。右指的是join关键字右边的表，简称右表。</p> <p>通俗解释：<strong>join时以右表的全部数据为准，左边与之关联；右表数据全部返回，左表关联上的显示返回，关联不上的显示null返回。</strong></p> <p>很明显，right join和left join之间很相似，重点在于以哪边为准，也就是一个方向的问题。</p> <p><img src="/study/assets/img/image-20210904155320018.a528a961.png" alt="image-20210904155320018"></p> <p><img src="/study/assets/img/image-20210904155748861.683ee108.png" alt="image-20210904155748861"></p> <h4 id="full-outer-join-全外连接"><a href="#full-outer-join-全外连接" class="header-anchor">#</a> full outer join 全外连接</h4> <p><strong>full outer join 等价 full join</strong>  ,中文叫做<strong>全外连接</strong>或者外连接。</p> <p>包含左、右两个表的全部行，不管另外一边的表中是否存在与它们匹配的行；</p> <p>在功能上：等价于对这两个数据集合分别进行左外连接和右外连接，然后再使用<strong>消去重复行</strong>的操作将上述两个结果集合并为一个结果集。</p> <p><img src="/study/assets/img/image-20210904155501610.f5b465bc.png" alt="image-20210904155501610"></p> <p><img src="/study/assets/img/image-20210904155825583.5be33c8b.png" alt="image-20210904155825583"></p> <h4 id="left-semi-join-左半开连接"><a href="#left-semi-join-左半开连接" class="header-anchor">#</a> left semi join 左半开连接</h4> <p>左半开连接（LEFT SEMI JOIN）会<strong>返回左边表的记录</strong>，前提是其记录对于右边的表<strong>满足ON</strong>语句中的<strong>判定条件</strong>。</p> <p>从效果上来看有点像inner join之后只返回左表的结果。</p> <p><img src="/study/assets/img/image-20210904160024141.3dae7e40.png" alt="image-20210904160024141"></p> <h4 id="cross-join-交叉连接"><a href="#cross-join-交叉连接" class="header-anchor">#</a> cross join 交叉连接</h4> <p><strong>交叉连接</strong>cross join，将会返回被连接的两个表的笛卡尔积，返回结果的行数等于两个表行数的乘积。对于大表来说，cross join慎用。</p> <p>在SQL标准中定义的cross join就是无条件的inner join。返回两个表的笛卡尔积,无需指定关联键。</p> <p>在HiveSQL语法中，cross join 后面可以跟where子句进行过滤，或者on条件过滤。</p> <p><img src="/study/assets/img/image-20210904160158015.679cd841.png" alt="image-20210904160158015"></p> <h4 id="join-连接主要事项"><a href="#join-连接主要事项" class="header-anchor">#</a> join 连接主要事项</h4> <ul><li><p>join在WHERE条件之前进行</p></li> <li><p>允许使用复杂的联接表达式,支持非等值连接</p> <p><img src="/study/assets/img/image-20210904160511267.f92a9c1b.png" alt="image-20210904160511267"></p></li> <li><p>同一查询中可以连接2个以上的表</p> <p><img src="/study/assets/img/image-20210904160441034.7ee6dcd7.png" alt="image-20210904160441034"></p></li> <li><p>如果每个表在联接子句中使用相同的列，则Hive将多个表上的联接转换为单个MR作业</p> <p><img src="/study/assets/img/image-20210904160639928.3bc2c0a3.png" alt="image-20210904160639928"></p></li> <li><p>在join的时候，可以通过语法STREAMTABLE提示指定要流式传输的表。如果省略STREAMTABLE提示，则Hive将流式传输最右边的表</p> <p><img src="/study/assets/img/image-20210904160903935.ca0555ef.png" alt="image-20210904160903935"></p></li> <li><p>如果除一个要连接的表之外的所有表都很小，则可以将其作为仅map作业执行（mapjoin）</p> <p><img src="/study/assets/img/image-20210904160952831.6d43dbf6.png" alt="image-20210904160952831"></p></li> <li><p>join时的最后一个表会通过reducer流式传输，并在其中缓冲之前的其他表，因此，将大表放置在最后有助于减少reducer阶段缓存数据所需要的内存</p> <p><img src="/study/assets/img/image-20210904160715434.4c8139b5.png" alt="image-20210904160715434"></p></li></ul> <h2 id="hive-内置运算符"><a href="#hive-内置运算符" class="header-anchor">#</a> Hive 内置运算符</h2> <h3 id="概述"><a href="#概述" class="header-anchor">#</a> 概述</h3> <p>整体上，Hive支持的运算符可以分为三大类：<strong>关系运算</strong>、<strong>算术运算</strong>、<strong>逻辑运算</strong>。</p> <p>官方参考文档：https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF</p> <p>也可以使用下述方式查看运算符的使用方式：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 显示所有的函数和运算符</span>
<span class="token keyword">show</span> functions<span class="token punctuation">;</span>
<span class="token comment">-- 查看运算符或者函数的使用说明</span>
<span class="token keyword">describe</span> <span class="token keyword">function</span> <span class="token operator">+</span><span class="token punctuation">;</span>
<span class="token comment">-- 使用extended 可以查看更加详细的使用说明</span>
<span class="token keyword">describe</span> <span class="token keyword">function</span> <span class="token keyword">extended</span> <span class="token operator">+</span><span class="token punctuation">;</span>
</code></pre></div><h3 id="关系运算符"><a href="#关系运算符" class="header-anchor">#</a> 关系运算符</h3> <p><strong>关系运算符</strong>是二元运算符，执行的是两个操作数的比较运算。每个关系运算符都返回boolean类型结果（TRUE或FALSE）。</p> <p><img src="/study/assets/img/image-20210904163715786.ae3a92e3.png" alt="image-20210904163715786"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- is null空值判断</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token string">'123456'</span> <span class="token operator">is</span> <span class="token boolean">null</span><span class="token punctuation">;</span>

<span class="token comment">--is not null 非空值判断</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token string">'123456'</span> <span class="token operator">is</span> <span class="token operator">not</span> <span class="token boolean">null</span><span class="token punctuation">;</span>

<span class="token comment">--like比较： _表示任意单个字符 %表示任意数量字符</span>
<span class="token comment">--否定比较： NOT A like B</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token string">'it_123456'</span> <span class="token operator">like</span> <span class="token string">'it_'</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token string">'it_123456'</span> <span class="token operator">like</span> <span class="token string">'it%'</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token operator">not</span> <span class="token string">'hadoop_123456'</span> <span class="token operator">like</span> <span class="token string">'hadoo_'</span><span class="token punctuation">;</span>

<span class="token comment">--rlike：确定字符串是否匹配正则表达式，是REGEXP_LIKE()的同义词。</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token string">'i1245t'</span> <span class="token operator">rlike</span> <span class="token string">'^i.*t$'</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token string">'123456'</span> <span class="token operator">rlike</span> <span class="token string">'^\\d+$'</span><span class="token punctuation">;</span>  <span class="token comment">--判断是否全为数字</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token string">'123456aa'</span> <span class="token operator">rlike</span> <span class="token string">'^\\d+$'</span><span class="token punctuation">;</span>

<span class="token comment">--regexp：功能与rlike相同 用于判断字符串是否匹配正则表达式</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token string">'i1245t'</span> <span class="token operator">regexp</span> <span class="token string">'^i.*t$'</span><span class="token punctuation">;</span>
</code></pre></div><h3 id="算术运算符"><a href="#算术运算符" class="header-anchor">#</a> 算术运算符</h3> <p><strong>算术运算符</strong>操作数必须是数值类型。 分为一元运算符和二元运算符：</p> <ul><li><p>一元运算符,只有一个操作数;</p></li> <li><p>二元运算符有两个操作数,运算符在两个操作数之间。</p></li></ul> <p><img src="/study/assets/img/image-20210904164004032.4dedd509.png" alt="image-20210904164004032"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 取整操作: div  给出将A除以B所得的整数部分。例如17 div 3得出5。</span>
<span class="token keyword">select</span> <span class="token number">17</span> <span class="token operator">div</span> <span class="token number">3</span><span class="token punctuation">;</span>

<span class="token comment">-- 取余操作: %  也叫做取模  A除以B所得的余数部分</span>
<span class="token keyword">select</span> <span class="token number">17</span> <span class="token operator">%</span> <span class="token number">3</span><span class="token punctuation">;</span>

<span class="token comment">-- 位与操作: &amp;  A和B按位进行与操作的结果。 与表示两个都为1则结果为1</span>
<span class="token keyword">select</span> <span class="token number">4</span> <span class="token operator">&amp;</span> <span class="token number">8</span> <span class="token keyword">from</span> dual<span class="token punctuation">;</span>  <span class="token comment">--4转换二进制：0100 8转换二进制：1000</span>
<span class="token keyword">select</span> <span class="token number">6</span> <span class="token operator">&amp;</span> <span class="token number">4</span> <span class="token keyword">from</span> dual<span class="token punctuation">;</span>  <span class="token comment">--4转换二进制：0100 6转换二进制：0110</span>

<span class="token comment">-- 位或操作: |  A和B按位进行或操作的结果  或表示有一个为1则结果为1</span>
<span class="token keyword">select</span> <span class="token number">4</span> <span class="token operator">|</span> <span class="token number">8</span> <span class="token keyword">from</span> dual<span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token number">6</span> <span class="token operator">|</span> <span class="token number">4</span> <span class="token keyword">from</span> dual<span class="token punctuation">;</span>

<span class="token comment">-- 位异或操作: ^ A和B按位进行异或操作的结果 异或表示两个不同则结果为1</span>
<span class="token keyword">select</span> <span class="token number">4</span> <span class="token operator">^</span> <span class="token number">8</span> <span class="token keyword">from</span> dual<span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token number">6</span> <span class="token operator">^</span> <span class="token number">4</span> <span class="token keyword">from</span> dual<span class="token punctuation">;</span>
</code></pre></div><h3 id="逻辑运算符"><a href="#逻辑运算符" class="header-anchor">#</a> 逻辑运算符</h3> <p>语法：SELECT … FROM table WHERE [NOT] EXISTS (subquery)</p> <p>功能：将主查询的数据，放到子查询中做条件验证，根据验证结果（TRUE 或 FALSE）来决定主查询的数据结果是否得以保留。</p> <p><img src="/study/assets/img/image-20210904164100297.785260ad.png" alt="image-20210904164100297"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 与操作: A AND B   如果A和B均为TRUE，则为TRUE，否则为FALSE。如果A或B为NULL，则为NULL。</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token number">3</span><span class="token operator">&gt;</span><span class="token number">1</span> <span class="token operator">and</span> <span class="token number">2</span><span class="token operator">&gt;</span><span class="token number">1</span><span class="token punctuation">;</span>
<span class="token comment">-- 或操作: A OR B   如果A或B或两者均为TRUE，则为TRUE，否则为FALSE。</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token number">3</span><span class="token operator">&gt;</span><span class="token number">1</span> <span class="token operator">or</span> <span class="token number">2</span><span class="token operator">!=</span><span class="token number">2</span><span class="token punctuation">;</span>
<span class="token comment">-- 非操作: NOT A 、!A   如果A为FALSE，则为TRUE；如果A为NULL，则为NULL。否则为FALSE。</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token operator">not</span> <span class="token number">2</span><span class="token operator">&gt;</span><span class="token number">1</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token operator">!</span><span class="token number">2</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span>
<span class="token comment">-- 在:A IN (val1, val2, ...)  如果A等于任何值，则为TRUE。</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token number">11</span> <span class="token operator">in</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">,</span><span class="token number">33</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">-- 不在:A NOT IN (val1, val2, ...) 如果A不等于任何值，则为TRUE</span>
<span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> dual <span class="token keyword">where</span> <span class="token number">11</span> <span class="token operator">not</span> <span class="token operator">in</span><span class="token punctuation">(</span><span class="token number">22</span><span class="token punctuation">,</span><span class="token number">33</span><span class="token punctuation">,</span><span class="token number">44</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">-- 逻辑是否存在: [NOT] EXISTS (subquery) 如果子查询返回至少一行，则为TRUE。</span>
<span class="token keyword">select</span> A<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">from</span> A
<span class="token keyword">where</span> <span class="token keyword">exists</span> <span class="token punctuation">(</span><span class="token keyword">select</span> B<span class="token punctuation">.</span>id <span class="token keyword">from</span> B <span class="token keyword">where</span> A<span class="token punctuation">.</span>id <span class="token operator">=</span> B<span class="token punctuation">.</span>id<span class="token punctuation">)</span>
</code></pre></div><h2 id="hive-函数入门"><a href="#hive-函数入门" class="header-anchor">#</a> Hive 函数入门</h2> <h3 id="概述-2"><a href="#概述-2" class="header-anchor">#</a> 概述</h3> <p>如同RDBMS中标准SQL语法一样，Hive SQL也内建了不少函数，满足于用户在不同场合下的数据分析需求，提高开发SQL数据分析的效率。</p> <p>使用<code>show functions</code>查看当下可用的所有函数；通过 <code>describe function extended funcname</code>来查看函数的使用方式。</p> <h3 id="分类标准"><a href="#分类标准" class="header-anchor">#</a> 分类标准</h3> <p>Hive的函数分为两大类：<strong>内置函数</strong>（Built-in Functions）、<strong>用户定义函数UDF</strong>（User-Defined Functions）：</p> <ul><li>内置函数可分为：<strong>数值类型函数</strong>、<strong>日期类型函数</strong>、<strong>字符串类型函数</strong>、<strong>集合函数</strong>、<strong>条件函数</strong>等；</li> <li>用户定义函数根据输入输出的行数可分为3类：UDF、UDAF、UDTF。</li></ul> <p><img src="/study/assets/img/image-20210904164726917.21417619.png" alt="image-20210904164726917"></p> <h3 id="内置函数分类"><a href="#内置函数分类" class="header-anchor">#</a> 内置函数分类</h3> <p>**内置函数（build-in）**指的是Hive开发实现好，直接可以使用的函数,也叫做内建函数。</p> <p>官方文档地址：https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF</p> <p>内置函数根据应用归类整体可以分为8大种类型，我们将对其中重要的，使用频率高的函数使用进行详细讲解。</p> <blockquote><p>查询函数使用说明：<strong>describe function extended 函数名</strong>;</p></blockquote> <h4 id="string-functions-字符串函数"><a href="#string-functions-字符串函数" class="header-anchor">#</a> String Functions 字符串函数</h4> <p>主要针对字符串数据类型进行操作，比如下面这些：</p> <p><img src="/study/assets/img/image-20210904165128946.e4e1885b.png" alt="image-20210904165128946"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">------------String Functions 字符串函数------------</span>

<span class="token comment">-- 字符串长度函数：length(str | binary)</span>
<span class="token keyword">select</span> length<span class="token punctuation">(</span><span class="token string">&quot;angelababy&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 字符串反转函数：reverse</span>
<span class="token keyword">select</span> reverse<span class="token punctuation">(</span><span class="token string">&quot;angelababy&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 字符串连接函数：concat(str1, str2, ... strN)</span>
<span class="token keyword">select</span> concat<span class="token punctuation">(</span><span class="token string">&quot;angela&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;baby&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 带分隔符字符串连接函数：concat_ws(separator, [string | array(string)]+)</span>
<span class="token keyword">select</span> concat_ws<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">'www'</span><span class="token punctuation">,</span> array<span class="token punctuation">(</span><span class="token string">'test'</span><span class="token punctuation">,</span> <span class="token string">'cn'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 字符串截取函数：substr(str, pos[, len]) 或者  substring(str, pos[, len])</span>
<span class="token keyword">select</span> substr<span class="token punctuation">(</span><span class="token string">&quot;angelababy&quot;</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">--pos是从1开始的索引，如果为负数则倒着数</span>
<span class="token keyword">select</span> substr<span class="token punctuation">(</span><span class="token string">&quot;angelababy&quot;</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 字符串转大写函数：upper,ucase</span>
<span class="token keyword">select</span> upper<span class="token punctuation">(</span><span class="token string">&quot;angelababy&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token function">ucase</span><span class="token punctuation">(</span><span class="token string">&quot;angelababy&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 字符串转小写函数：lower,lcase</span>
<span class="token keyword">select</span> lower<span class="token punctuation">(</span><span class="token string">&quot;ANGELABABY&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token function">lcase</span><span class="token punctuation">(</span><span class="token string">&quot;ANGELABABY&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 去空格函数：trim 去除左右两边的空格</span>
<span class="token keyword">select</span> trim<span class="token punctuation">(</span><span class="token string">&quot; angelababy &quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 左边去空格函数：ltrim</span>
<span class="token keyword">select</span> ltrim<span class="token punctuation">(</span><span class="token string">&quot; angelababy &quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 右边去空格函数：rtrim</span>
<span class="token keyword">select</span> rtrim<span class="token punctuation">(</span><span class="token string">&quot; angelababy &quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 正则表达式替换函数：regexp_replace(str, regexp, rep)</span>
<span class="token keyword">select</span> regexp_replace<span class="token punctuation">(</span><span class="token string">'100-200'</span><span class="token punctuation">,</span> <span class="token string">'(\\d+)'</span><span class="token punctuation">,</span> <span class="token string">'num'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 正则表达式解析函数：regexp_extract(str, regexp[, idx]) 提取正则匹配到的指定组内容</span>
<span class="token keyword">select</span> regexp_extract<span class="token punctuation">(</span><span class="token string">'100-200'</span><span class="token punctuation">,</span> <span class="token string">'(\\d+)-(\\d+)'</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- URL解析函数：parse_url 注意要想一次解析出多个 可以使用parse_url_tuple这个UDTF函数</span>
<span class="token keyword">select</span> parse_url<span class="token punctuation">(</span><span class="token string">'http://www.test.cn/path/p1.php?query=1'</span><span class="token punctuation">,</span> <span class="token string">'HOST'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- json解析函数：get_json_object</span>
<span class="token comment">-- 空格字符串函数：space(n) 返回指定个数空格</span>
<span class="token keyword">select</span> space<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 重复字符串函数：repeat(str, n) 重复str字符串n次</span>
<span class="token keyword">select</span> <span class="token keyword">repeat</span><span class="token punctuation">(</span><span class="token string">&quot;angela&quot;</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 首字符ascii函数：ascii</span>
<span class="token keyword">select</span> ascii<span class="token punctuation">(</span><span class="token string">&quot;angela&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">--a对应ASCII 97</span>

<span class="token comment">-- 左补足函数：lpad</span>
<span class="token keyword">select</span> lpad<span class="token punctuation">(</span><span class="token string">'hi'</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'??'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">--???hi</span>
<span class="token keyword">select</span> lpad<span class="token punctuation">(</span><span class="token string">'hi'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'??'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">--h</span>

<span class="token comment">-- 右补足函数：rpad</span>
<span class="token keyword">select</span> rpad<span class="token punctuation">(</span><span class="token string">'hi'</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'??'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 分割字符串函数: split(str, regex)</span>
<span class="token keyword">select</span> split<span class="token punctuation">(</span><span class="token string">'apache hive'</span><span class="token punctuation">,</span> <span class="token string">'\\s+'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 集合查找函数: find_in_set(str,str_array)</span>
<span class="token keyword">select</span> find_in_set<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span><span class="token string">'abc,b,ab,c,def'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="date-functions-日期函数"><a href="#date-functions-日期函数" class="header-anchor">#</a> Date Functions 日期函数</h4> <p>主要针对时间、日期数据类型进行操作，比如下面这些：</p> <p><img src="/study/assets/img/image-20210904165220761.80826d3f.png" alt="image-20210904165220761"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 获取当前日期: current_date</span>
<span class="token keyword">select</span> <span class="token keyword">current_date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 获取当前时间戳: current_timestamp</span>
<span class="token comment">-- 同一查询中对current_timestamp的所有调用均返回相同的值。</span>
<span class="token keyword">select</span> <span class="token keyword">current_timestamp</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 获取当前UNIX时间戳函数: unix_timestamp</span>
<span class="token keyword">select</span> unix_timestamp<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- UNIX时间戳转日期函数: from_unixtime</span>
<span class="token keyword">select</span> from_unixtime<span class="token punctuation">(</span><span class="token number">1618238391</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> from_unixtime<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'yyyy-MM-dd HH:mm:ss'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 日期转UNIX时间戳函数: unix_timestamp</span>
<span class="token keyword">select</span> unix_timestamp<span class="token punctuation">(</span><span class="token string">&quot;2011-12-07 13:01:03&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 指定格式日期转UNIX时间戳函数: unix_timestamp</span>
<span class="token keyword">select</span> unix_timestamp<span class="token punctuation">(</span><span class="token string">'20111207 13:01:03'</span><span class="token punctuation">,</span><span class="token string">'yyyyMMdd HH:mm:ss'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 抽取日期函数: to_date</span>
<span class="token keyword">select</span> to_date<span class="token punctuation">(</span><span class="token string">'2009-07-30 04:17:52'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 日期转年函数: year</span>
<span class="token keyword">select</span> <span class="token keyword">year</span><span class="token punctuation">(</span><span class="token string">'2009-07-30 04:17:52'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 日期转月函数: month</span>
<span class="token keyword">select</span> <span class="token keyword">month</span><span class="token punctuation">(</span><span class="token string">'2009-07-30 04:17:52'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 日期转天函数: day</span>
<span class="token keyword">select</span> <span class="token keyword">day</span><span class="token punctuation">(</span><span class="token string">'2009-07-30 04:17:52'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 日期转小时函数: hour</span>
<span class="token keyword">select</span> <span class="token keyword">hour</span><span class="token punctuation">(</span><span class="token string">'2009-07-30 04:17:52'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 日期转分钟函数: minute</span>
<span class="token keyword">select</span> <span class="token keyword">minute</span><span class="token punctuation">(</span><span class="token string">'2009-07-30 04:17:52'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 日期转秒函数: second</span>
<span class="token keyword">select</span> <span class="token keyword">second</span><span class="token punctuation">(</span><span class="token string">'2009-07-30 04:17:52'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 日期转周函数: weekofyear 返回指定日期所示年份第几周</span>
<span class="token keyword">select</span> weekofyear<span class="token punctuation">(</span><span class="token string">'2009-07-30 04:17:52'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 日期比较函数: datediff  日期格式要求'yyyy-MM-dd HH:mm:ss' or 'yyyy-MM-dd'</span>
<span class="token keyword">select</span> datediff<span class="token punctuation">(</span><span class="token string">'2012-12-08'</span><span class="token punctuation">,</span><span class="token string">'2012-05-09'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 日期增加函数: date_add</span>
<span class="token keyword">select</span> date_add<span class="token punctuation">(</span><span class="token string">'2012-02-28'</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 日期减少函数: date_sub</span>
<span class="token keyword">select</span> date_sub<span class="token punctuation">(</span><span class="token string">'2012-01-1'</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="mathematical-functions-数学函数"><a href="#mathematical-functions-数学函数" class="header-anchor">#</a> Mathematical Functions 数学函数</h4> <p>主要针对数值类型的数据进行数学计算，比如下面这些：</p> <p><img src="/study/assets/img/image-20210904165415177.4897aafb.png" alt="image-20210904165415177"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 取整函数: round  返回double类型的整数值部分 （遵循四舍五入）</span>
<span class="token keyword">select</span> <span class="token function">round</span><span class="token punctuation">(</span><span class="token number">3.1415926</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 指定精度取整函数: round(double a, int d) 返回指定精度d的double类型</span>
<span class="token keyword">select</span> <span class="token function">round</span><span class="token punctuation">(</span><span class="token number">3.1415926</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 向下取整函数: floor</span>
<span class="token keyword">select</span> floor<span class="token punctuation">(</span><span class="token number">3.1415926</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">-- 3</span>
<span class="token keyword">select</span> floor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3.1415926</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">-- -4</span>

<span class="token comment">-- 向上取整函数: ceil</span>
<span class="token keyword">select</span> ceil<span class="token punctuation">(</span><span class="token number">3.1415926</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">-- 4</span>
<span class="token keyword">select</span> ceil<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3.1415926</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">-- -3</span>

<span class="token comment">-- 取随机数函数: rand 每次执行都不一样 返回一个0到1范围内的随机数</span>
<span class="token keyword">select</span> rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 指定种子取随机数函数: rand(int seed) 得到一个稳定的随机数序列(种子一样，每次都是同一个随机数)</span>
<span class="token keyword">select</span> rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 二进制函数:  bin(BIGINT a)</span>
<span class="token keyword">select</span> bin<span class="token punctuation">(</span><span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 进制转换函数: conv(BIGINT num, int from_base, int to_base)</span>
<span class="token keyword">select</span> conv<span class="token punctuation">(</span><span class="token number">17</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 绝对值函数: abs</span>
<span class="token keyword">select</span> abs<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3.9</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="collection-functions-集合函数"><a href="#collection-functions-集合函数" class="header-anchor">#</a> Collection Functions 集合函数</h4> <p>主要针对集合这样的复杂数据类型进行操作，比如下面这些：</p> <p><img src="/study/assets/img/image-20210904165453421.4b559bcd.png" alt="image-20210904165453421"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 集合元素size函数: size(Map&lt;K.V&gt;) size(Array&lt;T&gt;)</span>
<span class="token keyword">select</span> size<span class="token punctuation">(</span><span class="token punctuation">`</span>array<span class="token punctuation">`</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">,</span><span class="token number">33</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> size<span class="token punctuation">(</span><span class="token punctuation">`</span>map<span class="token punctuation">`</span><span class="token punctuation">(</span><span class="token string">&quot;id&quot;</span><span class="token punctuation">,</span><span class="token number">10086</span><span class="token punctuation">,</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;zhangsan&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 取map集合keys函数: map_keys(Map&lt;K.V&gt;)</span>
<span class="token keyword">select</span> map_keys<span class="token punctuation">(</span><span class="token punctuation">`</span>map<span class="token punctuation">`</span><span class="token punctuation">(</span><span class="token string">&quot;id&quot;</span><span class="token punctuation">,</span><span class="token number">10086</span><span class="token punctuation">,</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;zhangsan&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 取map集合values函数: map_values(Map&lt;K.V&gt;)</span>
<span class="token keyword">select</span> map_values<span class="token punctuation">(</span><span class="token punctuation">`</span>map<span class="token punctuation">`</span><span class="token punctuation">(</span><span class="token string">&quot;id&quot;</span><span class="token punctuation">,</span><span class="token number">10086</span><span class="token punctuation">,</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;zhangsan&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 判断数组是否包含指定元素: array_contains(Array&lt;T&gt;, value)</span>
<span class="token keyword">select</span> array_contains<span class="token punctuation">(</span><span class="token punctuation">`</span>array<span class="token punctuation">`</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">,</span><span class="token number">33</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> array_contains<span class="token punctuation">(</span><span class="token punctuation">`</span>array<span class="token punctuation">`</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">,</span><span class="token number">33</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">66</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 数组排序函数:sort_array(Array&lt;T&gt;)</span>
<span class="token keyword">select</span> sort_array<span class="token punctuation">(</span><span class="token punctuation">`</span>array<span class="token punctuation">`</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="conditional-functions-条件函数"><a href="#conditional-functions-条件函数" class="header-anchor">#</a> Conditional Functions 条件函数</h4> <p>主要用于条件判断、逻辑判断转换这样的场合</p> <p><img src="/study/assets/img/image-20210904165652250.1a985ab5.png" alt="image-20210904165652250"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- 使用之前课程创建好的student表数据</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student <span class="token keyword">limit</span> <span class="token number">3</span><span class="token punctuation">;</span>

<span class="token comment">-- if条件判断: if(boolean testCondition, T valueTrue, T valueFalseOrNull)</span>
<span class="token keyword">select</span> <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token keyword">if</span><span class="token punctuation">(</span>sex <span class="token operator">=</span><span class="token string">'男'</span><span class="token punctuation">,</span><span class="token string">'M'</span><span class="token punctuation">,</span><span class="token string">'W'</span><span class="token punctuation">)</span> <span class="token keyword">from</span> student <span class="token keyword">limit</span> <span class="token number">3</span><span class="token punctuation">;</span>

<span class="token comment">-- 空判断函数: isnull( a )</span>
<span class="token keyword">select</span> isnull<span class="token punctuation">(</span><span class="token string">&quot;allen&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> isnull<span class="token punctuation">(</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 非空判断函数: isnotnull ( a )</span>
<span class="token keyword">select</span> isnotnull<span class="token punctuation">(</span><span class="token string">&quot;allen&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> isnotnull<span class="token punctuation">(</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 空值转换函数: nvl(T value, T default_value)</span>
<span class="token keyword">select</span> nvl<span class="token punctuation">(</span><span class="token string">&quot;allen&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;test&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> nvl<span class="token punctuation">(</span><span class="token boolean">null</span><span class="token punctuation">,</span><span class="token string">&quot;test&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 非空查找函数: COALESCE(T v1, T v2, ...)</span>
<span class="token comment">-- 返回参数中的第一个非空值；如果所有值都为NULL，那么返回NULL</span>
<span class="token keyword">select</span> <span class="token keyword">COALESCE</span><span class="token punctuation">(</span><span class="token boolean">null</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">,</span><span class="token number">33</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token keyword">COALESCE</span><span class="token punctuation">(</span><span class="token boolean">null</span><span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">,</span><span class="token number">33</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token keyword">COALESCE</span><span class="token punctuation">(</span><span class="token boolean">null</span><span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 条件转换函数: CASE a WHEN b THEN c [WHEN d THEN e]* [ELSE f] END</span>
<span class="token keyword">select</span> <span class="token keyword">case</span> <span class="token number">100</span> <span class="token keyword">when</span> <span class="token number">50</span> <span class="token keyword">then</span> <span class="token string">'tom'</span> <span class="token keyword">when</span> <span class="token number">100</span> <span class="token keyword">then</span> <span class="token string">'mary'</span> <span class="token keyword">else</span> <span class="token string">'tim'</span> <span class="token keyword">end</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token keyword">case</span> sex <span class="token keyword">when</span> <span class="token string">'男'</span> <span class="token keyword">then</span> <span class="token string">'man'</span> <span class="token keyword">else</span> <span class="token string">'women'</span> <span class="token keyword">end</span> <span class="token keyword">from</span> student <span class="token keyword">limit</span> <span class="token number">3</span><span class="token punctuation">;</span>

<span class="token comment">-- nullif( a, b ):</span>
<span class="token comment">-- 果a = b，则返回NULL；否则返回一个</span>
<span class="token keyword">select</span> <span class="token keyword">nullif</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token keyword">nullif</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- assert_true(condition)</span>
<span class="token comment">-- 如果'condition'不为真，则引发异常，否则返回null</span>
<span class="token keyword">SELECT</span> assert_true<span class="token punctuation">(</span><span class="token number">11</span> <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">SELECT</span> assert_true<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span> <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="type-conversion-functions-类型转换函数"><a href="#type-conversion-functions-类型转换函数" class="header-anchor">#</a> Type Conversion Functions 类型转换函数</h4> <p>主要用于显式的数据类型转换：</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">--任意数据类型之间转换:cast</span>
<span class="token keyword">select</span> cast<span class="token punctuation">(</span><span class="token number">12.14</span> <span class="token keyword">as</span> <span class="token keyword">bigint</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> cast<span class="token punctuation">(</span><span class="token number">12.14</span> <span class="token keyword">as</span> string<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="data-masking-functions-数据脱敏函数"><a href="#data-masking-functions-数据脱敏函数" class="header-anchor">#</a> Data Masking Functions 数据脱敏函数</h4> <p>主要完成对数据脱敏转换功能，屏蔽原始数据，主要如下：</p> <p><img src="/study/assets/img/image-20210904165938142.81f9de20.png" alt="image-20210904165938142"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- mask</span>
<span class="token comment">-- 将查询回的数据，默认转换规则：大写字母转换为X，小写字母转换为x，数字转换为n。</span>
<span class="token keyword">select</span> mask<span class="token punctuation">(</span><span class="token string">&quot;abc123DEF&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> mask<span class="token punctuation">(</span><span class="token string">&quot;abc123DEF&quot;</span><span class="token punctuation">,</span><span class="token string">'-'</span><span class="token punctuation">,</span><span class="token string">'.'</span><span class="token punctuation">,</span><span class="token string">'^'</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">--自定义替换的字母</span>

<span class="token comment">-- mask_first_n(string str[, int n]</span>
<span class="token comment">-- 对前n个进行脱敏替换</span>
<span class="token keyword">select</span> mask_first_n<span class="token punctuation">(</span><span class="token string">&quot;abc123DEF&quot;</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- mask_last_n(string str[, int n])</span>
<span class="token keyword">select</span> mask_last_n<span class="token punctuation">(</span><span class="token string">&quot;abc123DEF&quot;</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- mask_show_first_n(string str[, int n])</span>
<span class="token comment">-- 除了前n个字符，其余进行掩码处理</span>
<span class="token keyword">select</span> mask_show_first_n<span class="token punctuation">(</span><span class="token string">&quot;abc123DEF&quot;</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- mask_show_last_n(string str[, int n])</span>
<span class="token keyword">select</span> mask_show_last_n<span class="token punctuation">(</span><span class="token string">&quot;abc123DEF&quot;</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- mask_hash(string|char|varchar str)</span>
<span class="token comment">-- 返回字符串的hash编码。</span>
<span class="token keyword">select</span> mask_hash<span class="token punctuation">(</span><span class="token string">&quot;abc123DEF&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h4 id="misc-functions-其他杂项函数"><a href="#misc-functions-其他杂项函数" class="header-anchor">#</a> Misc. Functions 其他杂项函数</h4> <p><img src="/study/assets/img/image-20210904170646637.fd87084f.png" alt="image-20210904170646637"></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">-- hive调用java方法: java_method(class, method[, arg1[, arg2..]])</span>
<span class="token keyword">select</span> java_method<span class="token punctuation">(</span><span class="token string">&quot;java.lang.Math&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;max&quot;</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 反射函数: reflect(class, method[, arg1[, arg2..]])</span>
<span class="token keyword">select</span> reflect<span class="token punctuation">(</span><span class="token string">&quot;java.lang.Math&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;max&quot;</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 取哈希值函数:hash</span>
<span class="token keyword">select</span> <span class="token keyword">hash</span><span class="token punctuation">(</span><span class="token string">&quot;allen&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- current_user()、logged_in_user()、current_database()、version()</span>

<span class="token comment">-- SHA-1加密: sha1(string/binary)</span>
<span class="token keyword">select</span> sha1<span class="token punctuation">(</span><span class="token string">&quot;allen&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- SHA-2家族算法加密：sha2(string/binary, int)  (SHA-224, SHA-256, SHA-384, SHA-512)</span>
<span class="token keyword">select</span> sha2<span class="token punctuation">(</span><span class="token string">&quot;allen&quot;</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> sha2<span class="token punctuation">(</span><span class="token string">&quot;allen&quot;</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- crc32加密:</span>
<span class="token keyword">select</span> crc32<span class="token punctuation">(</span><span class="token string">&quot;allen&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- MD5加密: md5(string/binary)</span>
<span class="token keyword">select</span> md5<span class="token punctuation">(</span><span class="token string">&quot;allen&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h3 id="用户自定义函数分类"><a href="#用户自定义函数分类" class="header-anchor">#</a> 用户自定义函数分类</h3> <p><strong>用户自定义函数简称UDF</strong>，源自于英文user-defined function。</p> <p>根据<strong>函数输入输出的行数</strong>可以分为3类，分别是：</p> <ul><li>UDF（User-Defined-Function）普通函数，一进一出</li> <li>UDAF（User-Defined Aggregation Function）聚合函数，多进一出</li> <li>UDTF（User-Defined Table-Generating Functions）表生成函数，一进多出</li></ul> <p><img src="/study/assets/img/image-20210904171633489.1870556e.png" alt="image-20210904171633489"></p> <h4 id="udf-普通函数"><a href="#udf-普通函数" class="header-anchor">#</a> UDF 普通函数</h4> <p>UDF（User-Defined-Function）普通函数</p> <p>特点：是<strong>一进一出</strong>，也就是输入一行输出一行。</p> <p>比如round这样的取整函数，接收一行数据，输出的还是一行数据。</p> <p><img src="/study/assets/img/image-20210904171738233.891ccf17.png" alt="image-20210904171738233"></p> <h4 id="udaf-聚合函数"><a href="#udaf-聚合函数" class="header-anchor">#</a> UDAF 聚合函数</h4> <p><strong>UDAF 聚合函数</strong>，A所代表的单词就是Aggregation聚合的意思。</p> <p>特点：<strong>多进一出</strong>，也就是输入多行输出一行。</p> <p>比如count、sum这样的函数。</p> <p><img src="/study/assets/img/image-20210904171905083.81931299.png" alt="image-20210904171905083"></p> <h4 id="udtf-表生成函数"><a href="#udtf-表生成函数" class="header-anchor">#</a> UDTF 表生成函数</h4> <p><strong>UDTF 表生成函数</strong>，T所代表的单词是Table-Generating表生成的意思。</p> <p>特点：是<strong>一进多出</strong>，也就是输入一行输出多行。</p> <p>这类型的函数作用<strong>返回的结果类似于表</strong>，同时，UDTF函数也是我们接触比较少的函数。
比如explode函数。</p> <p><img src="/study/assets/img/image-20210904172018129.33641ec5.png" alt="image-20210904172018129"></p> <h4 id="案例-用户自定义udf"><a href="#案例-用户自定义udf" class="header-anchor">#</a> 案例：用户自定义UDF</h4> <h5 id="需求-2"><a href="#需求-2" class="header-anchor">#</a> 需求</h5> <blockquote><p>开发Hive UDF实现手机号加密</p></blockquote> <p>在企业中处理数据的时候，对于敏感数据往往需要进行脱敏处理。比如手机号。我们常见的处理方式是将手机号中间4位进行处理。</p> <p>Hive中没有这样的函数可以直接实现功能，虽然可以通过各种函数的嵌套调用最终也能实现，但是效率不高，现要求自定义开发实现Hive函数，满足上述需求。</p> <ul><li>能够对输入数据进行非空判断、手机号位数判断</li> <li>能够实现校验手机号格式，把满足规则的进行处理</li> <li>对于不符合手机号规则的数据直接返回，不处理</li></ul> <h5 id="实现步骤"><a href="#实现步骤" class="header-anchor">#</a> 实现步骤</h5> <ol><li>写一个java类，继承UDF，并重载evaluate方法，方法中实现函数的业务逻辑；</li> <li>重载意味着可以在一个java类中实现多个函数功能；</li> <li>程序打成jar包，上传HS2服务器本地或者HDFS;</li> <li>客户端命令行中添加jar包到Hive的classpath： <code>hive&gt;add JAR /xxxx/udf.jar;</code></li> <li>注册成为临时函数（给UDF命名）：<code>create temporary function</code> 函数名 as 'UDF类全路径';</li> <li>HQL中使用函数。</li></ol> <h5 id="代码实现"><a href="#代码实现" class="header-anchor">#</a> 代码实现</h5> <p><strong>开发环境准备</strong></p> <p>IDEA中创建Maven工程，添加下述pom依赖，用于开发Hive UDF；</p> <p>完整pom.xml请参考课程附件资料</p> <p>pom.xml依赖：</p> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.hive<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>hive-exec<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.1.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.1.4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>maven-shade-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">&gt;</span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>shade<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>filters</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>filter</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifact</span><span class="token punctuation">&gt;</span></span>*:*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifact</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>excludes</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.SF<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.DSA<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.RSA<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>excludes</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>filter</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>filters</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><p><strong>业务代码：</strong></p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">cn<span class="token punctuation">.</span>test<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>udf</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>commons<span class="token punctuation">.</span>lang<span class="token punctuation">.</span></span><span class="token class-name">StringUtils</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>exec<span class="token punctuation">.</span></span>UDF<span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>regex<span class="token punctuation">.</span></span><span class="token class-name">Matcher</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>regex<span class="token punctuation">.</span></span><span class="token class-name">Pattern</span><span class="token punctuation">;</span>

<span class="token comment">/**
 * @description: hive自定义函数UDF 实现对手机号中间4位进行****加密
 * @author: Itcast
 */</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">EncryptPhoneNumber</span> <span class="token keyword">extends</span> UDF <span class="token punctuation">{</span>
    <span class="token comment">/**
     * 重载evaluate方法 实现函数的业务逻辑
     * @param phoNum  入参：未加密手机号
     * @return 返回：加密后的手机号字符串
     */</span>
    <span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">evaluate</span><span class="token punctuation">(</span><span class="token class-name">String</span> phoNum<span class="token punctuation">)</span><span class="token punctuation">{</span>
        <span class="token class-name">String</span> encryptPhoNum <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
        <span class="token comment">//手机号不为空 并且为11位</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token class-name">StringUtils</span><span class="token punctuation">.</span><span class="token function">isNotEmpty</span><span class="token punctuation">(</span>phoNum<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> phoNum<span class="token punctuation">.</span><span class="token function">trim</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">11</span> <span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token comment">//判断数据是否满足中国大陆手机号码规范</span>
            <span class="token class-name">String</span> regex <span class="token operator">=</span> <span class="token string">&quot;^(1[3-9]\\d{9}$)&quot;</span><span class="token punctuation">;</span>
            <span class="token class-name">Pattern</span> p <span class="token operator">=</span> <span class="token class-name">Pattern</span><span class="token punctuation">.</span><span class="token function">compile</span><span class="token punctuation">(</span>regex<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">Matcher</span> m <span class="token operator">=</span> p<span class="token punctuation">.</span><span class="token function">matcher</span><span class="token punctuation">(</span>phoNum<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>m<span class="token punctuation">.</span><span class="token function">matches</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//进入这里都是符合手机号规则的</span>
                <span class="token comment">//使用正则替换 返回加密后数据</span>
                encryptPhoNum <span class="token operator">=</span> phoNum<span class="token punctuation">.</span><span class="token function">trim</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">replaceAll</span><span class="token punctuation">(</span><span class="token string">&quot;()\\d{4}(\\d{4})&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;$1****$2&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span><span class="token keyword">else</span><span class="token punctuation">{</span>
                <span class="token comment">//不符合手机号规则 数据直接原封不动返回</span>
                encryptPhoNum <span class="token operator">=</span> phoNum<span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token keyword">else</span><span class="token punctuation">{</span>
            <span class="token comment">//不符合11位 数据直接原封不动返回</span>
            encryptPhoNum <span class="token operator">=</span> phoNum<span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token keyword">return</span> encryptPhoNum<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h5 id="部署实例"><a href="#部署实例" class="header-anchor">#</a> 部署实例</h5> <p><strong>打jar包上传服务器</strong></p> <p><img src="/study/assets/img/image-20210905165419573.cc60a793.png" alt="image-20210905165419573"></p> <p><img src="/study/assets/img/image-20210905165444134.7f4b078c.png" alt="image-20210905165444134"></p> <p>把jar包上传到Hiveserver2服务运行所在机器的linux系统，或者HDFS文件系统。</p> <p><strong>添加到 Hive Classpath</strong></p> <p>在客户端使用命令把jar添加到classpath</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token number">0</span>：jdbc:hive2:<span class="token comment">//master:10000&gt; add jar /root/hive-udf-1.0-SNAPSHOT.jar;</span>
</code></pre></div><p><strong>注册临时函数</strong></p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token number">0</span>：jdbc:hive2:<span class="token comment">//master:10000&gt; create temporary function encrypt_phonum as 'cn.test.hive.udf.EncryptPhoneNumber';</span>
</code></pre></div><p><strong>功能效果演示</strong></p> <p><img src="/study/assets/img/image-20210905165952591.a5ba25cc.png" alt="image-20210905165952591"></p> <h2 id="hive-高阶函数"><a href="#hive-高阶函数" class="header-anchor">#</a> Hive 高阶函数</h2> <h3 id="udtf之explode函数"><a href="#udtf之explode函数" class="header-anchor">#</a> UDTF之explode函数</h3> <p>对于UDTF表生成函数，很多人难以理解什么叫做输入一行，输出多行。</p> <p>为什么叫做表生成？能够产生表吗？下面我们就来学习Hive当做内置的一个非常著名的UDTF函数，名字叫做explode函数，中文戏称之为“<strong>爆炸函数</strong>”，可以炸开数据。</p> <h4 id="功能介绍"><a href="#功能介绍" class="header-anchor">#</a> 功能介绍</h4> <ul><li>explode接收<strong>map、array类型</strong>的数据作为<strong>输入</strong>，然后把输入数据中的每个元素拆开变成一行数据，一个元素一行。</li> <li>explode执行效果正好满足于<strong>输入一行输出多行</strong>，所有叫做UDTF函数。</li></ul> <p><img src="/study/assets/img/image-20210905170523011.8e5b467a.png" alt="image-20210905170523011"></p> <h4 id="explode-函数使用"><a href="#explode-函数使用" class="header-anchor">#</a> explode 函数使用</h4> <p>一般情况下，explode函数可以直接单独使用即可；也可以根据业务需要结合lateral view侧视图一起使用。</p> <ul><li><p>explode(array) 将array里的每个元素生成一行；</p></li> <li><p>explode(map)   将map里的每一对元素作为一行，其中key为一列，value为一列；</p></li></ul> <p><img src="/study/assets/img/image-20210905171119073.1e3e95f3.png" alt="image-20210905171119073"></p> <h4 id="案例-nba总冠军球队名单分析"><a href="#案例-nba总冠军球队名单分析" class="header-anchor">#</a> 案例: NBA总冠军球队名单分析</h4> <ol><li>练习explode函数的使用</li> <li>感悟什么叫做UDTF表生成函数</li> <li>发现UDTF函数使用限制</li></ol> <h5 id="业务需求"><a href="#业务需求" class="header-anchor">#</a> 业务需求</h5> <p>有一份数据《The_NBA_Championship.txt》，关于部分年份的NBA总冠军球队名单；</p> <p>第一个字段表示球队名称，第二个字段是获取总冠军的年份；</p> <p>字段之间以，分割；总冠军年份之间以|进行分割。</p> <p>**需求：**使用Hive建表映射成功数据，对数据拆分，要求拆分之后数据如下所示：</p> <p><img src="/study/assets/img/image-20210905171631809.938fa94e.png" alt="image-20210905171631809"></p> <h5 id="建表加载数据"><a href="#建表加载数据" class="header-anchor">#</a> 建表加载数据</h5> <p><img src="/study/assets/img/image-20210905171829216.5705eb10.png" alt="image-20210905171829216"></p> <h5 id="sql-实现业务需求"><a href="#sql-实现业务需求" class="header-anchor">#</a> SQL 实现业务需求</h5> <p><img src="/study/assets/img/image-20210905172111244.c62832f0.png" alt="image-20210905172111244"></p> <h5 id="执行报错"><a href="#执行报错" class="header-anchor">#</a> 执行报错</h5> <ol><li>在select条件中，如果只有explode函数表达式，程序执行是没有任何问题的；</li> <li>但是如果在select条件中，包含explode和其他字段，就会报错；</li> <li>如何理解这个错误？为什么在select的时候，explode的旁边不支持其他字段的同时出现？</li></ol> <blockquote><p>UDTF's are not supported outside the SELECT clause, nor nested in expressions</p></blockquote> <p><img src="/study/assets/img/image-20210905172317069.b817a475.png" alt="image-20210905172317069"></p> <h5 id="udtf-语法限制"><a href="#udtf-语法限制" class="header-anchor">#</a> UDTF 语法限制</h5> <ol><li><p>explode函数属于UDTF表生成函数，explode执行返回结果可以理解为一张虚拟表，其数据来源于源表；</p></li> <li><p>在select中只查询源表数据没有问题，只查询explode生成的虚拟表数据也没问题，但是<strong>不能在只查询源表的时候，既想返回源表字段又想返回explode生成的虚拟表字段</strong>；通俗点讲，有两张表，不能只查询一张表但是又想返回分别属于两张表的字段；</p></li></ol> <p><img src="/study/assets/img/image-20210905172529961.d8cd2612.png" alt="image-20210905172529961"></p> <h5 id="udtf-语法限制解决"><a href="#udtf-语法限制解决" class="header-anchor">#</a> UDTF 语法限制解决</h5> <ol><li>从SQL层面上来说上述问题的解决方案是：对两张表进行join关联查询;</li> <li>Hive专门提供了语法<strong>lateral View侧视图</strong>，专门用于搭配explode这样的UDTF函数，以满足上述需要。</li></ol> <p><img src="/study/assets/img/image-20210905172705412.13bd9862.png" alt="image-20210905172705412"></p> <h3 id="lateral-view-侧视图"><a href="#lateral-view-侧视图" class="header-anchor">#</a> Lateral View 侧视图</h3> <h4 id="概念"><a href="#概念" class="header-anchor">#</a> 概念</h4> <p>Lateral View是一种特殊的语法，主要搭配UDTF类型函数一起使用，用于解决UDTF函数的一些查询限制的问题。一般只要使用UDTF，就会固定搭配lateral view使用。</p> <p>官方链接：https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView</p> <h4 id="原理"><a href="#原理" class="header-anchor">#</a> 原理</h4> <p>将UDTF的结果构建成一个类似于视图的表，然后将原表中的每一行和UDTF函数输出的每一行进行连接，生成一张新的虚拟表。这样就避免了UDTF的使用限制问题。</p> <p>使用lateral view时也可以对UDTF产生的记录设置字段名称，产生的字段可以用于group by、order by 、limit等语句中，不需要再单独嵌套一层子查询。</p> <p><img src="/study/assets/img/image-20210905173105093.d067f0a4.png" alt="image-20210905173105093"></p> <h4 id="lateral-view-udtf-使用"><a href="#lateral-view-udtf-使用" class="header-anchor">#</a> Lateral View + UDTF 使用</h4> <p>针对explode案例中NBA冠军球队年份排名案例，使用explode函数+lateral view侧视图，可以完美解决：</p> <p><img src="/study/assets/img/image-20210905173229858.bf126557.png" alt="image-20210905173229858"></p> <h3 id="aggregation-聚合函数"><a href="#aggregation-聚合函数" class="header-anchor">#</a> Aggregation 聚合函数</h3> <h4 id="概述-3"><a href="#概述-3" class="header-anchor">#</a> 概述</h4> <p>聚合函数的功能是：<strong>对一组值执行计算并返回单一的值</strong>。</p> <p>聚合函数是典型的<strong>输入多行输出一行</strong>，使用Hive的分类标准，属于UDAF类型函数。</p> <p>通常搭配Group By语法一起使用，分组后进行聚合操作。</p> <p><img src="/study/assets/img/image-20210905173440494.bcbf5635.png" alt="image-20210905173440494"></p> <h4 id="基础聚合"><a href="#基础聚合" class="header-anchor">#</a> 基础聚合</h4> <p>HQL提供了几种内置的UDAF聚合函数，例如<strong>max（...），min（...）和avg</strong>（...）**。这些我们把它称之为基础的聚合函数。</p> <p>通常情况下聚合函数会与GROUP BY子句一起使用。如果未指定GROUP BY子句，默认情况下，它会汇总所有行数据。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">--------------基础聚合函数-------------------</span>
<span class="token comment">-- 1、测试数据准备</span>
<span class="token keyword">drop</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token keyword">exists</span> student<span class="token punctuation">;</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> student<span class="token punctuation">(</span>
    num <span class="token keyword">int</span><span class="token punctuation">,</span>
    name string<span class="token punctuation">,</span>
    sex string<span class="token punctuation">,</span>
    age <span class="token keyword">int</span><span class="token punctuation">,</span>
    dept string<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>
<span class="token comment">-- 加载数据</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/hivedata/students.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> student<span class="token punctuation">;</span>
<span class="token comment">-- 验证</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>


<span class="token comment">-- 场景1：没有group by子句的聚合操作</span>
<span class="token comment">--    count(*) 所有行进行统计，包括 NULL 行</span>
<span class="token comment">--    count(1) 所有行进行统计，包括 NULL 行 </span>
<span class="token comment">--    count(column) 对 column 中非NULL进行统计</span>
<span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt1<span class="token punctuation">,</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt2<span class="token punctuation">,</span> <span class="token function">count</span><span class="token punctuation">(</span>sex<span class="token punctuation">)</span> cnt3 <span class="token keyword">from</span> student<span class="token punctuation">;</span> 

<span class="token comment">-- 场景2：带有group by子句的聚合操作 注意group by语法限制</span>
<span class="token keyword">select</span> sex<span class="token punctuation">,</span><span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt <span class="token keyword">from</span> student <span class="token keyword">group</span> <span class="token keyword">by</span> sex<span class="token punctuation">;</span>

<span class="token comment">-- 场景3：select时多个聚合函数一起使用</span>
<span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt1<span class="token punctuation">,</span><span class="token function">avg</span><span class="token punctuation">(</span>age<span class="token punctuation">)</span> <span class="token keyword">as</span> cnt2 <span class="token keyword">from</span> student<span class="token punctuation">;</span>

<span class="token comment">-- 场景4：聚合函数和case when条件转换函数、coalesce函数、if函数使用</span>
<span class="token keyword">select</span>
    <span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">CASE</span> <span class="token keyword">WHEN</span> sex <span class="token operator">=</span> <span class="token string">'男'</span><span class="token keyword">THEN</span> <span class="token number">1</span> <span class="token keyword">ELSE</span> <span class="token number">0</span> <span class="token keyword">END</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> student<span class="token punctuation">;</span>

<span class="token keyword">select</span>
    <span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">if</span><span class="token punctuation">(</span>sex <span class="token operator">=</span> <span class="token string">'男'</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> student<span class="token punctuation">;</span>

<span class="token comment">-- 场景5：聚合参数不支持嵌套聚合函数</span>
<span class="token keyword">select</span> <span class="token function">avg</span><span class="token punctuation">(</span><span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">from</span> student<span class="token punctuation">;</span>

<span class="token comment">-- 聚合参数针对null的处理方式</span>
<span class="token comment">-- null null 0</span>
<span class="token keyword">select</span> <span class="token function">max</span><span class="token punctuation">(</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">min</span><span class="token punctuation">(</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">-- 下面这两个不支持null</span>
<span class="token keyword">select</span> <span class="token function">sum</span><span class="token punctuation">(</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">avg</span><span class="token punctuation">(</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 场景5：聚合操作时针对null的处理</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> tmp_1 <span class="token punctuation">(</span>val1 <span class="token keyword">int</span><span class="token punctuation">,</span> val2 <span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> <span class="token keyword">TABLE</span> tmp_1 <span class="token keyword">VALUES</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token boolean">null</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> tmp_1<span class="token punctuation">;</span>

<span class="token comment">-- 第二行数据(NULL, 2) 在进行sum(val1 + val2)的时候会被忽略</span>
<span class="token keyword">select</span> <span class="token function">sum</span><span class="token punctuation">(</span>val1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">sum</span><span class="token punctuation">(</span>val1 <span class="token operator">+</span> val2<span class="token punctuation">)</span> <span class="token keyword">from</span> tmp_1<span class="token punctuation">;</span>
<span class="token comment">-- 可以使用coalesce函数解决</span>
<span class="token keyword">select</span>
    <span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">coalesce</span><span class="token punctuation">(</span>val1<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">coalesce</span><span class="token punctuation">(</span>val1<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> val2<span class="token punctuation">)</span>
<span class="token keyword">from</span> tmp_1<span class="token punctuation">;</span>

<span class="token comment">-- 场景6：配合distinct关键字去重聚合</span>
<span class="token comment">-- 此场景下，会编译期间会自动设置只启动一个reduce task处理数据  性能可能会不会 造成数据拥堵</span>
<span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> sex<span class="token punctuation">)</span> <span class="token keyword">as</span> cnt1 <span class="token keyword">from</span> student<span class="token punctuation">;</span>
<span class="token comment">-- 可以先去重 在聚合 通过子查询完成</span>
<span class="token comment">-- 因为先执行distinct的时候 可以使用多个reducetask来跑数据</span>
<span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">as</span> gender_uni_cnt
<span class="token keyword">from</span> <span class="token punctuation">(</span><span class="token keyword">select</span> <span class="token keyword">distinct</span> sex <span class="token keyword">from</span> student<span class="token punctuation">)</span> a<span class="token punctuation">;</span>

<span class="token comment">-- 案例需求：找出student中男女学生年龄最大的及其名字</span>
<span class="token comment">-- 这里使用了struct来构造数据 然后针对struct应用max找出最大元素 然后取值</span>
<span class="token keyword">select</span> sex<span class="token punctuation">,</span>
<span class="token function">max</span><span class="token punctuation">(</span>struct<span class="token punctuation">(</span>age<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>col1 <span class="token keyword">as</span> age<span class="token punctuation">,</span>
<span class="token function">max</span><span class="token punctuation">(</span>struct<span class="token punctuation">(</span>age<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>col2 <span class="token keyword">as</span> name
<span class="token keyword">from</span> student
<span class="token keyword">group</span> <span class="token keyword">by</span> sex<span class="token punctuation">;</span>

<span class="token keyword">select</span> struct<span class="token punctuation">(</span>age<span class="token punctuation">,</span> name<span class="token punctuation">)</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>
<span class="token keyword">select</span> struct<span class="token punctuation">(</span>age<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">.</span>col1 <span class="token keyword">from</span> student<span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token function">max</span><span class="token punctuation">(</span>struct<span class="token punctuation">(</span>age<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>
</code></pre></div><h4 id="增强聚合"><a href="#增强聚合" class="header-anchor">#</a> 增强聚合</h4> <p>增强聚合包括<strong>grouping_sets、cube、rollup</strong>这几个函数；主要适用于OLAP多维数据分析模式中，多维分析中的维指的分析问题时看待问题的维度、角度。</p> <p>下面通过案例更好的理解函数的功能含义。数据中字段含义：月份、天、用户标识cookieid。</p> <p><img src="/study/assets/img/image-20210905173918137.ddf01c7a.png" alt="image-20210905173918137"></p> <h5 id="grouping-sets"><a href="#grouping-sets" class="header-anchor">#</a> grouping sets</h5> <p><strong>grouping sets</strong>是一种将多个group by逻辑写在一个sql语句中的便利写法。</p> <p>等价于将不同维度的GROUP BY结果集进行UNION ALL。</p> <p>GROUPING__ID表示结果属于哪一个分组集合。</p> <p><img src="/study/assets/img/image-20210905180254634.68a7e15b.png" alt="image-20210905180254634"></p> <p><img src="/study/assets/img/image-20210905180127666.28ca9a8e.png" alt="image-20210905180127666"></p> <h5 id="cube"><a href="#cube" class="header-anchor">#</a> cube</h5> <p>cube表示根据GROUP BY的维度的所有组合进行聚合。</p> <p>对于cube来说,如果有n个维度,则所有组合的总个数是：2^n</p> <p>比如cube有a,b,c 3个维度，则所有组合情况是： (a,b,c),(a,b),(b,c),(a,c),(a),(b),(c),()</p> <p><img src="/study/assets/img/image-20210905180317440.96400974.png" alt="image-20210905180317440"></p> <h5 id="rollup"><a href="#rollup" class="header-anchor">#</a> rollup</h5> <p>cube的语法功能指的是：根据GROUP BY的维度的所有组合进行聚合。</p> <p>rollup是cube的子集，以最左侧的维度为主，从该维度进行层级聚合。</p> <p>比如ROLLUP有a,b,c3个维度，则所有组合情况是：(a,b,c),(a,b),(a),()</p> <p><img src="/study/assets/img/image-20210905180417846.e2d22868.png" alt="image-20210905180417846"></p> <h3 id="window-functions-窗口函数"><a href="#window-functions-窗口函数" class="header-anchor">#</a> Window functions 窗口函数</h3> <h4 id="概述-4"><a href="#概述-4" class="header-anchor">#</a> 概述</h4> <p><strong>窗口函数</strong>（Window functions）也叫做开窗函数、OLAP函数，其最大特点是：<strong>输入值是从SELECT语句的结果集中的一行或多行的“窗口”中获取的</strong>。</p> <p>如果函数具有OVER子句，则它是窗口函数。</p> <p>窗口函数可以简单地解释为类似于<strong>聚合函数的计算函数</strong>，但是通过GROUP BY子句组合的常规聚合会隐藏正在聚合的各个行，最终输出一行，窗口函数聚合后还可以访问当中的各个行，并且可以将这些行中的某些属性添加到结果集中。</p> <p><img src="/study/assets/img/image-20210905202839203.8f97d9bb.png" alt="image-20210905202839203"></p> <p>通过sum聚合函数进行普通常规聚合和窗口聚合，来直观感受窗口函数的特点。</p> <p><img src="/study/assets/img/image-20210905203030690.a1cab923.png" alt="image-20210905203030690"></p> <h4 id="语法规则-2"><a href="#语法规则-2" class="header-anchor">#</a> 语法规则</h4> <p><img src="/study/assets/img/image-20210905203136383.a0c50ae3.png" alt="image-20210905203136383"></p> <h4 id="案例-网站用户页面浏览次数分析"><a href="#案例-网站用户页面浏览次数分析" class="header-anchor">#</a> 案例：网站用户页面浏览次数分析</h4> <p>在网站访问中，经常使用cookie来标识不同的用户身份，通过cookie可以追踪不同用户的页面访问情况。</p> <p>通过用户在网站的访问数据学习Hive中窗口函数的相关语法知识。</p> <p>有下面两份数据：</p> <p><img src="/study/assets/img/image-20210905203520698.e5b0f90a.png" alt="image-20210905203520698"></p> <p>在Hive中创建两张表表，把数据加载进去用于窗口分析。</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token comment">--- 建表并且加载数据</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> website_pv_info<span class="token punctuation">(</span>
   cookieid string<span class="token punctuation">,</span>
   createtime string<span class="token punctuation">,</span>   <span class="token comment">--day</span>
   pv <span class="token keyword">int</span>
<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>

<span class="token keyword">create</span> <span class="token keyword">table</span> website_url_info <span class="token punctuation">(</span>
    cookieid string<span class="token punctuation">,</span>
    createtime string<span class="token punctuation">,</span>  <span class="token comment">--访问时间</span>
    url string       <span class="token comment">--访问页面</span>
<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span><span class="token punctuation">;</span>


<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/hivedata/website_pv_info.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> website_pv_info<span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/root/hivedata/website_url_info.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> website_url_info<span class="token punctuation">;</span>

<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> website_pv_info<span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> website_url_info<span class="token punctuation">;</span>
</code></pre></div><h5 id="窗口聚合函数"><a href="#窗口聚合函数" class="header-anchor">#</a> 窗口聚合函数</h5> <p>所谓窗口聚合函数指的是sum、max、min、avg这样的聚合函数在窗口中的使用；</p> <p>从Hive v2.2.0开始，支持DISTINCT与窗口函数中的聚合函数一起使用。</p> <p>这里以sum()函数为例，其他聚合函数使用类似。</p> <p><img src="/study/assets/img/image-20210905204143899.d5b2f978.png" alt="image-20210905204143899"></p> <p><img src="/study/assets/img/image-20210905204816528.d7ea63b8.png" alt="image-20210905204816528"></p> <p><img src="/study/assets/img/image-20210905204857274.29190b2f.png" alt="image-20210905204857274"></p> <p><img src="/study/assets/img/image-20210905205040351.c59d8a33.png" alt="image-20210905205040351"></p> <h4 id="窗口表达式"><a href="#窗口表达式" class="header-anchor">#</a> 窗口表达式</h4> <p>在sum(...) over( partition by... order by ... )语法完整的情况下，进行累积聚合操作，默认累积聚合行为是：<strong>从第一行聚合到当前行</strong>。</p> <p>Window expression窗口表达式给我们提供了一种控制行范围的能力，比如向前2行，向后3行。</p> <p>语法如下：</p> <p><img src="/study/assets/img/image-20210905210234836.a5a21c3c.png" alt="image-20210905210234836"></p> <p>示例：</p> <p><img src="/study/assets/img/image-20210905210305732.7d5de651.png" alt="image-20210905210305732"></p> <h4 id="窗口排序函数-row-number家族"><a href="#窗口排序函数-row-number家族" class="header-anchor">#</a> 窗口排序函数 - row_number家族</h4> <p>用于给每个分组内的数据打上排序的标号，注意窗口排序函数不支持窗口表达式</p> <ul><li>row_number：在每个分组中，为每行分配一个从1开始的唯一序列号，递增，不考虑重复；</li> <li>rank: 在每个分组中，为每行分配一个从1开始的序列号，考虑重复，挤占后续位置；</li> <li>dense_rank: 在每个分组中，为每行分配一个从1开始的序列号，考虑重复，不挤占后续位置；</li></ul> <p><img src="/study/assets/img/image-20210905210908591.fa45ebc3.png" alt="image-20210905210908591"></p> <p><strong>上述这三个函数用于分组TopN的场景非常适合。</strong></p> <p><img src="/study/assets/img/image-20210905211114016.6857d8d7.png" alt="image-20210905211114016"></p> <h4 id="窗口排序函数-ntile"><a href="#窗口排序函数-ntile" class="header-anchor">#</a> 窗口排序函数--ntile</h4> <p><strong>将每个分组内的数据分为指定的若干个桶里</strong>（分为若干个部分），并且为每一个桶分配一个桶编号。</p> <p>如果不能平均分配，则优先分配较小编号的桶，并且各个桶中能放的行数最多相差1。</p> <p><strong>有时会有这样的需求:</strong></p> <p>如果数据排序后分为三部分，业务人员只关心其中的一部分，如何将这中间的三分之一数据拿出来呢? NTILE函数即可以满足。</p> <p><img src="/study/assets/img/image-20210905211514819.40e72bbc.png" alt="image-20210905211514819"></p> <h4 id="窗口分析函数"><a href="#窗口分析函数" class="header-anchor">#</a> 窗口分析函数</h4> <ul><li><p><strong>LAG</strong>(col,n,DEFAULT) 用于统计窗口内往上第n行值</p> <p>第一个参数为列名，第二个参数为往上第n行（可选，默认为1），第三个参数为默认值（当往上第n行为NULL时候，取默认值，如不指定，则为NULL）；</p></li> <li><p><strong>LEAD</strong>(col,n,DEFAULT) 用于统计窗口内往下第n行值</p> <p>第一个参数为列名，第二个参数为往下第n行（可选，默认为1），第三个参数为默认值（当往下第n行为NULL时候，取默认值，如不指定，则为NULL）；</p></li> <li><p><strong>FIRST_VALUE</strong> 取分组内排序后，截止到当前行，第一个值</p></li> <li><p><strong>LAST_VALUE</strong> 取分组内排序后，截止到当前行，最后一个值</p></li></ul> <p><img src="/study/assets/img/image-20210905211907752.9f17fd09.png" alt="image-20210905211907752"></p> <p><img src="/study/assets/img/image-20210905211936112.23578ae5.png" alt="image-20210905211936112"></p> <p><img src="/study/assets/img/image-20210905212106805.6a886d08.png" alt="image-20210905212106805"></p> <h3 id="sampling-抽样函数"><a href="#sampling-抽样函数" class="header-anchor">#</a> Sampling 抽样函数</h3> <h4 id="概述-5"><a href="#概述-5" class="header-anchor">#</a> 概述</h4> <p>当数据量过大时，我们可能需要查找数据子集以加快数据处理速度分析。</p> <p>这就是<strong>抽样、采样</strong>，一种用于识别和分析数据中的子集的技术，以发现整个数据集中的模式和趋势。</p> <p>在HQL中，可以通过三种方式采样数据：<strong>随机采样</strong>，<strong>存储桶表采样</strong>和块采样。</p> <p><img src="/study/assets/img/image-20210905212231618.7a0407b0.png" alt="image-20210905212231618"></p> <h4 id="random-随机抽样"><a href="#random-随机抽样" class="header-anchor">#</a> Random 随机抽样</h4> <p>随机抽样使用**rand（）**函数来确保随机获取数据，LIMIT来限制抽取的数据个数。</p> <p><strong>优点是随机，缺点是速度不快</strong>，尤其表数据多的时候。</p> <ul><li>推荐<strong>DISTRIBUTE+SORT</strong>，可以确保数据也随机分布在mapper和reducer之间，使得底层执行有效率。</li> <li><strong>ORDER BY</strong>语句也可以达到相同的目的，但是表现不好，因为ORDER BY是全局排序，只会启动运行一个reducer 。</li></ul> <p>示例：</p> <p><img src="/study/assets/img/image-20210905212503004.f46f2e8d.png" alt="image-20210905212503004"></p> <h4 id="block-基于数据块抽样"><a href="#block-基于数据块抽样" class="header-anchor">#</a> Block 基于数据块抽样</h4> <p>Block块采样允许<strong>随机获取n行数据、百分比数据或指定大小的数据。</strong></p> <p>采样粒度是<strong>HDFS块大小</strong>。</p> <p>优点是速度快，缺点是不随机。</p> <p><img src="/study/assets/img/image-20210905212746127.03da0db1.png" alt="image-20210905212746127"></p> <h4 id="bucket-table-基于分桶表抽样"><a href="#bucket-table-基于分桶表抽样" class="header-anchor">#</a> Bucket table 基于分桶表抽样</h4> <p>这是一种特殊的采样方法，针对分桶表进行了优化。</p> <p><strong>优点是既随机速度也很快。</strong></p> <p>语法如下：</p> <p><img src="/study/assets/img/image-20210905212905004.710b1d62.png" alt="image-20210905212905004"></p> <p>示例：</p> <p><img src="/study/assets/img/image-20210905212944859.ebdff186.png" alt="image-20210905212944859"></p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/study/da-shu-ju/hadoop.html" class="prev">
        Hadoop
      </a></span> <span class="next"><a href="/study/da-shu-ju/hue.html">
        Hue
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----><!----></div></div>
    <script src="/study/assets/js/app.dc60e210.js" defer></script><script src="/study/assets/js/6.fceef279.js" defer></script><script src="/study/assets/js/2.6082ecbd.js" defer></script>
  </body>
</html>
